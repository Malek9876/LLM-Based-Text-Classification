{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malek9876/LLM-Based-Text-Classification/blob/main/Sentiment_Analysis_Using_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMQV0xV5GUQX",
        "outputId": "808358cf-d3fa-4d51-a1b6-1c70457d0df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (24.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: kagglehub in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.6)\n",
            "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (23.2)\n",
            "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (2024.8.30)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.1)\n",
            "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.48.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
            "Requirement already satisfied: seaborn in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "%pip install --upgrade pip\n",
        "%pip install kagglehub\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download('abhi8923shriv/sentiment-analysis-dataset')\n",
        "\n",
        "# Install the required libraries\n",
        "%pip install pandas numpy nltk scikit-learn transformers matplotlib seaborn\n",
        "#%pip uninstall torch torchvision torchaudio -y\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WspHhyP757H4"
      },
      "source": [
        "# Sentiment Analysis on Kaggle sentiment analysis dataset\n",
        "sentiment analysis tasks on kaggle sentiment analysis dataset using simple machine learning model: Naive bayes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgtBS7we9zxF"
      },
      "source": [
        "## Including needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:36.548968Z",
          "iopub.status.busy": "2024-09-12T08:22:36.548571Z",
          "iopub.status.idle": "2024-09-12T08:22:39.953833Z",
          "shell.execute_reply": "2024-09-12T08:22:39.952412Z",
          "shell.execute_reply.started": "2024-09-12T08:22:36.548927Z"
        },
        "id": "V56eXYTz3Wi6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# --------------- MAIN LIBRARIES ------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# --------------- HELPING LIBRARIES ----------------\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ------------- Pytorch Librairies ---------------\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX8kWFB-_ou8"
      },
      "source": [
        "## Uploading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:39.957158Z",
          "iopub.status.busy": "2024-09-12T08:22:39.956494Z",
          "iopub.status.idle": "2024-09-12T08:22:39.976107Z",
          "shell.execute_reply": "2024-09-12T08:22:39.974235Z",
          "shell.execute_reply.started": "2024-09-12T08:22:39.957103Z"
        },
        "id": "K9dAjDTZBSKW",
        "outputId": "2a1964af-5ae9-4781-a91d-ffb39be37cb8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "train_dataset = path+'/train.csv'\n",
        "test_dataset = path+'/test.csv'\n",
        "\n",
        "# Check if the path exists\n",
        "print (os.path.exists(train_dataset))\n",
        "print (os.path.exists(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:39.978592Z",
          "iopub.status.busy": "2024-09-12T08:22:39.978053Z",
          "iopub.status.idle": "2024-09-12T08:22:40.231514Z",
          "shell.execute_reply": "2024-09-12T08:22:40.230228Z",
          "shell.execute_reply.started": "2024-09-12T08:22:39.978535Z"
        },
        "id": "hW9BRdvvB5-i",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "train_df = pd.read_csv(train_dataset, encoding='ISO-8859-1')\n",
        "test_df = pd.read_csv(test_dataset, encoding='ISO-8859-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.236134Z",
          "iopub.status.busy": "2024-09-12T08:22:40.234876Z",
          "iopub.status.idle": "2024-09-12T08:22:40.279444Z",
          "shell.execute_reply": "2024-09-12T08:22:40.278232Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.236076Z"
        },
        "id": "Cv2hsR9aDAkQ",
        "outputId": "d2e36aeb-3af6-413d-91a4-0e2c161d341c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment Time of Tweet Age of User  \\\n",
              "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
              "1                             Sooo SAD  negative          noon       21-30   \n",
              "2                          bullying me  negative         night       31-45   \n",
              "3                       leave me alone  negative       morning       46-60   \n",
              "4                        Sons of ****,  negative          noon       60-70   \n",
              "\n",
              "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
              "0  Afghanistan          38928346         652860.0               60  \n",
              "1      Albania           2877797          27400.0              105  \n",
              "2      Algeria          43851044        2381740.0               18  \n",
              "3      Andorra             77265            470.0              164  \n",
              "4       Angola          32866272        1246700.0               26  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLHgZmS_KaeW"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.282164Z",
          "iopub.status.busy": "2024-09-12T08:22:40.281383Z",
          "iopub.status.idle": "2024-09-12T08:22:40.337247Z",
          "shell.execute_reply": "2024-09-12T08:22:40.335825Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.282119Z"
        },
        "id": "lQTMOPxnWhs7",
        "outputId": "5595146d-2358-4289-f2bc-c087a7e39b76",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27481 entries, 0 to 27480\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            27481 non-null  object \n",
            " 1   text              27480 non-null  object \n",
            " 2   selected_text     27480 non-null  object \n",
            " 3   sentiment         27481 non-null  object \n",
            " 4   Time of Tweet     27481 non-null  object \n",
            " 5   Age of User       27481 non-null  object \n",
            " 6   Country           27481 non-null  object \n",
            " 7   Population -2020  27481 non-null  int64  \n",
            " 8   Land Area (Km²)   27481 non-null  float64\n",
            " 9   Density (P/Km²)   27481 non-null  int64  \n",
            "dtypes: float64(1), int64(2), object(7)\n",
            "memory usage: 2.1+ MB\n"
          ]
        }
      ],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.340796Z",
          "iopub.status.busy": "2024-09-12T08:22:40.340393Z",
          "iopub.status.idle": "2024-09-12T08:22:40.358799Z",
          "shell.execute_reply": "2024-09-12T08:22:40.357343Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.340755Z"
        },
        "id": "GmpjaoKBWluP",
        "outputId": "2143527c-74cd-4a50-f732-82d04cd4fdb2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4815 entries, 0 to 4814\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            3534 non-null   object \n",
            " 1   text              3534 non-null   object \n",
            " 2   sentiment         3534 non-null   object \n",
            " 3   Time of Tweet     3534 non-null   object \n",
            " 4   Age of User       3534 non-null   object \n",
            " 5   Country           3534 non-null   object \n",
            " 6   Population -2020  3534 non-null   float64\n",
            " 7   Land Area (Km²)   3534 non-null   float64\n",
            " 8   Density (P/Km²)   3534 non-null   float64\n",
            "dtypes: float64(3), object(6)\n",
            "memory usage: 338.7+ KB\n"
          ]
        }
      ],
      "source": [
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U95kjy7kKgIC"
      },
      "source": [
        "#### Handling null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.360843Z",
          "iopub.status.busy": "2024-09-12T08:22:40.360383Z",
          "iopub.status.idle": "2024-09-12T08:22:40.402343Z",
          "shell.execute_reply": "2024-09-12T08:22:40.401081Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.36079Z"
        },
        "id": "RaWIiyJWKeUd",
        "outputId": "6c61868f-1cf3-4f01-b690-d9f168cb98cc",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                1\n",
              "selected_text       1\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.404817Z",
          "iopub.status.busy": "2024-09-12T08:22:40.404388Z",
          "iopub.status.idle": "2024-09-12T08:22:40.465463Z",
          "shell.execute_reply": "2024-09-12T08:22:40.463998Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.404776Z"
        },
        "id": "_5ZDZQ73Kydz",
        "outputId": "a31675d6-563d-4ac8-be41-3b6fd77cfa95",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                0\n",
              "selected_text       0\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = train_df.dropna()\n",
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.467344Z",
          "iopub.status.busy": "2024-09-12T08:22:40.466939Z",
          "iopub.status.idle": "2024-09-12T08:22:40.481329Z",
          "shell.execute_reply": "2024-09-12T08:22:40.479919Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.4673Z"
        },
        "id": "x5nimN6_WGRR",
        "outputId": "3eee7f0a-83e3-492f-bcf0-f3edd602ab4c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              1281\n",
              "text                1281\n",
              "sentiment           1281\n",
              "Time of Tweet       1281\n",
              "Age of User         1281\n",
              "Country             1281\n",
              "Population -2020    1281\n",
              "Land Area (Km²)     1281\n",
              "Density (P/Km²)     1281\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.487599Z",
          "iopub.status.busy": "2024-09-12T08:22:40.486547Z",
          "iopub.status.idle": "2024-09-12T08:22:40.507416Z",
          "shell.execute_reply": "2024-09-12T08:22:40.506177Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.487539Z"
        },
        "id": "A3hqNN4GWP9J",
        "outputId": "d37c315f-eccb-42f3-9563-941610c401d5",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                0\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOgrqQewLCdw"
      },
      "source": [
        "#### Removing stopwords & lowercase all text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.509448Z",
          "iopub.status.busy": "2024-09-12T08:22:40.508972Z",
          "iopub.status.idle": "2024-09-12T08:22:40.598748Z",
          "shell.execute_reply": "2024-09-12T08:22:40.597069Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.509394Z"
        },
        "id": "Qpsxd4BWNHJO",
        "outputId": "f1abd31d-5bd5-4b9f-de18-4cb44ce81a10",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.601099Z",
          "iopub.status.busy": "2024-09-12T08:22:40.600609Z",
          "iopub.status.idle": "2024-09-12T08:22:40.609951Z",
          "shell.execute_reply": "2024-09-12T08:22:40.608024Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.601044Z"
        },
        "id": "GyCFZy2FOZ0u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Text preprocessing function that removes stopwords and convert text to lowercase\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.611901Z",
          "iopub.status.busy": "2024-09-12T08:22:40.611511Z",
          "iopub.status.idle": "2024-09-12T08:22:45.335514Z",
          "shell.execute_reply": "2024-09-12T08:22:45.334329Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.611861Z"
        },
        "id": "6Rd5y7pkOyXz",
        "outputId": "e9b5306f-5c8d-46c9-fa42-c4856f39cf98",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60</td>\n",
              "      <td>i`d responded, going</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105</td>\n",
              "      <td>sooo sad miss san diego!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18</td>\n",
              "      <td>boss bullying me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164</td>\n",
              "      <td>interview! leave alone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26</td>\n",
              "      <td>sons ****, couldn`t put releases already bought</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment Time of Tweet Age of User  \\\n",
              "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
              "1                             Sooo SAD  negative          noon       21-30   \n",
              "2                          bullying me  negative         night       31-45   \n",
              "3                       leave me alone  negative       morning       46-60   \n",
              "4                        Sons of ****,  negative          noon       60-70   \n",
              "\n",
              "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \\\n",
              "0  Afghanistan          38928346         652860.0               60   \n",
              "1      Albania           2877797          27400.0              105   \n",
              "2      Algeria          43851044        2381740.0               18   \n",
              "3      Andorra             77265            470.0              164   \n",
              "4       Angola          32866272        1246700.0               26   \n",
              "\n",
              "                                    processed_text  \n",
              "0                             i`d responded, going  \n",
              "1                       sooo sad miss san diego!!!  \n",
              "2                              boss bullying me...  \n",
              "3                           interview! leave alone  \n",
              "4  sons ****, couldn`t put releases already bought  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply preprocessing on train dataset\n",
        "train_df['processed_text'] = train_df['text'].apply(preprocess_text)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:45.337762Z",
          "iopub.status.busy": "2024-09-12T08:22:45.337232Z",
          "iopub.status.idle": "2024-09-12T08:22:45.959644Z",
          "shell.execute_reply": "2024-09-12T08:22:45.958512Z",
          "shell.execute_reply.started": "2024-09-12T08:22:45.337709Z"
        },
        "id": "2Vpcp2FVXXVQ",
        "outputId": "c6770cf5-f897-410a-b6ae-7df5bd9181a2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f87dea47db</td>\n",
              "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346.0</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>last session day http://twitpic.com/67ezh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96d74cb729</td>\n",
              "      <td>Shanghai is also really exciting (precisely -...</td>\n",
              "      <td>positive</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797.0</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>shanghai also really exciting (precisely -- sk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eee518ae67</td>\n",
              "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044.0</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>recession hit veronique branquinho, quit compa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01082688c6</td>\n",
              "      <td>happy bday!</td>\n",
              "      <td>positive</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265.0</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>happy bday!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33987a8ee5</td>\n",
              "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
              "      <td>positive</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272.0</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>http://twitpic.com/4w75p - like it!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text sentiment  \\\n",
              "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
              "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
              "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
              "3  01082688c6                                        happy bday!  positive   \n",
              "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
              "\n",
              "  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n",
              "0       morning        0-20  Afghanistan        38928346.0         652860.0   \n",
              "1          noon       21-30      Albania         2877797.0          27400.0   \n",
              "2         night       31-45      Algeria        43851044.0        2381740.0   \n",
              "3       morning       46-60      Andorra           77265.0            470.0   \n",
              "4          noon       60-70       Angola        32866272.0        1246700.0   \n",
              "\n",
              "   Density (P/Km²)                                     processed_text  \n",
              "0             60.0          last session day http://twitpic.com/67ezh  \n",
              "1            105.0  shanghai also really exciting (precisely -- sk...  \n",
              "2             18.0  recession hit veronique branquinho, quit compa...  \n",
              "3            164.0                                        happy bday!  \n",
              "4             26.0               http://twitpic.com/4w75p - like it!!  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply preprocessing on test dataset\n",
        "test_df['processed_text'] = test_df['text'].apply(preprocess_text)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9FZF-S6RwT0"
      },
      "source": [
        "## Check Imbalancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:27:19.351826Z",
          "iopub.status.busy": "2024-09-12T08:27:19.351335Z",
          "iopub.status.idle": "2024-09-12T08:27:19.610508Z",
          "shell.execute_reply": "2024-09-12T08:27:19.609354Z",
          "shell.execute_reply.started": "2024-09-12T08:27:19.351775Z"
        },
        "id": "uRP-7dXHUcgb",
        "outputId": "c55e8422-deb7-49b4-b029-1d1d3a550c50",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Distribution of sentiment labels\n",
        "sns.countplot(x='sentiment', data=train_df)\n",
        "plt.title(\"Distribution of Sentiment Labels\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ppFEsZZXIW75"
      },
      "outputs": [],
      "source": [
        "# 1. Transform sentiment into 3 classes\n",
        "# Example mapping: positive -> 2, neutral -> 1, negative -> 0\n",
        "sentiment_mapping = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
        "train_df[\"sentiment_class\"] = train_df[\"sentiment\"].map(sentiment_mapping)\n",
        "test_df[\"sentiment_class\"] = test_df[\"sentiment\"].map(sentiment_mapping)\n",
        "\n",
        "# 2. Extract all the values from the 'processed_text' column into a list\n",
        "trainval_x = train_df[\"processed_text\"].tolist()\n",
        "trainval_y = train_df[\"sentiment_class\"].tolist()\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(trainval_x, trainval_y, test_size=0.25, random_state=42)\n",
        "\n",
        "test_x = test_df[\"processed_text\"].tolist()\n",
        "test_y = test_df[\"sentiment_class\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGje1w01rjlw",
        "outputId": "862fa31c-ba1a-4f4d-ce50-676b87f2b2a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27480 6870 3534\n"
          ]
        }
      ],
      "source": [
        "print(len(trainval_x),len(val_x),len(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "meidY0NVsChh"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "PRETRAINED_MODEL = \"bert-base-uncased\"\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "EPOCHS = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Custom Dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of sentiment labels (e.g., 0, 1).\n",
        "            tokenizer (transformers.BertTokenizer): Tokenizer for BERT.\n",
        "            max_length (int): Maximum length for tokenized sequences.\n",
        "        \"\"\"\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and encode the text\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Extract embeddings for all data\n",
        "def extract_embeddings(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Extracts embeddings for all data using a pre-trained BERT model.\n",
        "\n",
        "    Args:\n",
        "        model (transformers.BertModel): Pre-trained BERT model.\n",
        "        dataloader (DataLoader): DataLoader for the dataset.\n",
        "        device (torch.device): Device to run the model on (CPU or GPU).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A matrix of size (number_of_samples, embedding_size).\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    embeddings = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            # Forward pass through BERT\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            pooled_output = outputs.pooler_output  # CLS token representation\n",
        "\n",
        "            # Append embeddings to the list\n",
        "            embeddings.append(pooled_output.cpu())\n",
        "\n",
        "    # Combine all embeddings into a single matrix\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "# Initialize tokenizer, dataset, and dataloader\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
        "traindataset = TextDataset(train_x, train_y, tokenizer, MAX_LENGTH)\n",
        "trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "valdataset = TextDataset(val_x, val_y, tokenizer, MAX_LENGTH)\n",
        "valloader = DataLoader(valdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "bert = BertModel.from_pretrained(PRETRAINED_MODEL).to(device)\n",
        "# Extract embeddings\n",
        "train_embeddings = extract_embeddings(bert, trainloader, device)\n",
        "train_embeddings =train_embeddings.cpu()\n",
        "\n",
        "val_embeddings = extract_embeddings(bert, valloader, device)\n",
        "val_embeddings =val_embeddings.cpu()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWzk4bUcvX03",
        "outputId": "a905e572-cd4f-4db6-9117-16f9e062d890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20610, 768])\n",
            "torch.Size([6870, 768])\n"
          ]
        }
      ],
      "source": [
        "print(train_embeddings.size())\n",
        "print(val_embeddings.size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lHR_N9OiwgYL"
      },
      "outputs": [],
      "source": [
        "criterion= nn.CrossEntropyLoss()\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "# Custom Dataset\n",
        "class EmbeddingDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of sentiment labels (e.g., 0, 1).\n",
        "            tokenizer (transformers.BertTokenizer): Tokenizer for BERT.\n",
        "            max_length (int): Maximum length for tokenized sequences.\n",
        "        \"\"\"\n",
        "        self.embeddings = embeddings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and encode the text\n",
        "        embeddings = self.embeddings[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": embeddings.squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Model Definition\n",
        "import torch.nn as nn\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes, dropout_rate=0.2):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_size1)  # Batch Normalization\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_size2)  # Batch Normalization\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\n",
        "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.fc1(input_ids)\n",
        "        x = self.bn1(x)  # Apply Batch Normalization\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)  # Apply Batch Normalization\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# training script\n",
        "\n",
        "def train( model, train_loader, optimizer, epoch,log_interval=50):\n",
        "    model.train()\n",
        "    loss_cpu=0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, target = data['input_ids'],data['label']\n",
        "        inputs, target = inputs.cuda(), target.cuda()\n",
        "        inputs =inputs.detach()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        loss_cpu+= loss.item()\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
        "                %(epoch, EPOCHS, batch_idx+1,\n",
        "                    (len(train_loader)//BATCH_SIZE)+1, loss.item(), 100.*correct/total))\n",
        "            #n_iter=epoch * len(train_loader) + batch_idx\n",
        "\n",
        "    return loss_cpu/len(train_loader)\n",
        "\n",
        "# testing script\n",
        "def test( model, test_loader,epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss_MSE =0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(test_loader, 0):\n",
        "            inputs, target = data['input_ids'],data['label']\n",
        "            inputs, target = inputs.cuda(), target.cuda()\n",
        "            outputs  = model(inputs)\n",
        "            loss = criterion(outputs,target)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target.data).cpu().sum()\n",
        "            test_loss_MSE+= loss.item()\n",
        "\n",
        "    test_loss_MSE = test_loss_MSE/ len(test_loader)\n",
        "    print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), 100.*correct/total))\n",
        "    return test_loss_MSE, 100.*correct/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0X6VeclzYro",
        "outputId": "1d64bacd-dc0d-42b0-a915-387380137513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let us Train.\n",
            "Training with parameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_size1': 256, 'hidden_size2': 128, 'learning_rate': 1e-05, 'weight_decay': 0.01}\n",
            "Epoch 1/10, Training Loss: 1.0812687121103945\n",
            "Epoch 1/10, Validation Accuracy: 0.5037845705967977\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.41      0.43      1956\n",
            "           1       0.50      0.60      0.54      2787\n",
            "           2       0.58      0.47      0.52      2127\n",
            "\n",
            "    accuracy                           0.50      6870\n",
            "   macro avg       0.51      0.49      0.50      6870\n",
            "weighted avg       0.51      0.50      0.50      6870\n",
            "\n",
            "Epoch 2/10, Training Loss: 1.001170870148401\n",
            "Epoch 2/10, Validation Accuracy: 0.5519650655021834\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.44      0.49      1956\n",
            "           1       0.53      0.61      0.57      2787\n",
            "           2       0.59      0.58      0.58      2127\n",
            "\n",
            "    accuracy                           0.55      6870\n",
            "   macro avg       0.55      0.54      0.55      6870\n",
            "weighted avg       0.55      0.55      0.55      6870\n",
            "\n",
            "Epoch 3/10, Training Loss: 0.956047872175932\n",
            "Epoch 3/10, Validation Accuracy: 0.5689956331877729\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.45      0.51      1956\n",
            "           1       0.54      0.64      0.58      2787\n",
            "           2       0.62      0.58      0.60      2127\n",
            "\n",
            "    accuracy                           0.57      6870\n",
            "   macro avg       0.58      0.56      0.56      6870\n",
            "weighted avg       0.57      0.57      0.57      6870\n",
            "\n",
            "Epoch 4/10, Training Loss: 0.9291904780310604\n",
            "Epoch 4/10, Validation Accuracy: 0.5759825327510917\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.51      0.54      1956\n",
            "           1       0.56      0.59      0.57      2787\n",
            "           2       0.60      0.63      0.61      2127\n",
            "\n",
            "    accuracy                           0.58      6870\n",
            "   macro avg       0.58      0.57      0.57      6870\n",
            "weighted avg       0.58      0.58      0.58      6870\n",
            "\n",
            "Epoch 5/10, Training Loss: 0.9091080400563165\n",
            "Epoch 5/10, Validation Accuracy: 0.585589519650655\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.56      0.56      1956\n",
            "           1       0.57      0.59      0.58      2787\n",
            "           2       0.65      0.59      0.62      2127\n",
            "\n",
            "    accuracy                           0.59      6870\n",
            "   macro avg       0.59      0.58      0.59      6870\n",
            "weighted avg       0.59      0.59      0.59      6870\n",
            "\n",
            "Epoch 6/10, Training Loss: 0.8944503188306762\n",
            "Epoch 6/10, Validation Accuracy: 0.5880640465793304\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.42      0.51      1956\n",
            "           1       0.55      0.66      0.60      2787\n",
            "           2       0.61      0.65      0.63      2127\n",
            "\n",
            "    accuracy                           0.59      6870\n",
            "   macro avg       0.60      0.58      0.58      6870\n",
            "weighted avg       0.60      0.59      0.58      6870\n",
            "\n",
            "Epoch 7/10, Training Loss: 0.8854509956567164\n",
            "Epoch 7/10, Validation Accuracy: 0.5986899563318777\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.54      0.56      1956\n",
            "           1       0.56      0.67      0.61      2787\n",
            "           2       0.69      0.56      0.62      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.61      0.59      0.60      6870\n",
            "weighted avg       0.61      0.60      0.60      6870\n",
            "\n",
            "Epoch 8/10, Training Loss: 0.8769049580093728\n",
            "Epoch 8/10, Validation Accuracy: 0.6039301310043668\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.56      0.57      1956\n",
            "           1       0.57      0.63      0.60      2787\n",
            "           2       0.67      0.61      0.64      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.61      0.60      0.60      6870\n",
            "weighted avg       0.61      0.60      0.60      6870\n",
            "\n",
            "Epoch 9/10, Training Loss: 0.8675000823741397\n",
            "Epoch 9/10, Validation Accuracy: 0.6034934497816594\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.48      0.55      1956\n",
            "           1       0.57      0.66      0.61      2787\n",
            "           2       0.64      0.64      0.64      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.61      0.59      0.60      6870\n",
            "weighted avg       0.61      0.60      0.60      6870\n",
            "\n",
            "Epoch 10/10, Training Loss: 0.8643498903336542\n",
            "Epoch 10/10, Validation Accuracy: 0.6065502183406114\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.50      0.56      1956\n",
            "           1       0.58      0.64      0.61      2787\n",
            "           2       0.63      0.66      0.64      2127\n",
            "\n",
            "    accuracy                           0.61      6870\n",
            "   macro avg       0.61      0.60      0.60      6870\n",
            "weighted avg       0.61      0.61      0.60      6870\n",
            "\n",
            "Training with parameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_size1': 256, 'hidden_size2': 128, 'learning_rate': 1e-05, 'weight_decay': 0.001}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12920\\2240961638.py:90: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Training Loss: 1.0742069679345394\n",
            "Epoch 1/10, Validation Accuracy: 0.49912663755458514\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.24      0.33      1956\n",
            "           1       0.49      0.62      0.55      2787\n",
            "           2       0.51      0.58      0.54      2127\n",
            "\n",
            "    accuracy                           0.50      6870\n",
            "   macro avg       0.50      0.48      0.47      6870\n",
            "weighted avg       0.50      0.50      0.48      6870\n",
            "\n",
            "Epoch 2/10, Training Loss: 1.0102564476809994\n",
            "Epoch 2/10, Validation Accuracy: 0.5420669577874818\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.26      0.37      1956\n",
            "           1       0.50      0.73      0.59      2787\n",
            "           2       0.59      0.56      0.57      2127\n",
            "\n",
            "    accuracy                           0.54      6870\n",
            "   macro avg       0.57      0.52      0.51      6870\n",
            "weighted avg       0.56      0.54      0.52      6870\n",
            "\n",
            "Epoch 3/10, Training Loss: 0.9684572936376862\n",
            "Epoch 3/10, Validation Accuracy: 0.5598253275109171\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.46      0.50      1956\n",
            "           1       0.53      0.61      0.57      2787\n",
            "           2       0.60      0.59      0.59      2127\n",
            "\n",
            "    accuracy                           0.56      6870\n",
            "   macro avg       0.56      0.55      0.56      6870\n",
            "weighted avg       0.56      0.56      0.56      6870\n",
            "\n",
            "Epoch 4/10, Training Loss: 0.9384276307479437\n",
            "Epoch 4/10, Validation Accuracy: 0.5758369723435226\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.55      0.54      1956\n",
            "           1       0.56      0.59      0.57      2787\n",
            "           2       0.64      0.59      0.61      2127\n",
            "\n",
            "    accuracy                           0.58      6870\n",
            "   macro avg       0.58      0.57      0.58      6870\n",
            "weighted avg       0.58      0.58      0.58      6870\n",
            "\n",
            "Epoch 5/10, Training Loss: 0.9150706878164219\n",
            "Epoch 5/10, Validation Accuracy: 0.5848617176128094\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.58      0.56      1956\n",
            "           1       0.56      0.62      0.59      2787\n",
            "           2       0.67      0.55      0.61      2127\n",
            "\n",
            "    accuracy                           0.58      6870\n",
            "   macro avg       0.59      0.58      0.58      6870\n",
            "weighted avg       0.59      0.58      0.59      6870\n",
            "\n",
            "Epoch 6/10, Training Loss: 0.904748983906057\n",
            "Epoch 6/10, Validation Accuracy: 0.5832605531295487\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.63      0.58      1956\n",
            "           1       0.59      0.53      0.56      2787\n",
            "           2       0.64      0.61      0.62      2127\n",
            "\n",
            "    accuracy                           0.58      6870\n",
            "   macro avg       0.59      0.59      0.59      6870\n",
            "weighted avg       0.59      0.58      0.58      6870\n",
            "\n",
            "Epoch 7/10, Training Loss: 0.8913788173454354\n",
            "Epoch 7/10, Validation Accuracy: 0.5962154294032024\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.53      0.56      1956\n",
            "           1       0.57      0.63      0.60      2787\n",
            "           2       0.65      0.61      0.63      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.60      0.59      0.59      6870\n",
            "weighted avg       0.60      0.60      0.60      6870\n",
            "\n",
            "Epoch 8/10, Training Loss: 0.8859397042323987\n",
            "Epoch 8/10, Validation Accuracy: 0.5967976710334789\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.60      0.58      1956\n",
            "           1       0.57      0.65      0.61      2787\n",
            "           2       0.70      0.52      0.60      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.61      0.59      0.60      6870\n",
            "weighted avg       0.61      0.60      0.60      6870\n",
            "\n",
            "Epoch 9/10, Training Loss: 0.8747125980404036\n",
            "Epoch 9/10, Validation Accuracy: 0.5965065502183406\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.64      0.59      1956\n",
            "           1       0.59      0.56      0.57      2787\n",
            "           2       0.66      0.61      0.63      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.60      0.60      0.60      6870\n",
            "weighted avg       0.60      0.60      0.60      6870\n",
            "\n",
            "Epoch 10/10, Training Loss: 0.8709757399061593\n",
            "Epoch 10/10, Validation Accuracy: 0.6029112081513828\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.56      0.58      1956\n",
            "           1       0.59      0.58      0.58      2787\n",
            "           2       0.62      0.68      0.65      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.60      0.60      0.60      6870\n",
            "weighted avg       0.60      0.60      0.60      6870\n",
            "\n",
            "Training with parameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_size1': 256, 'hidden_size2': 128, 'learning_rate': 2e-05, 'weight_decay': 0.01}\n",
            "Epoch 1/10, Training Loss: 1.051392334262935\n",
            "Epoch 1/10, Validation Accuracy: 0.5310043668122271\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.36      0.44      1956\n",
            "           1       0.51      0.61      0.55      2787\n",
            "           2       0.55      0.59      0.57      2127\n",
            "\n",
            "    accuracy                           0.53      6870\n",
            "   macro avg       0.54      0.52      0.52      6870\n",
            "weighted avg       0.53      0.53      0.52      6870\n",
            "\n",
            "Epoch 2/10, Training Loss: 0.9570851802710246\n",
            "Epoch 2/10, Validation Accuracy: 0.5660844250363901\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.51      0.53      1956\n",
            "           1       0.54      0.57      0.56      2787\n",
            "           2       0.60      0.61      0.60      2127\n",
            "\n",
            "    accuracy                           0.57      6870\n",
            "   macro avg       0.57      0.56      0.57      6870\n",
            "weighted avg       0.57      0.57      0.57      6870\n",
            "\n",
            "Epoch 3/10, Training Loss: 0.9166232232270108\n",
            "Epoch 3/10, Validation Accuracy: 0.5617176128093159\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.28      0.39      1956\n",
            "           1       0.51      0.72      0.60      2787\n",
            "           2       0.61      0.62      0.61      2127\n",
            "\n",
            "    accuracy                           0.56      6870\n",
            "   macro avg       0.60      0.54      0.54      6870\n",
            "weighted avg       0.59      0.56      0.54      6870\n",
            "\n",
            "Epoch 4/10, Training Loss: 0.8936899635873912\n",
            "Epoch 4/10, Validation Accuracy: 0.5701601164483261\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.34      0.45      1956\n",
            "           1       0.53      0.66      0.59      2787\n",
            "           2       0.60      0.66      0.63      2127\n",
            "\n",
            "    accuracy                           0.57      6870\n",
            "   macro avg       0.59      0.55      0.55      6870\n",
            "weighted avg       0.58      0.57      0.56      6870\n",
            "\n",
            "Epoch 5/10, Training Loss: 0.885531714169624\n",
            "Epoch 5/10, Validation Accuracy: 0.5965065502183406\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.62      0.58      1956\n",
            "           1       0.59      0.57      0.58      2787\n",
            "           2       0.67      0.60      0.64      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.60      0.60      0.60      6870\n",
            "weighted avg       0.60      0.60      0.60      6870\n",
            "\n",
            "Epoch 6/10, Training Loss: 0.8691263100755036\n",
            "Epoch 6/10, Validation Accuracy: 0.5940320232896652\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.40      0.50      1956\n",
            "           1       0.53      0.74      0.62      2787\n",
            "           2       0.68      0.58      0.63      2127\n",
            "\n",
            "    accuracy                           0.59      6870\n",
            "   macro avg       0.62      0.57      0.58      6870\n",
            "weighted avg       0.61      0.59      0.59      6870\n",
            "\n",
            "Epoch 7/10, Training Loss: 0.8639944911986401\n",
            "Epoch 7/10, Validation Accuracy: 0.6096069868995633\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.58      0.59      1956\n",
            "           1       0.58      0.63      0.60      2787\n",
            "           2       0.67      0.61      0.64      2127\n",
            "\n",
            "    accuracy                           0.61      6870\n",
            "   macro avg       0.61      0.61      0.61      6870\n",
            "weighted avg       0.61      0.61      0.61      6870\n",
            "\n",
            "Epoch 8/10, Training Loss: 0.8586981013814897\n",
            "Epoch 8/10, Validation Accuracy: 0.6074235807860262\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.59      0.58      1956\n",
            "           1       0.59      0.60      0.60      2787\n",
            "           2       0.67      0.63      0.65      2127\n",
            "\n",
            "    accuracy                           0.61      6870\n",
            "   macro avg       0.61      0.61      0.61      6870\n",
            "weighted avg       0.61      0.61      0.61      6870\n",
            "\n",
            "Epoch 9/10, Training Loss: 0.8480439651249567\n",
            "Epoch 9/10, Validation Accuracy: 0.5981077147016012\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.49      0.54      1956\n",
            "           1       0.54      0.75      0.63      2787\n",
            "           2       0.73      0.50      0.60      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.63      0.58      0.59      6870\n",
            "weighted avg       0.62      0.60      0.59      6870\n",
            "\n",
            "Epoch 10/10, Training Loss: 0.8412375991463603\n",
            "Epoch 10/10, Validation Accuracy: 0.6023289665211062\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.43      0.52      1956\n",
            "           1       0.55      0.70      0.62      2787\n",
            "           2       0.65      0.63      0.64      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.62      0.59      0.59      6870\n",
            "weighted avg       0.61      0.60      0.60      6870\n",
            "\n",
            "Training with parameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_size1': 256, 'hidden_size2': 128, 'learning_rate': 2e-05, 'weight_decay': 0.001}\n",
            "Epoch 1/10, Training Loss: 1.0646806098256858\n",
            "Epoch 1/10, Validation Accuracy: 0.541193595342067\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.37      0.45      1956\n",
            "           1       0.54      0.58      0.56      2787\n",
            "           2       0.53      0.65      0.59      2127\n",
            "\n",
            "    accuracy                           0.54      6870\n",
            "   macro avg       0.55      0.53      0.53      6870\n",
            "weighted avg       0.54      0.54      0.53      6870\n",
            "\n",
            "Epoch 2/10, Training Loss: 0.9653013931900942\n",
            "Epoch 2/10, Validation Accuracy: 0.5643377001455604\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.33      0.43      1956\n",
            "           1       0.54      0.64      0.59      2787\n",
            "           2       0.57      0.69      0.62      2127\n",
            "\n",
            "    accuracy                           0.56      6870\n",
            "   macro avg       0.58      0.55      0.55      6870\n",
            "weighted avg       0.57      0.56      0.55      6870\n",
            "\n",
            "Epoch 3/10, Training Loss: 0.9225974973921982\n",
            "Epoch 3/10, Validation Accuracy: 0.5713245997088792\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50      1956\n",
            "           1       0.57      0.56      0.56      2787\n",
            "           2       0.54      0.74      0.63      2127\n",
            "\n",
            "    accuracy                           0.57      6870\n",
            "   macro avg       0.58      0.57      0.56      6870\n",
            "weighted avg       0.58      0.57      0.56      6870\n",
            "\n",
            "Epoch 4/10, Training Loss: 0.8956265773083735\n",
            "Epoch 4/10, Validation Accuracy: 0.5800582241630277\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.61      0.58      1956\n",
            "           1       0.61      0.45      0.52      2787\n",
            "           2       0.58      0.72      0.64      2127\n",
            "\n",
            "    accuracy                           0.58      6870\n",
            "   macro avg       0.58      0.59      0.58      6870\n",
            "weighted avg       0.58      0.58      0.57      6870\n",
            "\n",
            "Epoch 5/10, Training Loss: 0.8779406551942266\n",
            "Epoch 5/10, Validation Accuracy: 0.6005822416302765\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.51      0.55      1956\n",
            "           1       0.57      0.62      0.60      2787\n",
            "           2       0.64      0.66      0.65      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.61      0.60      0.60      6870\n",
            "weighted avg       0.60      0.60      0.60      6870\n",
            "\n",
            "Epoch 6/10, Training Loss: 0.8731295478453861\n",
            "Epoch 6/10, Validation Accuracy: 0.5991266375545852\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.49      0.55      1956\n",
            "           1       0.59      0.59      0.59      2787\n",
            "           2       0.60      0.71      0.65      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.60      0.60      0.60      6870\n",
            "weighted avg       0.60      0.60      0.60      6870\n",
            "\n",
            "Epoch 7/10, Training Loss: 0.8613647801271056\n",
            "Epoch 7/10, Validation Accuracy: 0.6045123726346434\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.45      0.54      1956\n",
            "           1       0.57      0.65      0.61      2787\n",
            "           2       0.61      0.69      0.65      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.62      0.60      0.60      6870\n",
            "weighted avg       0.61      0.60      0.60      6870\n",
            "\n",
            "Epoch 8/10, Training Loss: 0.8547954541337773\n",
            "Epoch 8/10, Validation Accuracy: 0.6027656477438137\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.55      0.58      1956\n",
            "           1       0.61      0.54      0.57      2787\n",
            "           2       0.58      0.73      0.65      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.60      0.61      0.60      6870\n",
            "weighted avg       0.61      0.60      0.60      6870\n",
            "\n",
            "Epoch 9/10, Training Loss: 0.84986943040063\n",
            "Epoch 9/10, Validation Accuracy: 0.5917030567685589\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.38      0.49      1956\n",
            "           1       0.58      0.61      0.60      2787\n",
            "           2       0.56      0.76      0.65      2127\n",
            "\n",
            "    accuracy                           0.59      6870\n",
            "   macro avg       0.62      0.58      0.58      6870\n",
            "weighted avg       0.61      0.59      0.58      6870\n",
            "\n",
            "Epoch 10/10, Training Loss: 0.8420736393148838\n",
            "Epoch 10/10, Validation Accuracy: 0.6120815138282387\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.64      0.60      1956\n",
            "           1       0.59      0.63      0.61      2787\n",
            "           2       0.72      0.56      0.63      2127\n",
            "\n",
            "    accuracy                           0.61      6870\n",
            "   macro avg       0.62      0.61      0.61      6870\n",
            "weighted avg       0.62      0.61      0.61      6870\n",
            "\n",
            "Training with parameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_size1': 256, 'hidden_size2': 256, 'learning_rate': 1e-05, 'weight_decay': 0.01}\n",
            "Epoch 1/10, Training Loss: 1.0769391908048715\n",
            "Epoch 1/10, Validation Accuracy: 0.5128093158660845\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.27      0.36      1956\n",
            "           1       0.51      0.58      0.54      2787\n",
            "           2       0.51      0.64      0.57      2127\n",
            "\n",
            "    accuracy                           0.51      6870\n",
            "   macro avg       0.52      0.50      0.49      6870\n",
            "weighted avg       0.52      0.51      0.50      6870\n",
            "\n",
            "Epoch 2/10, Training Loss: 0.9909762987576891\n",
            "Epoch 2/10, Validation Accuracy: 0.536098981077147\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.30      0.40      1956\n",
            "           1       0.53      0.57      0.55      2787\n",
            "           2       0.52      0.71      0.60      2127\n",
            "\n",
            "    accuracy                           0.54      6870\n",
            "   macro avg       0.55      0.53      0.52      6870\n",
            "weighted avg       0.55      0.54      0.52      6870\n",
            "\n",
            "Epoch 3/10, Training Loss: 0.9490405820400492\n",
            "Epoch 3/10, Validation Accuracy: 0.5657933042212518\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.42      0.50      1956\n",
            "           1       0.53      0.62      0.57      2787\n",
            "           2       0.59      0.62      0.61      2127\n",
            "\n",
            "    accuracy                           0.57      6870\n",
            "   macro avg       0.57      0.56      0.56      6870\n",
            "weighted avg       0.57      0.57      0.56      6870\n",
            "\n",
            "Epoch 4/10, Training Loss: 0.9243937590121066\n",
            "Epoch 4/10, Validation Accuracy: 0.5793304221251819\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.46      0.51      1956\n",
            "           1       0.54      0.67      0.60      2787\n",
            "           2       0.65      0.57      0.61      2127\n",
            "\n",
            "    accuracy                           0.58      6870\n",
            "   macro avg       0.59      0.57      0.57      6870\n",
            "weighted avg       0.59      0.58      0.58      6870\n",
            "\n",
            "Epoch 5/10, Training Loss: 0.9055582472330618\n",
            "Epoch 5/10, Validation Accuracy: 0.5640465793304221\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.36      0.47      1956\n",
            "           1       0.54      0.58      0.56      2787\n",
            "           2       0.55      0.72      0.63      2127\n",
            "\n",
            "    accuracy                           0.56      6870\n",
            "   macro avg       0.58      0.56      0.55      6870\n",
            "weighted avg       0.58      0.56      0.55      6870\n",
            "\n",
            "Epoch 6/10, Training Loss: 0.8918823220960033\n",
            "Epoch 6/10, Validation Accuracy: 0.5823871906841339\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.64      0.57      1956\n",
            "           1       0.57      0.57      0.57      2787\n",
            "           2       0.70      0.55      0.61      2127\n",
            "\n",
            "    accuracy                           0.58      6870\n",
            "   macro avg       0.59      0.59      0.58      6870\n",
            "weighted avg       0.59      0.58      0.58      6870\n",
            "\n",
            "Epoch 7/10, Training Loss: 0.8799504207905376\n",
            "Epoch 7/10, Validation Accuracy: 0.5957787481804949\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.54      0.56      1956\n",
            "           1       0.57      0.61      0.59      2787\n",
            "           2       0.63      0.63      0.63      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.60      0.59      0.60      6870\n",
            "weighted avg       0.60      0.60      0.60      6870\n",
            "\n",
            "Epoch 8/10, Training Loss: 0.874632620533828\n",
            "Epoch 8/10, Validation Accuracy: 0.6008733624454149\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.59      0.58      1956\n",
            "           1       0.58      0.59      0.59      2787\n",
            "           2       0.65      0.62      0.64      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.60      0.60      0.60      6870\n",
            "weighted avg       0.60      0.60      0.60      6870\n",
            "\n",
            "Epoch 9/10, Training Loss: 0.8669467996243769\n",
            "Epoch 9/10, Validation Accuracy: 0.6043668122270742\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.57      0.57      1956\n",
            "           1       0.58      0.64      0.61      2787\n",
            "           2       0.68      0.59      0.63      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.61      0.60      0.60      6870\n",
            "weighted avg       0.61      0.60      0.60      6870\n",
            "\n",
            "Epoch 10/10, Training Loss: 0.8640806717990615\n",
            "Epoch 10/10, Validation Accuracy: 0.6069868995633187\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.53      0.57      1956\n",
            "           1       0.58      0.61      0.60      2787\n",
            "           2       0.63      0.67      0.65      2127\n",
            "\n",
            "    accuracy                           0.61      6870\n",
            "   macro avg       0.61      0.60      0.61      6870\n",
            "weighted avg       0.61      0.61      0.61      6870\n",
            "\n",
            "Training with parameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_size1': 256, 'hidden_size2': 256, 'learning_rate': 1e-05, 'weight_decay': 0.001}\n",
            "Epoch 1/10, Training Loss: 1.0625099935906424\n",
            "Epoch 1/10, Validation Accuracy: 0.5250363901018923\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.27      0.37      1956\n",
            "           1       0.50      0.65      0.57      2787\n",
            "           2       0.55      0.59      0.57      2127\n",
            "\n",
            "    accuracy                           0.53      6870\n",
            "   macro avg       0.54      0.51      0.50      6870\n",
            "weighted avg       0.53      0.53      0.51      6870\n",
            "\n",
            "Epoch 2/10, Training Loss: 0.98068925664588\n",
            "Epoch 2/10, Validation Accuracy: 0.5580786026200873\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.41      0.49      1956\n",
            "           1       0.56      0.55      0.55      2787\n",
            "           2       0.54      0.71      0.61      2127\n",
            "\n",
            "    accuracy                           0.56      6870\n",
            "   macro avg       0.57      0.55      0.55      6870\n",
            "weighted avg       0.56      0.56      0.55      6870\n",
            "\n",
            "Epoch 3/10, Training Loss: 0.9379557097206874\n",
            "Epoch 3/10, Validation Accuracy: 0.5774381368267831\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.41      0.49      1956\n",
            "           1       0.54      0.66      0.59      2787\n",
            "           2       0.61      0.63      0.62      2127\n",
            "\n",
            "    accuracy                           0.58      6870\n",
            "   macro avg       0.59      0.56      0.57      6870\n",
            "weighted avg       0.58      0.58      0.57      6870\n",
            "\n",
            "Epoch 4/10, Training Loss: 0.9145910809770017\n",
            "Epoch 4/10, Validation Accuracy: 0.5857350800582242\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.45      0.52      1956\n",
            "           1       0.56      0.61      0.59      2787\n",
            "           2       0.60      0.68      0.64      2127\n",
            "\n",
            "    accuracy                           0.59      6870\n",
            "   macro avg       0.59      0.58      0.58      6870\n",
            "weighted avg       0.59      0.59      0.58      6870\n",
            "\n",
            "Epoch 5/10, Training Loss: 0.8951019872455328\n",
            "Epoch 5/10, Validation Accuracy: 0.5919941775836972\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.54      0.55      1956\n",
            "           1       0.56      0.62      0.59      2787\n",
            "           2       0.66      0.60      0.63      2127\n",
            "\n",
            "    accuracy                           0.59      6870\n",
            "   macro avg       0.60      0.59      0.59      6870\n",
            "weighted avg       0.59      0.59      0.59      6870\n",
            "\n",
            "Epoch 6/10, Training Loss: 0.8901509362248065\n",
            "Epoch 6/10, Validation Accuracy: 0.5963609898107715\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.57      0.57      1956\n",
            "           1       0.58      0.57      0.58      2787\n",
            "           2       0.63      0.66      0.64      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.60      0.60      0.60      6870\n",
            "weighted avg       0.60      0.60      0.60      6870\n",
            "\n",
            "Epoch 7/10, Training Loss: 0.8788844591202752\n",
            "Epoch 7/10, Validation Accuracy: 0.5873362445414847\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.44      0.52      1956\n",
            "           1       0.57      0.60      0.59      2787\n",
            "           2       0.59      0.70      0.64      2127\n",
            "\n",
            "    accuracy                           0.59      6870\n",
            "   macro avg       0.60      0.58      0.58      6870\n",
            "weighted avg       0.59      0.59      0.58      6870\n",
            "\n",
            "Epoch 8/10, Training Loss: 0.8739588960752158\n",
            "Epoch 8/10, Validation Accuracy: 0.5995633187772926\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.52      0.56      1956\n",
            "           1       0.58      0.59      0.59      2787\n",
            "           2       0.61      0.68      0.64      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.60      0.60      0.60      6870\n",
            "weighted avg       0.60      0.60      0.60      6870\n",
            "\n",
            "Epoch 9/10, Training Loss: 0.8645873319981227\n",
            "Epoch 9/10, Validation Accuracy: 0.5890829694323144\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.70      0.60      1956\n",
            "           1       0.64      0.44      0.52      2787\n",
            "           2       0.62      0.69      0.65      2127\n",
            "\n",
            "    accuracy                           0.59      6870\n",
            "   macro avg       0.59      0.61      0.59      6870\n",
            "weighted avg       0.60      0.59      0.58      6870\n",
            "\n",
            "Epoch 10/10, Training Loss: 0.8565050012217397\n",
            "Epoch 10/10, Validation Accuracy: 0.5972343522561863\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.55      0.57      1956\n",
            "           1       0.60      0.53      0.57      2787\n",
            "           2       0.59      0.72      0.65      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.60      0.60      0.60      6870\n",
            "weighted avg       0.60      0.60      0.59      6870\n",
            "\n",
            "Training with parameters: {'batch_size': 16, 'dropout_rate': 0.2, 'hidden_size1': 256, 'hidden_size2': 256, 'learning_rate': 2e-05, 'weight_decay': 0.01}\n",
            "Epoch 1/10, Training Loss: 1.0307014726134887\n",
            "Epoch 1/10, Validation Accuracy: 0.5285298398835516\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.33      0.43      1956\n",
            "           1       0.56      0.50      0.53      2787\n",
            "           2       0.48      0.75      0.58      2127\n",
            "\n",
            "    accuracy                           0.53      6870\n",
            "   macro avg       0.55      0.53      0.51      6870\n",
            "weighted avg       0.55      0.53      0.52      6870\n",
            "\n",
            "Epoch 2/10, Training Loss: 0.9426967535303497\n",
            "Epoch 2/10, Validation Accuracy: 0.5701601164483261\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.62      0.57      1956\n",
            "           1       0.59      0.47      0.52      2787\n",
            "           2       0.59      0.66      0.62      2127\n",
            "\n",
            "    accuracy                           0.57      6870\n",
            "   macro avg       0.57      0.58      0.57      6870\n",
            "weighted avg       0.57      0.57      0.57      6870\n",
            "\n",
            "Epoch 3/10, Training Loss: 0.9038683116696287\n",
            "Epoch 3/10, Validation Accuracy: 0.5400291120815138\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.40      0.49      1956\n",
            "           1       0.60      0.42      0.49      2787\n",
            "           2       0.48      0.83      0.61      2127\n",
            "\n",
            "    accuracy                           0.54      6870\n",
            "   macro avg       0.57      0.55      0.53      6870\n",
            "weighted avg       0.57      0.54      0.53      6870\n",
            "\n",
            "Epoch 4/10, Training Loss: 0.8901211629846268\n",
            "Epoch 4/10, Validation Accuracy: 0.5857350800582242\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.54      0.56      1956\n",
            "           1       0.60      0.51      0.55      2787\n",
            "           2       0.58      0.72      0.64      2127\n",
            "\n",
            "    accuracy                           0.59      6870\n",
            "   macro avg       0.59      0.59      0.59      6870\n",
            "weighted avg       0.59      0.59      0.58      6870\n",
            "\n",
            "Epoch 5/10, Training Loss: 0.8760653589721561\n",
            "Epoch 5/10, Validation Accuracy: 0.604075691411936\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.50      0.55      1956\n",
            "           1       0.57      0.65      0.61      2787\n",
            "           2       0.66      0.63      0.65      2127\n",
            "\n",
            "    accuracy                           0.60      6870\n",
            "   macro avg       0.61      0.60      0.60      6870\n",
            "weighted avg       0.61      0.60      0.60      6870\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[34], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 47\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     49\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[28], line 57\u001b[0m, in \u001b[0;36mSentimentClassifier.forward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x)  \u001b[38;5;66;03m# Apply Batch Normalization\u001b[39;00m\n\u001b[0;32m     56\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(x)\n\u001b[1;32m---> 57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1426\u001b[0m )\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from torch.optim import AdamW\n",
        "print(\"Let us Train.\")\n",
        "\n",
        "# Hyperparameter Grid\n",
        "param_grid = {\n",
        "    'hidden_size1': [256, 512],\n",
        "    'hidden_size2': [128, 256],\n",
        "    'dropout_rate': [0.2, 0.3],\n",
        "    'learning_rate': [1e-5, 2e-5],\n",
        "    'weight_decay': [1e-2, 1e-3],\n",
        "    'batch_size': [16, 32]\n",
        "}\n",
        "\n",
        "EPOCHS = 10  # Adjust as needed\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Results DataFrame\n",
        "results_df = pd.DataFrame(columns=list(param_grid.keys()) + ['val_accuracy', 'best_epoch'])\n",
        "\n",
        "# Grid Search\n",
        "for params in ParameterGrid(param_grid):\n",
        "    print(f\"Training with parameters: {params}\")\n",
        "\n",
        "    # Create data loaders with current batch size\n",
        "    trainloader = DataLoader(traindataset, batch_size=params['batch_size'], shuffle=True)\n",
        "    valloader = DataLoader(valdataset, batch_size=params['batch_size'], shuffle=False)\n",
        "\n",
        "    # Initialize model and optimizer with current hyperparameters\n",
        "    model = SentimentClassifier(768, params['hidden_size1'], params['hidden_size2'], 3, params['dropout_rate']).to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)\n",
        "\n",
        "    best_val_accuracy = 0\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0  # For calculating average training loss\n",
        "\n",
        "        for batch in trainloader:\n",
        "            inputs, labels = batch['input_ids'], batch['label']\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * inputs.size(0) # Accumulate weighted loss\n",
        "\n",
        "        avg_train_loss = total_loss / len(traindataset) # Calculate average training loss\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS}, Training Loss: {avg_train_loss}\")\n",
        "\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_predictions = []\n",
        "        val_labels = []\n",
        "        val_loss = 0 # Initialize validation loss\n",
        "        with torch.no_grad():\n",
        "            for batch in valloader:\n",
        "                inputs, labels = batch['input_ids'], batch['label']\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_predictions.extend(predicted.cpu().tolist())\n",
        "                val_labels.extend(labels.cpu().tolist())\n",
        "                loss = criterion(outputs, labels)  # Calculate loss for the batch\n",
        "                val_loss += loss.item() * inputs.size(0) # Accumulate weighted loss\n",
        "\n",
        "\n",
        "        avg_val_loss = val_loss / len(valdataset)  # Average validation loss\n",
        "        accuracy = accuracy_score(val_labels, val_predictions)\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS}, Validation Accuracy: {accuracy}\")\n",
        "        print(classification_report(val_labels, val_predictions))\n",
        "\n",
        "        # Update best accuracy and epoch\n",
        "        if accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = accuracy\n",
        "            best_epoch = epoch + 1\n",
        "\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "    # Store results\n",
        "    new_row = params.copy()\n",
        "    new_row['val_accuracy'] = best_val_accuracy\n",
        "    new_row['best_epoch'] = best_epoch\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "# Print and save results\n",
        "print(\"\\nHyperparameter Tuning Results:\")\n",
        "print(results_df)\n",
        "results_df.to_csv(\"hyperparameter_tuning_results.csv\", index=False)\n",
        "\n",
        "# Train the best model on the full training set (train + val) and evaluate on the test set\n",
        "best_params = results_df.loc[results_df['val_accuracy'].idxmax()].to_dict()\n",
        "\n",
        "# Combine train and validation data\n",
        "train_embeddings_combined = torch.cat([train_embeddings, val_embeddings], dim=0)\n",
        "train_labels_combined = train_y + val_y # Assuming train_y and val_y are lists\n",
        "\n",
        "combined_dataset = EmbeddingDataset(train_embeddings_combined, train_labels_combined)\n",
        "combined_loader = DataLoader(combined_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
        "\n",
        "# Initialize the best model\n",
        "best_model = SentimentClassifier(768, best_params['hidden_size1'], best_params['hidden_size2'], 3, best_params['dropout_rate']).to(device)\n",
        "optimizer = AdamW(best_model.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
        "\n",
        "# Train the best model on the combined data\n",
        "for epoch in range(EPOCHS):\n",
        "    # Training loop (using your train function with combined_loader)\n",
        "    train_loss = train(best_model, combined_loader, optimizer, epoch)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Training Loss: {train_loss}\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "testdataset = EmbeddingDataset(test_embeddings, test_y)\n",
        "testloader = DataLoader(testdataset, batch_size=best_params['batch_size'], shuffle=False)\n",
        "test_loss, test_accuracy = test(best_model, testloader, epoch) # Assuming you have a test function\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUgqW43GU6ne"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:28:24.157868Z",
          "iopub.status.busy": "2024-09-12T08:28:24.157398Z",
          "iopub.status.idle": "2024-09-12T08:28:24.285993Z",
          "shell.execute_reply": "2024-09-12T08:28:24.284901Z",
          "shell.execute_reply.started": "2024-09-12T08:28:24.157825Z"
        },
        "id": "s8_Iuj66dBip",
        "outputId": "c4b9ca89-fb80-4c58-de6a-fb78c24d52fe",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== \n",
            "Test set = \n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 6.7745 Acc@1: 48.50%\n",
            "==================== \n"
          ]
        }
      ],
      "source": [
        "testdataset = TextDataset(test_x,test_y, tokenizer, MAX_LENGTH)\n",
        "testloader = DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "bert = BertModel.from_pretrained(PRETRAINED_MODEL).to(device)\n",
        "# Extract embeddings\n",
        "\n",
        "test_embeddings = extract_embeddings(bert, testloader, device)\n",
        "test_embeddings =test_embeddings.cpu()\n",
        "print('==================== ')\n",
        "print('Test set = ')\n",
        "testdataset = EmbeddingDataset(test_embeddings, test_y)\n",
        "testdataset = DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loss,accu = test(model, testdataset,epoch)\n",
        "print('==================== ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkD2ubONd_R2"
      },
      "source": [
        "## Questions\n",
        "\n",
        "**q0/  please analyse the dataset with differents classical machine learning model**\n",
        "\n",
        "**q1/  please perform a classification with differents classical machine learning model and analyse the performences**\n",
        "\n",
        "**q2/  please perform a classification with a MLP?**\n",
        "\n",
        "**q3/  please analyse all the performences and explain which is the best**\n",
        "\n",
        "**q4/  please use an LLM compare your performences to a LLM**\n",
        "\n",
        "**q5/  please explain why I choose a BERT embedding instead of the raw text**\n",
        "\n",
        "**q6/  please read the BERT paper and explain the BERT architecture**\n",
        "\n",
        "**q7/  please finetue with LORA an LLM to classify the sentiment (optional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of KNN model is : 0.46066779852857953\n"
          ]
        }
      ],
      "source": [
        "## KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Elbow method to find the best K\n",
        "k_range = range(1, 10)\n",
        "scores = []\n",
        "for k in k_range:\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn_model.fit(train_embeddings, train_y)\n",
        "    knn_predictions = knn_model.predict(val_embeddings)\n",
        "    scores.append(accuracy_score(val_y, knn_predictions))\n",
        "plt.plot(k_range, scores)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Accuracy Scores for Values of K of K-Nearest-Neighbors')\n",
        "plt.show()\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(train_embeddings, train_y)\n",
        "yhat = knn_model.predict(test_embeddings)\n",
        "print('Accuracy of KNN model is :',accuracy_score(test_y, yhat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUIRWJllOee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (newton-cg) Accuracy: 0.64\n",
            "Logistic Regression (lbfgs) Accuracy: 0.64\n",
            "Logistic Regression (sag) Accuracy: 0.64\n"
          ]
        }
      ],
      "source": [
        "## QUESTION 0 and 1 :\n",
        "import sklearn\n",
        "## LOGISTIC REGRESSION\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "for solver in ['newton-cg', 'lbfgs', 'sag', 'saga']:\n",
        "    logistic_model = LogisticRegression(max_iter=1000, solver=solver,C=10, random_state=42)\n",
        "    logistic_model.fit(train_embeddings, train_y)\n",
        "    logistic_predictions = logistic_model.predict(val_embeddings)\n",
        "    logistic_accuracy = accuracy_score(val_y, logistic_predictions)\n",
        "    print(f'Logistic Regression ({solver}) Accuracy: {logistic_accuracy:.2f}')\n",
        "    yhat = logistic_model.predict(test_embeddings)\n",
        "    acc = accuracy_score(test_y, yhat)\n",
        "    print(f'Logistic Regression ({solver}) Accuracy: {acc:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Validation Accuracy: 0.42\n",
            "Decision Tree Test Accuracy: 0.42\n"
          ]
        }
      ],
      "source": [
        "## DECISION TREE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree_model.fit(train_embeddings, train_y)\n",
        "decision_tree_predictions = decision_tree_model.predict(val_embeddings)\n",
        "decision_tree_accuracy = accuracy_score(val_y, decision_tree_predictions)\n",
        "print(f'Decision Tree Validation Accuracy: {decision_tree_accuracy:.2f}')\n",
        "yhat = decision_tree_model.predict(test_embeddings)\n",
        "acc = accuracy_score(test_y, yhat)\n",
        "print(f'Decision Tree Test Accuracy: {acc:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Validation Accuracy: 0.54\n",
            "Random Forest Test Accuracy: 0.55\n"
          ]
        }
      ],
      "source": [
        "## RANDOM FOREST\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest_model = RandomForestClassifier(random_state=42, n_estimators=100,)\n",
        "random_forest_model.fit(train_embeddings, train_y)\n",
        "random_forest_predictions = random_forest_model.predict(val_embeddings)\n",
        "random_forest_accuracy = accuracy_score(val_y, random_forest_predictions)\n",
        "print(f'Random Forest Validation Accuracy: {random_forest_accuracy:.2f}')\n",
        "yhat = random_forest_model.predict(test_embeddings)\n",
        "acc = accuracy_score(test_y, yhat)\n",
        "print(f'Random Forest Test Accuracy: {acc:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM (linear, C=0.1) Validation Accuracy: 0.63\n",
            "SVM (linear, C=0.1) Test Accuracy: 0.64\n",
            "SVM (linear, C=1) Validation Accuracy: 0.65\n",
            "SVM (linear, C=1) Test Accuracy: 0.65\n"
          ]
        }
      ],
      "source": [
        "## SVM with parameters and hyperparameters\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
        "    for C in [0.1, 1, 10]:\n",
        "        svm_model = SVC(kernel=kernel, C=C, random_state=42)\n",
        "        svm_model.fit(train_embeddings, train_y)\n",
        "        svm_predictions = svm_model.predict(val_embeddings)\n",
        "        svm_accuracy = accuracy_score(val_y, svm_predictions)\n",
        "        print(f'SVM ({kernel}, C={C}) Validation Accuracy: {svm_accuracy:.2f}')\n",
        "        yhat = svm_model.predict(test_embeddings)\n",
        "        acc = accuracy_score(test_y, yhat)\n",
        "        print(f'SVM ({kernel}, C={C}) Test Accuracy: {acc:.2f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Validation Accuracy: 0.4473\n",
            "Epoch 2/10, Validation Accuracy: 0.3728\n",
            "Epoch 3/10, Validation Accuracy: 0.4437\n",
            "Epoch 4/10, Validation Accuracy: 0.5361\n",
            "Epoch 5/10, Validation Accuracy: 0.5876\n",
            "Epoch 6/10, Validation Accuracy: 0.4028\n",
            "Epoch 7/10, Validation Accuracy: 0.5907\n",
            "Epoch 8/10, Validation Accuracy: 0.6044\n",
            "Epoch 9/10, Validation Accuracy: 0.5951\n",
            "Epoch 10/10, Validation Accuracy: 0.4611\n",
            "Test Accuracy: 0.4595\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.15      0.25      1001\n",
            "           1       0.54      0.32      0.40      1430\n",
            "           2       0.41      0.93      0.57      1103\n",
            "\n",
            "    accuracy                           0.46      3534\n",
            "   macro avg       0.58      0.46      0.40      3534\n",
            "weighted avg       0.57      0.46      0.41      3534\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Assuming you have these already:\n",
        "# train_embeddings  (Tensor)\n",
        "# train_y          (List or numpy array)\n",
        "# val_embeddings    (Tensor)\n",
        "# val_y            (List or numpy array)\n",
        "# test_embeddings   (Tensor)\n",
        "# test_y           (List or numpy array)\n",
        "# NUM_CLASSES      (int, the number of sentiment classes)\n",
        "# device           (torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# 1. Create TensorDatasets and DataLoaders\n",
        "train_dataset = TensorDataset(train_embeddings, torch.tensor(train_y, dtype=torch.long))\n",
        "val_dataset = TensorDataset(val_embeddings, torch.tensor(val_y, dtype=torch.long))\n",
        "test_dataset = TensorDataset(test_embeddings, torch.tensor(test_y, dtype=torch.long))\n",
        "\n",
        "BATCH_SIZE = 128  # Adjust as needed\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "# 2. Define the MLP Model\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "input_size = train_embeddings.shape[1]\n",
        "hidden_size = 512  # Experiment with this value\n",
        "mlp_model = MLPClassifier(input_size, hidden_size, NUM_CLASSES).to(device)\n",
        "\n",
        "\n",
        "# 3. Training Loop\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=1e-3)  # Adjust learning rate\n",
        "\n",
        "EPOCHS = 10  # Adjust as needed\n",
        "for epoch in range(EPOCHS):\n",
        "    for batch in train_loader:\n",
        "        embeddings, labels = batch\n",
        "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = mlp_model(embeddings)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        val_predictions = []\n",
        "        for batch in val_loader:\n",
        "            embeddings, labels = batch\n",
        "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
        "            outputs = mlp_model(embeddings)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_predictions.extend(predicted.cpu().numpy())\n",
        "        val_accuracy = accuracy_score(val_y, val_predictions)\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# 4. Evaluation on Test Set\n",
        "with torch.no_grad():\n",
        "    test_predictions = []\n",
        "    for batch in test_loader:\n",
        "        embeddings, labels = batch\n",
        "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
        "        outputs = mlp_model(embeddings)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_predictions.extend(predicted.cpu().numpy())\n",
        "    test_accuracy = accuracy_score(test_y, test_predictions)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "    print(classification_report(test_y, test_predictions)) # Detailed report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "100%|██████████| 442/442 [04:28<00:00,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.50      0.91      0.64      1000\n",
            "     neutral       0.78      0.06      0.11      1428\n",
            "    positive       0.58      0.85      0.69      1103\n",
            "\n",
            "    accuracy                           0.55      3531\n",
            "   macro avg       0.62      0.60      0.48      3531\n",
            "weighted avg       0.64      0.55      0.44      3531\n",
            "\n",
            "Accuracy: 0.5454545454545454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
        "\n",
        "candidate_labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "batch_size = 8  # Start with a smaller batch size; adjust as needed based on GPU memory\n",
        "\n",
        "n_samples = len(test_df['sentiment'])\n",
        "llm_predictions = [None] * n_samples\n",
        "original_labels = list(test_df['sentiment'])\n",
        "\n",
        "for i in tqdm(range(0, n_samples, batch_size)):\n",
        "    batch = test_df['processed_text'][i:i + batch_size].tolist()\n",
        "    valid_batch = [str(text).strip() for text in batch if str(text).strip()]\n",
        "\n",
        "    if valid_batch:\n",
        "        try:\n",
        "            results = classifier(valid_batch, candidate_labels)\n",
        "            for j, result in enumerate(results):\n",
        "                llm_predictions[i + j] = result['labels'][0]\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {i}: {e}\")\n",
        "            for j in range(len(batch)):\n",
        "                llm_predictions[i + j] = \"neutral\"  # Or another default value\n",
        "    else:\n",
        "        for j in range(len(batch)):\n",
        "            llm_predictions[i + j] = \"neutral\"\n",
        "\n",
        "# Filter None values\n",
        "valid_indices = [i for i, pred in enumerate(llm_predictions) if pred is not None]\n",
        "filtered_predictions = [llm_predictions[i] for i in valid_indices]\n",
        "filtered_labels = [original_labels[i] for i in valid_indices]\n",
        "\n",
        "# Evaluate\n",
        "print(classification_report(filtered_labels, filtered_predictions))\n",
        "print(\"Accuracy:\", accuracy_score(filtered_labels, filtered_predictions))\n",
        "\n",
        "# Convert to numerical labels (if needed)\n",
        "sentiment_mapping = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
        "numerical_predictions = [sentiment_mapping.get(pred, -1) for pred in filtered_predictions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example\n",
        "del results\n",
        "del valid_batch\n",
        "torch.cuda.empty_cache()  # This is important!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 989445,
          "sourceId": 1808590,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30761,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
