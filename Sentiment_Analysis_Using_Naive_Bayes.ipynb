{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malek9876/LLM-Based-Text-Classification/blob/main/Sentiment_Analysis_Using_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMQV0xV5GUQX",
        "outputId": "808358cf-d3fa-4d51-a1b6-1c70457d0df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\elyes\\anaconda3\\lib\\site-packages (25.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: kagglehub in c:\\users\\elyes\\anaconda3\\lib\\site-packages (0.3.6)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: packaging in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from kagglehub) (24.1)\n",
            "Requirement already satisfied: requests in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from kagglehub) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2024.12.14)\n",
            "Requirement already satisfied: colorama in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
            "Requirement already satisfied: pandas in c:\\users\\elyes\\anaconda3\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\elyes\\anaconda3\\lib\\site-packages (1.26.4)\n",
            "Requirement already satisfied: nltk in c:\\users\\elyes\\anaconda3\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\elyes\\anaconda3\\lib\\site-packages (1.5.1)\n",
            "Requirement already satisfied: transformers in c:\\users\\elyes\\anaconda3\\lib\\site-packages (4.48.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\elyes\\anaconda3\\lib\\site-packages (3.9.2)\n",
            "Requirement already satisfied: seaborn in c:\\users\\elyes\\anaconda3\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: click in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (0.28.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in c:\\users\\elyes\\anaconda3\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in c:\\users\\elyes\\anaconda3\\lib\\site-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\elyes\\anaconda3\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "%pip install --upgrade pip\n",
        "%pip install kagglehub\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download('abhi8923shriv/sentiment-analysis-dataset')\n",
        "\n",
        "# Install the required libraries\n",
        "%pip install pandas numpy nltk scikit-learn transformers matplotlib seaborn\n",
        "#%pip uninstall torch torchvision torchaudio -y\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WspHhyP757H4"
      },
      "source": [
        "# Sentiment Analysis on Kaggle sentiment analysis dataset\n",
        "sentiment analysis tasks on kaggle sentiment analysis dataset using simple machine learning model: Naive bayes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgtBS7we9zxF"
      },
      "source": [
        "## Including needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:36.548968Z",
          "iopub.status.busy": "2024-09-12T08:22:36.548571Z",
          "iopub.status.idle": "2024-09-12T08:22:39.953833Z",
          "shell.execute_reply": "2024-09-12T08:22:39.952412Z",
          "shell.execute_reply.started": "2024-09-12T08:22:36.548927Z"
        },
        "id": "V56eXYTz3Wi6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# --------------- MAIN LIBRARIES ------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# --------------- HELPING LIBRARIES ----------------\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ------------- Pytorch Librairies ---------------\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX8kWFB-_ou8"
      },
      "source": [
        "## Uploading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:39.957158Z",
          "iopub.status.busy": "2024-09-12T08:22:39.956494Z",
          "iopub.status.idle": "2024-09-12T08:22:39.976107Z",
          "shell.execute_reply": "2024-09-12T08:22:39.974235Z",
          "shell.execute_reply.started": "2024-09-12T08:22:39.957103Z"
        },
        "id": "K9dAjDTZBSKW",
        "outputId": "2a1964af-5ae9-4781-a91d-ffb39be37cb8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "train_dataset = path+'/train.csv'\n",
        "test_dataset = path+'/test.csv'\n",
        "\n",
        "# Check if the path exists\n",
        "print (os.path.exists(train_dataset))\n",
        "print (os.path.exists(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:39.978592Z",
          "iopub.status.busy": "2024-09-12T08:22:39.978053Z",
          "iopub.status.idle": "2024-09-12T08:22:40.231514Z",
          "shell.execute_reply": "2024-09-12T08:22:40.230228Z",
          "shell.execute_reply.started": "2024-09-12T08:22:39.978535Z"
        },
        "id": "hW9BRdvvB5-i",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "train_df = pd.read_csv(train_dataset, encoding='ISO-8859-1')\n",
        "test_df = pd.read_csv(test_dataset, encoding='ISO-8859-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.236134Z",
          "iopub.status.busy": "2024-09-12T08:22:40.234876Z",
          "iopub.status.idle": "2024-09-12T08:22:40.279444Z",
          "shell.execute_reply": "2024-09-12T08:22:40.278232Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.236076Z"
        },
        "id": "Cv2hsR9aDAkQ",
        "outputId": "d2e36aeb-3af6-413d-91a4-0e2c161d341c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment Time of Tweet Age of User  \\\n",
              "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
              "1                             Sooo SAD  negative          noon       21-30   \n",
              "2                          bullying me  negative         night       31-45   \n",
              "3                       leave me alone  negative       morning       46-60   \n",
              "4                        Sons of ****,  negative          noon       60-70   \n",
              "\n",
              "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
              "0  Afghanistan          38928346         652860.0               60  \n",
              "1      Albania           2877797          27400.0              105  \n",
              "2      Algeria          43851044        2381740.0               18  \n",
              "3      Andorra             77265            470.0              164  \n",
              "4       Angola          32866272        1246700.0               26  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLHgZmS_KaeW"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.282164Z",
          "iopub.status.busy": "2024-09-12T08:22:40.281383Z",
          "iopub.status.idle": "2024-09-12T08:22:40.337247Z",
          "shell.execute_reply": "2024-09-12T08:22:40.335825Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.282119Z"
        },
        "id": "lQTMOPxnWhs7",
        "outputId": "5595146d-2358-4289-f2bc-c087a7e39b76",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27481 entries, 0 to 27480\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            27481 non-null  object \n",
            " 1   text              27480 non-null  object \n",
            " 2   selected_text     27480 non-null  object \n",
            " 3   sentiment         27481 non-null  object \n",
            " 4   Time of Tweet     27481 non-null  object \n",
            " 5   Age of User       27481 non-null  object \n",
            " 6   Country           27481 non-null  object \n",
            " 7   Population -2020  27481 non-null  int64  \n",
            " 8   Land Area (Km²)   27481 non-null  float64\n",
            " 9   Density (P/Km²)   27481 non-null  int64  \n",
            "dtypes: float64(1), int64(2), object(7)\n",
            "memory usage: 2.1+ MB\n"
          ]
        }
      ],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.340796Z",
          "iopub.status.busy": "2024-09-12T08:22:40.340393Z",
          "iopub.status.idle": "2024-09-12T08:22:40.358799Z",
          "shell.execute_reply": "2024-09-12T08:22:40.357343Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.340755Z"
        },
        "id": "GmpjaoKBWluP",
        "outputId": "2143527c-74cd-4a50-f732-82d04cd4fdb2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4815 entries, 0 to 4814\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            3534 non-null   object \n",
            " 1   text              3534 non-null   object \n",
            " 2   sentiment         3534 non-null   object \n",
            " 3   Time of Tweet     3534 non-null   object \n",
            " 4   Age of User       3534 non-null   object \n",
            " 5   Country           3534 non-null   object \n",
            " 6   Population -2020  3534 non-null   float64\n",
            " 7   Land Area (Km²)   3534 non-null   float64\n",
            " 8   Density (P/Km²)   3534 non-null   float64\n",
            "dtypes: float64(3), object(6)\n",
            "memory usage: 338.7+ KB\n"
          ]
        }
      ],
      "source": [
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U95kjy7kKgIC"
      },
      "source": [
        "#### Handling null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.360843Z",
          "iopub.status.busy": "2024-09-12T08:22:40.360383Z",
          "iopub.status.idle": "2024-09-12T08:22:40.402343Z",
          "shell.execute_reply": "2024-09-12T08:22:40.401081Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.36079Z"
        },
        "id": "RaWIiyJWKeUd",
        "outputId": "6c61868f-1cf3-4f01-b690-d9f168cb98cc",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                1\n",
              "selected_text       1\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.404817Z",
          "iopub.status.busy": "2024-09-12T08:22:40.404388Z",
          "iopub.status.idle": "2024-09-12T08:22:40.465463Z",
          "shell.execute_reply": "2024-09-12T08:22:40.463998Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.404776Z"
        },
        "id": "_5ZDZQ73Kydz",
        "outputId": "a31675d6-563d-4ac8-be41-3b6fd77cfa95",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                0\n",
              "selected_text       0\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = train_df.dropna()\n",
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.467344Z",
          "iopub.status.busy": "2024-09-12T08:22:40.466939Z",
          "iopub.status.idle": "2024-09-12T08:22:40.481329Z",
          "shell.execute_reply": "2024-09-12T08:22:40.479919Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.4673Z"
        },
        "id": "x5nimN6_WGRR",
        "outputId": "3eee7f0a-83e3-492f-bcf0-f3edd602ab4c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              1281\n",
              "text                1281\n",
              "sentiment           1281\n",
              "Time of Tweet       1281\n",
              "Age of User         1281\n",
              "Country             1281\n",
              "Population -2020    1281\n",
              "Land Area (Km²)     1281\n",
              "Density (P/Km²)     1281\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.487599Z",
          "iopub.status.busy": "2024-09-12T08:22:40.486547Z",
          "iopub.status.idle": "2024-09-12T08:22:40.507416Z",
          "shell.execute_reply": "2024-09-12T08:22:40.506177Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.487539Z"
        },
        "id": "A3hqNN4GWP9J",
        "outputId": "d37c315f-eccb-42f3-9563-941610c401d5",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                0\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOgrqQewLCdw"
      },
      "source": [
        "#### Removing stopwords & lowercase all text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.509448Z",
          "iopub.status.busy": "2024-09-12T08:22:40.508972Z",
          "iopub.status.idle": "2024-09-12T08:22:40.598748Z",
          "shell.execute_reply": "2024-09-12T08:22:40.597069Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.509394Z"
        },
        "id": "Qpsxd4BWNHJO",
        "outputId": "f1abd31d-5bd5-4b9f-de18-4cb44ce81a10",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\elyes\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.601099Z",
          "iopub.status.busy": "2024-09-12T08:22:40.600609Z",
          "iopub.status.idle": "2024-09-12T08:22:40.609951Z",
          "shell.execute_reply": "2024-09-12T08:22:40.608024Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.601044Z"
        },
        "id": "GyCFZy2FOZ0u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Text preprocessing function that removes stopwords and convert text to lowercase\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.611901Z",
          "iopub.status.busy": "2024-09-12T08:22:40.611511Z",
          "iopub.status.idle": "2024-09-12T08:22:45.335514Z",
          "shell.execute_reply": "2024-09-12T08:22:45.334329Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.611861Z"
        },
        "id": "6Rd5y7pkOyXz",
        "outputId": "e9b5306f-5c8d-46c9-fa42-c4856f39cf98",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing on train dataset\n",
        "train_df['processed_text'] = train_df['text'].apply(preprocess_text)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:45.337762Z",
          "iopub.status.busy": "2024-09-12T08:22:45.337232Z",
          "iopub.status.idle": "2024-09-12T08:22:45.959644Z",
          "shell.execute_reply": "2024-09-12T08:22:45.958512Z",
          "shell.execute_reply.started": "2024-09-12T08:22:45.337709Z"
        },
        "id": "2Vpcp2FVXXVQ",
        "outputId": "c6770cf5-f897-410a-b6ae-7df5bd9181a2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f87dea47db</td>\n",
              "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346.0</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>last session day http://twitpic.com/67ezh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96d74cb729</td>\n",
              "      <td>Shanghai is also really exciting (precisely -...</td>\n",
              "      <td>positive</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797.0</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>shanghai also really exciting (precisely -- sk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eee518ae67</td>\n",
              "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044.0</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>recession hit veronique branquinho, quit compa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01082688c6</td>\n",
              "      <td>happy bday!</td>\n",
              "      <td>positive</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265.0</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>happy bday!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33987a8ee5</td>\n",
              "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
              "      <td>positive</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272.0</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>http://twitpic.com/4w75p - like it!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text sentiment  \\\n",
              "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
              "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
              "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
              "3  01082688c6                                        happy bday!  positive   \n",
              "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
              "\n",
              "  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n",
              "0       morning        0-20  Afghanistan        38928346.0         652860.0   \n",
              "1          noon       21-30      Albania         2877797.0          27400.0   \n",
              "2         night       31-45      Algeria        43851044.0        2381740.0   \n",
              "3       morning       46-60      Andorra           77265.0            470.0   \n",
              "4          noon       60-70       Angola        32866272.0        1246700.0   \n",
              "\n",
              "   Density (P/Km²)                                     processed_text  \n",
              "0             60.0          last session day http://twitpic.com/67ezh  \n",
              "1            105.0  shanghai also really exciting (precisely -- sk...  \n",
              "2             18.0  recession hit veronique branquinho, quit compa...  \n",
              "3            164.0                                        happy bday!  \n",
              "4             26.0               http://twitpic.com/4w75p - like it!!  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply preprocessing on test dataset\n",
        "test_df['processed_text'] = test_df['text'].apply(preprocess_text)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9FZF-S6RwT0"
      },
      "source": [
        "## Check Imbalancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:27:19.351826Z",
          "iopub.status.busy": "2024-09-12T08:27:19.351335Z",
          "iopub.status.idle": "2024-09-12T08:27:19.610508Z",
          "shell.execute_reply": "2024-09-12T08:27:19.609354Z",
          "shell.execute_reply.started": "2024-09-12T08:27:19.351775Z"
        },
        "id": "uRP-7dXHUcgb",
        "outputId": "c55e8422-deb7-49b4-b029-1d1d3a550c50",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Distribution of sentiment labels\n",
        "sns.countplot(x='sentiment', data=train_df)\n",
        "plt.title(\"Distribution of Sentiment Labels\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ppFEsZZXIW75"
      },
      "outputs": [],
      "source": [
        "# 1. Transform sentiment into 3 classes\n",
        "# Example mapping: positive -> 2, neutral -> 1, negative -> 0\n",
        "sentiment_mapping = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
        "train_df[\"sentiment_class\"] = train_df[\"sentiment\"].map(sentiment_mapping)\n",
        "test_df[\"sentiment_class\"] = test_df[\"sentiment\"].map(sentiment_mapping)\n",
        "\n",
        "# 2. Extract all the values from the 'processed_text' column into a list\n",
        "trainval_x = train_df[\"processed_text\"].tolist()\n",
        "trainval_y = train_df[\"sentiment_class\"].tolist()\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(trainval_x, trainval_y, test_size=0.25, random_state=42)\n",
        "\n",
        "test_x = test_df[\"processed_text\"].tolist()\n",
        "test_y = test_df[\"sentiment_class\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGje1w01rjlw",
        "outputId": "862fa31c-ba1a-4f4d-ce50-676b87f2b2a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27480 6870 3534\n"
          ]
        }
      ],
      "source": [
        "print(len(trainval_x),len(val_x),len(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "meidY0NVsChh"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "PRETRAINED_MODEL = \"bert-base-uncased\"\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "EPOCHS = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Custom Dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of sentiment labels (e.g., 0, 1).\n",
        "            tokenizer (transformers.BertTokenizer): Tokenizer for BERT.\n",
        "            max_length (int): Maximum length for tokenized sequences.\n",
        "        \"\"\"\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and encode the text\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Extract embeddings for all data\n",
        "def extract_embeddings(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Extracts embeddings for all data using a pre-trained BERT model.\n",
        "\n",
        "    Args:\n",
        "        model (transformers.BertModel): Pre-trained BERT model.\n",
        "        dataloader (DataLoader): DataLoader for the dataset.\n",
        "        device (torch.device): Device to run the model on (CPU or GPU).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A matrix of size (number_of_samples, embedding_size).\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    embeddings = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            # Forward pass through BERT\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            pooled_output = outputs.pooler_output  # CLS token representation\n",
        "\n",
        "            # Append embeddings to the list\n",
        "            embeddings.append(pooled_output.cpu())\n",
        "\n",
        "    # Combine all embeddings into a single matrix\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "# Initialize tokenizer, dataset, and dataloader\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
        "traindataset = TextDataset(train_x, train_y, tokenizer, MAX_LENGTH)\n",
        "trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "valdataset = TextDataset(val_x, val_y, tokenizer, MAX_LENGTH)\n",
        "valloader = DataLoader(valdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "bert = BertModel.from_pretrained(PRETRAINED_MODEL).to(device)\n",
        "# Extract embeddings\n",
        "train_embeddings = extract_embeddings(bert, trainloader, device)\n",
        "train_embeddings =train_embeddings.cpu()\n",
        "\n",
        "val_embeddings = extract_embeddings(bert, valloader, device)\n",
        "val_embeddings =val_embeddings.cpu()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWzk4bUcvX03",
        "outputId": "a905e572-cd4f-4db6-9117-16f9e062d890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20610, 768])\n",
            "torch.Size([6870, 768])\n"
          ]
        }
      ],
      "source": [
        "print(train_embeddings.size())\n",
        "print(val_embeddings.size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lHR_N9OiwgYL"
      },
      "outputs": [],
      "source": [
        "criterion= nn.CrossEntropyLoss()\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "# Custom Dataset\n",
        "class EmbeddingDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of sentiment labels (e.g., 0, 1).\n",
        "            tokenizer (transformers.BertTokenizer): Tokenizer for BERT.\n",
        "            max_length (int): Maximum length for tokenized sequences.\n",
        "        \"\"\"\n",
        "        self.embeddings = embeddings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and encode the text\n",
        "        embeddings = self.embeddings[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": embeddings.squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Model Definition\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "\n",
        "        # Fully connected layer for classification\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "\n",
        "        # Pass through the fully connected layer\n",
        "        logits = self.fc(input_ids)\n",
        "        return logits\n",
        "\n",
        "# training script\n",
        "\n",
        "def train( model, train_loader, optimizer, epoch,log_interval=50):\n",
        "    model.train()\n",
        "    loss_cpu=0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, target = data['input_ids'],data['label']\n",
        "        inputs, target = inputs.cuda(), target.cuda()\n",
        "        inputs =inputs.detach()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        loss_cpu+= loss.item()\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
        "                %(epoch, EPOCHS, batch_idx+1,\n",
        "                    (len(train_loader)//BATCH_SIZE)+1, loss.item(), 100.*correct/total))\n",
        "            #n_iter=epoch * len(train_loader) + batch_idx\n",
        "\n",
        "    return loss_cpu/len(train_loader)\n",
        "\n",
        "# testing script\n",
        "def test( model, test_loader,epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss_MSE =0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(test_loader, 0):\n",
        "            inputs, target = data['input_ids'],data['label']\n",
        "            inputs, target = inputs.cuda(), target.cuda()\n",
        "            outputs  = model(inputs)\n",
        "            loss = criterion(outputs,target)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target.data).cpu().sum()\n",
        "            test_loss_MSE+= loss.item()\n",
        "\n",
        "    test_loss_MSE = test_loss_MSE/ len(test_loader)\n",
        "    print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), 100.*correct/total))\n",
        "    return test_loss_MSE, 100.*correct/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def __getitem__(self, idx):\n",
        "    text = self.texts[idx]\n",
        "    encoding = self.tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=self.max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    return {\n",
        "        \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "        \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "        \"label\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0X6VeclzYro",
        "outputId": "1d64bacd-dc0d-42b0-a915-387380137513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let us Train.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3/ training model 1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "| Epoch [  0/ 50] Iter[  1/  6]\t\tLoss: 1.1099 Acc@1: 43.750%\n",
            "| Epoch [  0/ 50] Iter[ 51/  6]\t\tLoss: 5.5732 Acc@1: 35.876%\n",
            "| Epoch [  0/ 50] Iter[101/  6]\t\tLoss: 18.7418 Acc@1: 34.653%\n",
            "| Epoch [  0/ 50] Iter[151/  6]\t\tLoss: 16.8084 Acc@1: 34.127%\n",
            "| Epoch [  0/ 50] Iter[201/  6]\t\tLoss: 33.0875 Acc@1: 35.813%\n",
            "| Epoch [  0/ 50] Iter[251/  6]\t\tLoss: 21.3532 Acc@1: 35.371%\n",
            "| Epoch [  0/ 50] Iter[301/  6]\t\tLoss: 29.4919 Acc@1: 34.396%\n",
            "\n",
            "| Validation Epoch #0\t\t\tLoss: 39.3741 Acc@1: 30.99%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 39.305991102147985 for epoch : 0 ERROR TEST =  (39.305991102147985, tensor(30.9898))\n",
            "| Epoch [  1/ 50] Iter[  1/  6]\t\tLoss: 36.4442 Acc@1: 35.938%\n",
            "| Epoch [  1/ 50] Iter[ 51/  6]\t\tLoss: 29.8762 Acc@1: 33.150%\n",
            "| Epoch [  1/ 50] Iter[101/  6]\t\tLoss: 39.2728 Acc@1: 36.479%\n",
            "| Epoch [  1/ 50] Iter[151/  6]\t\tLoss: 42.8253 Acc@1: 37.645%\n",
            "| Epoch [  1/ 50] Iter[201/  6]\t\tLoss: 42.2562 Acc@1: 37.904%\n",
            "| Epoch [  1/ 50] Iter[251/  6]\t\tLoss: 53.6080 Acc@1: 36.261%\n",
            "| Epoch [  1/ 50] Iter[301/  6]\t\tLoss: 34.5226 Acc@1: 34.884%\n",
            "\n",
            "| Validation Epoch #1\t\t\tLoss: 14.6497 Acc@1: 30.07%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 12.165452453825209 for epoch : 1 ERROR TEST =  (12.165452453825209, tensor(30.0728))\n",
            "| Epoch [  2/ 50] Iter[  1/  6]\t\tLoss: 11.7647 Acc@1: 34.375%\n",
            "| Epoch [  2/ 50] Iter[ 51/  6]\t\tLoss: 25.2622 Acc@1: 37.163%\n",
            "| Epoch [  2/ 50] Iter[101/  6]\t\tLoss: 43.0764 Acc@1: 38.552%\n",
            "| Epoch [  2/ 50] Iter[151/  6]\t\tLoss: 36.8439 Acc@1: 39.456%\n",
            "| Epoch [  2/ 50] Iter[201/  6]\t\tLoss: 69.0184 Acc@1: 39.731%\n",
            "| Epoch [  2/ 50] Iter[251/  6]\t\tLoss: 65.0131 Acc@1: 38.141%\n",
            "| Epoch [  2/ 50] Iter[301/  6]\t\tLoss: 42.3899 Acc@1: 37.464%\n",
            "\n",
            "| Validation Epoch #2\t\t\tLoss: 44.4972 Acc@1: 40.86%\n",
            "lr = 0.001\n",
            "| Epoch [  3/ 50] Iter[  1/  6]\t\tLoss: 64.3588 Acc@1: 42.188%\n",
            "| Epoch [  3/ 50] Iter[ 51/  6]\t\tLoss: 62.2912 Acc@1: 40.931%\n",
            "| Epoch [  3/ 50] Iter[101/  6]\t\tLoss: 33.5376 Acc@1: 41.012%\n",
            "| Epoch [  3/ 50] Iter[151/  6]\t\tLoss: 10.7225 Acc@1: 40.284%\n",
            "| Epoch [  3/ 50] Iter[201/  6]\t\tLoss: 36.4208 Acc@1: 38.441%\n",
            "| Epoch [  3/ 50] Iter[251/  6]\t\tLoss: 65.9794 Acc@1: 36.653%\n",
            "| Epoch [  3/ 50] Iter[301/  6]\t\tLoss: 63.5896 Acc@1: 35.294%\n",
            "\n",
            "| Validation Epoch #3\t\t\tLoss: 52.9068 Acc@1: 34.69%\n",
            "lr = 0.001\n",
            "| Epoch [  4/ 50] Iter[  1/  6]\t\tLoss: 55.8731 Acc@1: 35.938%\n",
            "| Epoch [  4/ 50] Iter[ 51/  6]\t\tLoss: 68.5821 Acc@1: 33.946%\n",
            "| Epoch [  4/ 50] Iter[101/  6]\t\tLoss: 67.3317 Acc@1: 32.658%\n",
            "| Epoch [  4/ 50] Iter[151/  6]\t\tLoss: 36.7118 Acc@1: 31.809%\n",
            "| Epoch [  4/ 50] Iter[201/  6]\t\tLoss: 18.7142 Acc@1: 33.411%\n",
            "| Epoch [  4/ 50] Iter[251/  6]\t\tLoss: 44.6914 Acc@1: 34.991%\n",
            "| Epoch [  4/ 50] Iter[301/  6]\t\tLoss: 70.3227 Acc@1: 35.673%\n",
            "\n",
            "| Validation Epoch #4\t\t\tLoss: 39.6271 Acc@1: 40.54%\n",
            "lr = 0.001\n",
            "| Epoch [  5/ 50] Iter[  1/  6]\t\tLoss: 54.5842 Acc@1: 43.750%\n",
            "| Epoch [  5/ 50] Iter[ 51/  6]\t\tLoss: 63.4436 Acc@1: 42.249%\n",
            "| Epoch [  5/ 50] Iter[101/  6]\t\tLoss: 72.2279 Acc@1: 37.268%\n",
            "| Epoch [  5/ 50] Iter[151/  6]\t\tLoss: 101.2113 Acc@1: 34.582%\n",
            "| Epoch [  5/ 50] Iter[201/  6]\t\tLoss: 52.5147 Acc@1: 33.162%\n",
            "| Epoch [  5/ 50] Iter[251/  6]\t\tLoss: 36.5683 Acc@1: 33.784%\n",
            "| Epoch [  5/ 50] Iter[301/  6]\t\tLoss: 38.2861 Acc@1: 34.988%\n",
            "\n",
            "| Validation Epoch #5\t\t\tLoss: 42.0612 Acc@1: 40.52%\n",
            "lr = 0.001\n",
            "| Epoch [  6/ 50] Iter[  1/  6]\t\tLoss: 40.6590 Acc@1: 48.438%\n",
            "| Epoch [  6/ 50] Iter[ 51/  6]\t\tLoss: 38.3216 Acc@1: 41.054%\n",
            "| Epoch [  6/ 50] Iter[101/  6]\t\tLoss: 41.9521 Acc@1: 40.780%\n",
            "| Epoch [  6/ 50] Iter[151/  6]\t\tLoss: 85.8877 Acc@1: 38.235%\n",
            "| Epoch [  6/ 50] Iter[201/  6]\t\tLoss: 76.9064 Acc@1: 37.228%\n",
            "| Epoch [  6/ 50] Iter[251/  6]\t\tLoss: 98.7839 Acc@1: 36.155%\n",
            "| Epoch [  6/ 50] Iter[301/  6]\t\tLoss: 70.4342 Acc@1: 35.465%\n",
            "\n",
            "| Validation Epoch #6\t\t\tLoss: 64.3023 Acc@1: 32.49%\n",
            "lr = 0.001\n",
            "| Epoch [  7/ 50] Iter[  1/  6]\t\tLoss: 58.6014 Acc@1: 29.688%\n",
            "| Epoch [  7/ 50] Iter[ 51/  6]\t\tLoss: 16.5126 Acc@1: 34.620%\n",
            "| Epoch [  7/ 50] Iter[101/  6]\t\tLoss: 19.0946 Acc@1: 38.815%\n",
            "| Epoch [  7/ 50] Iter[151/  6]\t\tLoss: 36.2276 Acc@1: 39.870%\n",
            "| Epoch [  7/ 50] Iter[201/  6]\t\tLoss: 68.7238 Acc@1: 39.490%\n",
            "| Epoch [  7/ 50] Iter[251/  6]\t\tLoss: 65.9128 Acc@1: 37.525%\n",
            "| Epoch [  7/ 50] Iter[301/  6]\t\tLoss: 87.3901 Acc@1: 36.285%\n",
            "\n",
            "| Validation Epoch #7\t\t\tLoss: 100.7043 Acc@1: 41.57%\n",
            "lr = 0.001\n",
            "| Epoch [  8/ 50] Iter[  1/  6]\t\tLoss: 78.9878 Acc@1: 45.312%\n",
            "| Epoch [  8/ 50] Iter[ 51/  6]\t\tLoss: 101.4406 Acc@1: 41.115%\n",
            "| Epoch [  8/ 50] Iter[101/  6]\t\tLoss: 127.0770 Acc@1: 41.197%\n",
            "| Epoch [  8/ 50] Iter[151/  6]\t\tLoss: 97.4064 Acc@1: 40.584%\n",
            "| Epoch [  8/ 50] Iter[201/  6]\t\tLoss: 72.2684 Acc@1: 40.928%\n",
            "| Epoch [  8/ 50] Iter[251/  6]\t\tLoss: 110.8039 Acc@1: 39.181%\n",
            "| Epoch [  8/ 50] Iter[301/  6]\t\tLoss: 97.6861 Acc@1: 37.443%\n",
            "\n",
            "| Validation Epoch #8\t\t\tLoss: 45.3395 Acc@1: 28.60%\n",
            "lr = 0.001\n",
            "| Epoch [  9/ 50] Iter[  1/  6]\t\tLoss: 64.2300 Acc@1: 25.000%\n",
            "| Epoch [  9/ 50] Iter[ 51/  6]\t\tLoss: 37.9168 Acc@1: 29.320%\n",
            "| Epoch [  9/ 50] Iter[101/  6]\t\tLoss: 27.6715 Acc@1: 35.102%\n",
            "| Epoch [  9/ 50] Iter[151/  6]\t\tLoss: 23.1073 Acc@1: 37.790%\n",
            "| Epoch [  9/ 50] Iter[201/  6]\t\tLoss: 42.7737 Acc@1: 38.612%\n",
            "| Epoch [  9/ 50] Iter[251/  6]\t\tLoss: 76.7606 Acc@1: 37.126%\n",
            "| Epoch [  9/ 50] Iter[301/  6]\t\tLoss: 110.5385 Acc@1: 36.394%\n",
            "\n",
            "| Validation Epoch #9\t\t\tLoss: 105.6923 Acc@1: 30.96%\n",
            "lr = 0.0001\n",
            "| Epoch [ 10/ 50] Iter[  1/  6]\t\tLoss: 94.7488 Acc@1: 28.125%\n",
            "| Epoch [ 10/ 50] Iter[ 51/  6]\t\tLoss: 99.5192 Acc@1: 31.832%\n",
            "| Epoch [ 10/ 50] Iter[101/  6]\t\tLoss: 87.2919 Acc@1: 31.033%\n",
            "| Epoch [ 10/ 50] Iter[151/  6]\t\tLoss: 80.3050 Acc@1: 31.033%\n",
            "| Epoch [ 10/ 50] Iter[201/  6]\t\tLoss: 82.4726 Acc@1: 31.367%\n",
            "| Epoch [ 10/ 50] Iter[251/  6]\t\tLoss: 62.5035 Acc@1: 31.443%\n",
            "| Epoch [ 10/ 50] Iter[301/  6]\t\tLoss: 74.8446 Acc@1: 31.645%\n",
            "\n",
            "| Validation Epoch #10\t\t\tLoss: 77.7970 Acc@1: 32.75%\n",
            "lr = 0.0001\n",
            "| Epoch [ 11/ 50] Iter[  1/  6]\t\tLoss: 81.5168 Acc@1: 29.688%\n",
            "| Epoch [ 11/ 50] Iter[ 51/  6]\t\tLoss: 61.2872 Acc@1: 33.272%\n",
            "| Epoch [ 11/ 50] Iter[101/  6]\t\tLoss: 44.4240 Acc@1: 34.994%\n",
            "| Epoch [ 11/ 50] Iter[151/  6]\t\tLoss: 64.4740 Acc@1: 36.000%\n",
            "| Epoch [ 11/ 50] Iter[201/  6]\t\tLoss: 50.8838 Acc@1: 37.174%\n",
            "| Epoch [ 11/ 50] Iter[251/  6]\t\tLoss: 44.0346 Acc@1: 38.365%\n",
            "| Epoch [ 11/ 50] Iter[301/  6]\t\tLoss: 29.0559 Acc@1: 39.576%\n",
            "\n",
            "| Validation Epoch #11\t\t\tLoss: 49.5967 Acc@1: 46.99%\n",
            "lr = 0.0001\n",
            "| Epoch [ 12/ 50] Iter[  1/  6]\t\tLoss: 51.1734 Acc@1: 40.625%\n",
            "| Epoch [ 12/ 50] Iter[ 51/  6]\t\tLoss: 58.3143 Acc@1: 48.223%\n",
            "| Epoch [ 12/ 50] Iter[101/  6]\t\tLoss: 27.2690 Acc@1: 48.345%\n",
            "| Epoch [ 12/ 50] Iter[151/  6]\t\tLoss: 40.0986 Acc@1: 47.568%\n",
            "| Epoch [ 12/ 50] Iter[201/  6]\t\tLoss: 54.3951 Acc@1: 46.580%\n",
            "| Epoch [ 12/ 50] Iter[251/  6]\t\tLoss: 48.4322 Acc@1: 45.786%\n",
            "| Epoch [ 12/ 50] Iter[301/  6]\t\tLoss: 35.3553 Acc@1: 45.281%\n",
            "\n",
            "| Validation Epoch #12\t\t\tLoss: 31.1088 Acc@1: 42.87%\n",
            "lr = 0.0001\n",
            "| Epoch [ 13/ 50] Iter[  1/  6]\t\tLoss: 47.4476 Acc@1: 50.000%\n",
            "| Epoch [ 13/ 50] Iter[ 51/  6]\t\tLoss: 40.5523 Acc@1: 42.984%\n",
            "| Epoch [ 13/ 50] Iter[101/  6]\t\tLoss: 51.8038 Acc@1: 42.420%\n",
            "| Epoch [ 13/ 50] Iter[151/  6]\t\tLoss: 41.2604 Acc@1: 41.877%\n",
            "| Epoch [ 13/ 50] Iter[201/  6]\t\tLoss: 37.1352 Acc@1: 41.947%\n",
            "| Epoch [ 13/ 50] Iter[251/  6]\t\tLoss: 45.8294 Acc@1: 41.845%\n",
            "| Epoch [ 13/ 50] Iter[301/  6]\t\tLoss: 41.2938 Acc@1: 41.668%\n",
            "\n",
            "| Validation Epoch #13\t\t\tLoss: 58.4372 Acc@1: 41.53%\n",
            "lr = 0.0001\n",
            "| Epoch [ 14/ 50] Iter[  1/  6]\t\tLoss: 39.7017 Acc@1: 37.500%\n",
            "| Epoch [ 14/ 50] Iter[ 51/  6]\t\tLoss: 38.8734 Acc@1: 41.575%\n",
            "| Epoch [ 14/ 50] Iter[101/  6]\t\tLoss: 43.9452 Acc@1: 42.188%\n",
            "| Epoch [ 14/ 50] Iter[151/  6]\t\tLoss: 32.6008 Acc@1: 42.022%\n",
            "| Epoch [ 14/ 50] Iter[201/  6]\t\tLoss: 24.9676 Acc@1: 41.993%\n",
            "| Epoch [ 14/ 50] Iter[251/  6]\t\tLoss: 27.4453 Acc@1: 41.858%\n",
            "| Epoch [ 14/ 50] Iter[301/  6]\t\tLoss: 27.0438 Acc@1: 41.757%\n",
            "\n",
            "| Validation Epoch #14\t\t\tLoss: 27.8577 Acc@1: 43.03%\n",
            "lr = 0.0001\n",
            "| Epoch [ 15/ 50] Iter[  1/  6]\t\tLoss: 21.1787 Acc@1: 50.000%\n",
            "| Epoch [ 15/ 50] Iter[ 51/  6]\t\tLoss: 21.4721 Acc@1: 41.850%\n",
            "| Epoch [ 15/ 50] Iter[101/  6]\t\tLoss: 18.8225 Acc@1: 42.713%\n",
            "| Epoch [ 15/ 50] Iter[151/  6]\t\tLoss: 15.2853 Acc@1: 43.160%\n",
            "| Epoch [ 15/ 50] Iter[201/  6]\t\tLoss: 13.2390 Acc@1: 43.509%\n",
            "| Epoch [ 15/ 50] Iter[251/  6]\t\tLoss: 9.9124 Acc@1: 44.354%\n",
            "| Epoch [ 15/ 50] Iter[301/  6]\t\tLoss: 6.3425 Acc@1: 45.027%\n",
            "\n",
            "| Validation Epoch #15\t\t\tLoss: 2.9847 Acc@1: 49.55%\n",
            "lr = 0.0001\n",
            "Best RMSE is of : 8.558052946020055 for epoch : 15 ERROR TEST =  (8.558052946020055, tensor(49.5488))\n",
            "| Epoch [ 16/ 50] Iter[  1/  6]\t\tLoss: 7.1499 Acc@1: 51.562%\n",
            "| Epoch [ 16/ 50] Iter[ 51/  6]\t\tLoss: 8.2593 Acc@1: 50.674%\n",
            "| Epoch [ 16/ 50] Iter[101/  6]\t\tLoss: 7.1162 Acc@1: 49.768%\n",
            "| Epoch [ 16/ 50] Iter[151/  6]\t\tLoss: 7.6007 Acc@1: 49.307%\n",
            "| Epoch [ 16/ 50] Iter[201/  6]\t\tLoss: 10.2872 Acc@1: 48.111%\n",
            "| Epoch [ 16/ 50] Iter[251/  6]\t\tLoss: 16.5640 Acc@1: 46.875%\n",
            "| Epoch [ 16/ 50] Iter[301/  6]\t\tLoss: 15.4776 Acc@1: 45.406%\n",
            "\n",
            "| Validation Epoch #16\t\t\tLoss: 13.9096 Acc@1: 36.52%\n",
            "lr = 0.0001\n",
            "| Epoch [ 17/ 50] Iter[  1/  6]\t\tLoss: 18.9894 Acc@1: 34.375%\n",
            "| Epoch [ 17/ 50] Iter[ 51/  6]\t\tLoss: 22.2365 Acc@1: 36.489%\n",
            "| Epoch [ 17/ 50] Iter[101/  6]\t\tLoss: 17.4049 Acc@1: 35.814%\n",
            "| Epoch [ 17/ 50] Iter[151/  6]\t\tLoss: 27.2765 Acc@1: 34.903%\n",
            "| Epoch [ 17/ 50] Iter[201/  6]\t\tLoss: 17.4675 Acc@1: 34.429%\n",
            "| Epoch [ 17/ 50] Iter[251/  6]\t\tLoss: 27.2117 Acc@1: 33.877%\n",
            "| Epoch [ 17/ 50] Iter[301/  6]\t\tLoss: 23.4912 Acc@1: 33.804%\n",
            "\n",
            "| Validation Epoch #17\t\t\tLoss: 36.7496 Acc@1: 32.49%\n",
            "lr = 0.0001\n",
            "| Epoch [ 18/ 50] Iter[  1/  6]\t\tLoss: 26.0609 Acc@1: 29.688%\n",
            "| Epoch [ 18/ 50] Iter[ 51/  6]\t\tLoss: 32.9431 Acc@1: 32.077%\n",
            "| Epoch [ 18/ 50] Iter[101/  6]\t\tLoss: 28.3655 Acc@1: 32.658%\n",
            "| Epoch [ 18/ 50] Iter[151/  6]\t\tLoss: 27.6670 Acc@1: 32.326%\n",
            "| Epoch [ 18/ 50] Iter[201/  6]\t\tLoss: 27.5590 Acc@1: 32.525%\n",
            "| Epoch [ 18/ 50] Iter[251/  6]\t\tLoss: 30.6632 Acc@1: 32.688%\n",
            "| Epoch [ 18/ 50] Iter[301/  6]\t\tLoss: 35.2700 Acc@1: 32.812%\n",
            "\n",
            "| Validation Epoch #18\t\t\tLoss: 40.5896 Acc@1: 33.99%\n",
            "lr = 0.0001\n",
            "| Epoch [ 19/ 50] Iter[  1/  6]\t\tLoss: 28.0927 Acc@1: 37.500%\n",
            "| Epoch [ 19/ 50] Iter[ 51/  6]\t\tLoss: 32.2949 Acc@1: 34.804%\n",
            "| Epoch [ 19/ 50] Iter[101/  6]\t\tLoss: 28.4361 Acc@1: 34.081%\n",
            "| Epoch [ 19/ 50] Iter[151/  6]\t\tLoss: 41.1961 Acc@1: 34.478%\n",
            "| Epoch [ 19/ 50] Iter[201/  6]\t\tLoss: 26.9490 Acc@1: 35.207%\n",
            "| Epoch [ 19/ 50] Iter[251/  6]\t\tLoss: 30.6833 Acc@1: 35.962%\n",
            "| Epoch [ 19/ 50] Iter[301/  6]\t\tLoss: 25.7822 Acc@1: 36.576%\n",
            "\n",
            "| Validation Epoch #19\t\t\tLoss: 35.5145 Acc@1: 39.94%\n",
            "lr = 0.0001\n",
            "| Epoch [ 20/ 50] Iter[  1/  6]\t\tLoss: 26.9387 Acc@1: 37.500%\n",
            "| Epoch [ 20/ 50] Iter[ 51/  6]\t\tLoss: 24.5870 Acc@1: 40.656%\n",
            "| Epoch [ 20/ 50] Iter[101/  6]\t\tLoss: 35.1910 Acc@1: 40.532%\n",
            "| Epoch [ 20/ 50] Iter[151/  6]\t\tLoss: 25.8186 Acc@1: 41.080%\n",
            "| Epoch [ 20/ 50] Iter[201/  6]\t\tLoss: 34.6142 Acc@1: 41.356%\n",
            "| Epoch [ 20/ 50] Iter[251/  6]\t\tLoss: 31.7821 Acc@1: 41.553%\n",
            "| Epoch [ 20/ 50] Iter[301/  6]\t\tLoss: 32.6924 Acc@1: 41.404%\n",
            "\n",
            "| Validation Epoch #20\t\t\tLoss: 17.4464 Acc@1: 39.97%\n",
            "lr = 0.0001\n",
            "| Epoch [ 21/ 50] Iter[  1/  6]\t\tLoss: 36.0738 Acc@1: 31.250%\n",
            "| Epoch [ 21/ 50] Iter[ 51/  6]\t\tLoss: 23.7326 Acc@1: 38.480%\n",
            "| Epoch [ 21/ 50] Iter[101/  6]\t\tLoss: 30.9360 Acc@1: 38.490%\n",
            "| Epoch [ 21/ 50] Iter[151/  6]\t\tLoss: 28.7200 Acc@1: 38.142%\n",
            "| Epoch [ 21/ 50] Iter[201/  6]\t\tLoss: 31.3649 Acc@1: 38.161%\n",
            "| Epoch [ 21/ 50] Iter[251/  6]\t\tLoss: 31.1999 Acc@1: 37.805%\n",
            "| Epoch [ 21/ 50] Iter[301/  6]\t\tLoss: 31.5541 Acc@1: 37.448%\n",
            "\n",
            "| Validation Epoch #21\t\t\tLoss: 17.2326 Acc@1: 36.04%\n",
            "lr = 0.0001\n",
            "| Epoch [ 22/ 50] Iter[  1/  6]\t\tLoss: 29.6153 Acc@1: 34.375%\n",
            "| Epoch [ 22/ 50] Iter[ 51/  6]\t\tLoss: 27.0704 Acc@1: 36.581%\n",
            "| Epoch [ 22/ 50] Iter[101/  6]\t\tLoss: 22.8881 Acc@1: 35.288%\n",
            "| Epoch [ 22/ 50] Iter[151/  6]\t\tLoss: 22.3966 Acc@1: 35.813%\n",
            "| Epoch [ 22/ 50] Iter[201/  6]\t\tLoss: 23.3036 Acc@1: 35.844%\n",
            "| Epoch [ 22/ 50] Iter[251/  6]\t\tLoss: 21.3878 Acc@1: 36.479%\n",
            "| Epoch [ 22/ 50] Iter[301/  6]\t\tLoss: 13.4162 Acc@1: 37.261%\n",
            "\n",
            "| Validation Epoch #22\t\t\tLoss: 19.0607 Acc@1: 40.38%\n",
            "lr = 0.0001\n",
            "| Epoch [ 23/ 50] Iter[  1/  6]\t\tLoss: 16.5494 Acc@1: 39.062%\n",
            "| Epoch [ 23/ 50] Iter[ 51/  6]\t\tLoss: 14.4205 Acc@1: 42.126%\n",
            "| Epoch [ 23/ 50] Iter[101/  6]\t\tLoss: 12.0803 Acc@1: 43.394%\n",
            "| Epoch [ 23/ 50] Iter[151/  6]\t\tLoss: 12.6115 Acc@1: 44.640%\n",
            "| Epoch [ 23/ 50] Iter[201/  6]\t\tLoss: 7.2255 Acc@1: 45.320%\n",
            "| Epoch [ 23/ 50] Iter[251/  6]\t\tLoss: 9.1324 Acc@1: 46.321%\n",
            "| Epoch [ 23/ 50] Iter[301/  6]\t\tLoss: 9.7679 Acc@1: 47.124%\n",
            "\n",
            "| Validation Epoch #23\t\t\tLoss: 8.1907 Acc@1: 49.91%\n",
            "lr = 1e-05\n",
            "| Epoch [ 24/ 50] Iter[  1/  6]\t\tLoss: 10.5878 Acc@1: 45.312%\n",
            "| Epoch [ 24/ 50] Iter[ 51/  6]\t\tLoss: 6.7532 Acc@1: 50.460%\n",
            "| Epoch [ 24/ 50] Iter[101/  6]\t\tLoss: 10.7021 Acc@1: 50.820%\n",
            "| Epoch [ 24/ 50] Iter[151/  6]\t\tLoss: 8.9192 Acc@1: 50.435%\n",
            "| Epoch [ 24/ 50] Iter[201/  6]\t\tLoss: 7.2519 Acc@1: 50.179%\n",
            "| Epoch [ 24/ 50] Iter[251/  6]\t\tLoss: 12.1856 Acc@1: 50.112%\n",
            "| Epoch [ 24/ 50] Iter[301/  6]\t\tLoss: 9.2961 Acc@1: 49.922%\n",
            "\n",
            "| Validation Epoch #24\t\t\tLoss: 8.6167 Acc@1: 49.71%\n",
            "lr = 1e-05\n",
            "| Epoch [ 25/ 50] Iter[  1/  6]\t\tLoss: 6.7217 Acc@1: 64.062%\n",
            "| Epoch [ 25/ 50] Iter[ 51/  6]\t\tLoss: 8.3894 Acc@1: 49.847%\n",
            "| Epoch [ 25/ 50] Iter[101/  6]\t\tLoss: 12.1951 Acc@1: 50.170%\n",
            "| Epoch [ 25/ 50] Iter[151/  6]\t\tLoss: 7.3596 Acc@1: 50.797%\n",
            "| Epoch [ 25/ 50] Iter[201/  6]\t\tLoss: 13.3534 Acc@1: 50.218%\n",
            "| Epoch [ 25/ 50] Iter[251/  6]\t\tLoss: 8.2506 Acc@1: 50.025%\n",
            "| Epoch [ 25/ 50] Iter[301/  6]\t\tLoss: 8.5094 Acc@1: 49.782%\n",
            "\n",
            "| Validation Epoch #25\t\t\tLoss: 5.8186 Acc@1: 49.39%\n",
            "lr = 1e-05\n",
            "| Epoch [ 26/ 50] Iter[  1/  6]\t\tLoss: 9.7474 Acc@1: 42.188%\n",
            "| Epoch [ 26/ 50] Iter[ 51/  6]\t\tLoss: 8.8942 Acc@1: 50.429%\n",
            "| Epoch [ 26/ 50] Iter[101/  6]\t\tLoss: 11.4237 Acc@1: 50.309%\n",
            "| Epoch [ 26/ 50] Iter[151/  6]\t\tLoss: 10.7672 Acc@1: 50.021%\n",
            "| Epoch [ 26/ 50] Iter[201/  6]\t\tLoss: 7.2091 Acc@1: 49.642%\n",
            "| Epoch [ 26/ 50] Iter[251/  6]\t\tLoss: 12.0049 Acc@1: 49.365%\n",
            "| Epoch [ 26/ 50] Iter[301/  6]\t\tLoss: 12.2214 Acc@1: 49.336%\n",
            "\n",
            "| Validation Epoch #26\t\t\tLoss: 8.9295 Acc@1: 48.94%\n",
            "lr = 1e-05\n",
            "| Epoch [ 27/ 50] Iter[  1/  6]\t\tLoss: 8.0265 Acc@1: 54.688%\n",
            "| Epoch [ 27/ 50] Iter[ 51/  6]\t\tLoss: 10.5641 Acc@1: 47.947%\n",
            "| Epoch [ 27/ 50] Iter[101/  6]\t\tLoss: 7.6324 Acc@1: 48.345%\n",
            "| Epoch [ 27/ 50] Iter[151/  6]\t\tLoss: 9.5624 Acc@1: 48.551%\n",
            "| Epoch [ 27/ 50] Iter[201/  6]\t\tLoss: 8.3325 Acc@1: 48.780%\n",
            "| Epoch [ 27/ 50] Iter[251/  6]\t\tLoss: 7.4898 Acc@1: 49.346%\n",
            "| Epoch [ 27/ 50] Iter[301/  6]\t\tLoss: 8.2768 Acc@1: 49.294%\n",
            "\n",
            "| Validation Epoch #27\t\t\tLoss: 7.8737 Acc@1: 48.94%\n",
            "lr = 1e-05\n",
            "| Epoch [ 28/ 50] Iter[  1/  6]\t\tLoss: 11.4687 Acc@1: 43.750%\n",
            "| Epoch [ 28/ 50] Iter[ 51/  6]\t\tLoss: 8.1109 Acc@1: 49.081%\n",
            "| Epoch [ 28/ 50] Iter[101/  6]\t\tLoss: 10.8725 Acc@1: 48.871%\n",
            "| Epoch [ 28/ 50] Iter[151/  6]\t\tLoss: 11.6037 Acc@1: 49.007%\n",
            "| Epoch [ 28/ 50] Iter[201/  6]\t\tLoss: 9.2857 Acc@1: 49.293%\n",
            "| Epoch [ 28/ 50] Iter[251/  6]\t\tLoss: 8.5123 Acc@1: 49.751%\n",
            "| Epoch [ 28/ 50] Iter[301/  6]\t\tLoss: 9.0793 Acc@1: 49.460%\n",
            "\n",
            "| Validation Epoch #28\t\t\tLoss: 10.8414 Acc@1: 49.59%\n",
            "lr = 1e-05\n",
            "| Epoch [ 29/ 50] Iter[  1/  6]\t\tLoss: 9.5212 Acc@1: 45.312%\n",
            "| Epoch [ 29/ 50] Iter[ 51/  6]\t\tLoss: 11.3920 Acc@1: 50.950%\n",
            "| Epoch [ 29/ 50] Iter[101/  6]\t\tLoss: 8.8224 Acc@1: 50.449%\n",
            "| Epoch [ 29/ 50] Iter[151/  6]\t\tLoss: 10.8660 Acc@1: 49.483%\n",
            "| Epoch [ 29/ 50] Iter[201/  6]\t\tLoss: 14.1801 Acc@1: 49.534%\n",
            "| Epoch [ 29/ 50] Iter[251/  6]\t\tLoss: 6.5221 Acc@1: 49.739%\n",
            "| Epoch [ 29/ 50] Iter[301/  6]\t\tLoss: 7.7444 Acc@1: 49.839%\n",
            "\n",
            "| Validation Epoch #29\t\t\tLoss: 6.6528 Acc@1: 50.39%\n",
            "lr = 1e-05\n",
            "| Epoch [ 30/ 50] Iter[  1/  6]\t\tLoss: 7.9391 Acc@1: 56.250%\n",
            "| Epoch [ 30/ 50] Iter[ 51/  6]\t\tLoss: 10.7374 Acc@1: 50.031%\n",
            "| Epoch [ 30/ 50] Iter[101/  6]\t\tLoss: 6.8402 Acc@1: 51.129%\n",
            "| Epoch [ 30/ 50] Iter[151/  6]\t\tLoss: 8.9212 Acc@1: 51.221%\n",
            "| Epoch [ 30/ 50] Iter[201/  6]\t\tLoss: 7.7422 Acc@1: 50.793%\n",
            "| Epoch [ 30/ 50] Iter[251/  6]\t\tLoss: 9.4127 Acc@1: 50.872%\n",
            "| Epoch [ 30/ 50] Iter[301/  6]\t\tLoss: 7.3477 Acc@1: 50.810%\n",
            "\n",
            "| Validation Epoch #30\t\t\tLoss: 3.0583 Acc@1: 50.87%\n",
            "lr = 1e-05\n",
            "Best RMSE is of : 8.191218811052817 for epoch : 30 ERROR TEST =  (8.191218811052817, tensor(50.8734))\n",
            "| Epoch [ 31/ 50] Iter[  1/  6]\t\tLoss: 7.1895 Acc@1: 60.938%\n",
            "| Epoch [ 31/ 50] Iter[ 51/  6]\t\tLoss: 9.2013 Acc@1: 50.735%\n",
            "| Epoch [ 31/ 50] Iter[101/  6]\t\tLoss: 6.5206 Acc@1: 50.278%\n",
            "| Epoch [ 31/ 50] Iter[151/  6]\t\tLoss: 10.1982 Acc@1: 51.262%\n",
            "| Epoch [ 31/ 50] Iter[201/  6]\t\tLoss: 6.7288 Acc@1: 51.112%\n",
            "| Epoch [ 31/ 50] Iter[251/  6]\t\tLoss: 7.8377 Acc@1: 51.133%\n",
            "| Epoch [ 31/ 50] Iter[301/  6]\t\tLoss: 8.7176 Acc@1: 51.267%\n",
            "\n",
            "| Validation Epoch #31\t\t\tLoss: 10.2311 Acc@1: 51.22%\n",
            "lr = 1e-05\n",
            "Best RMSE is of : 7.771534107349537 for epoch : 31 ERROR TEST =  (7.771534107349537, tensor(51.2227))\n",
            "| Epoch [ 32/ 50] Iter[  1/  6]\t\tLoss: 6.1498 Acc@1: 51.562%\n",
            "| Epoch [ 32/ 50] Iter[ 51/  6]\t\tLoss: 6.9728 Acc@1: 50.980%\n",
            "| Epoch [ 32/ 50] Iter[101/  6]\t\tLoss: 7.0654 Acc@1: 51.377%\n",
            "| Epoch [ 32/ 50] Iter[151/  6]\t\tLoss: 7.4914 Acc@1: 51.738%\n",
            "| Epoch [ 32/ 50] Iter[201/  6]\t\tLoss: 8.4956 Acc@1: 51.632%\n",
            "| Epoch [ 32/ 50] Iter[251/  6]\t\tLoss: 11.2511 Acc@1: 51.762%\n",
            "| Epoch [ 32/ 50] Iter[301/  6]\t\tLoss: 6.0114 Acc@1: 51.890%\n",
            "\n",
            "| Validation Epoch #32\t\t\tLoss: 3.9844 Acc@1: 51.06%\n",
            "lr = 1e-05\n",
            "Best RMSE is of : 7.489852688930653 for epoch : 32 ERROR TEST =  (7.489852688930653, tensor(51.0626))\n",
            "| Epoch [ 33/ 50] Iter[  1/  6]\t\tLoss: 7.8978 Acc@1: 40.625%\n",
            "| Epoch [ 33/ 50] Iter[ 51/  6]\t\tLoss: 6.7563 Acc@1: 51.654%\n",
            "| Epoch [ 33/ 50] Iter[101/  6]\t\tLoss: 7.0054 Acc@1: 51.222%\n",
            "| Epoch [ 33/ 50] Iter[151/  6]\t\tLoss: 6.7769 Acc@1: 51.738%\n",
            "| Epoch [ 33/ 50] Iter[201/  6]\t\tLoss: 9.8450 Acc@1: 51.601%\n",
            "| Epoch [ 33/ 50] Iter[251/  6]\t\tLoss: 5.3769 Acc@1: 51.830%\n",
            "| Epoch [ 33/ 50] Iter[301/  6]\t\tLoss: 7.8183 Acc@1: 51.734%\n",
            "\n",
            "| Validation Epoch #33\t\t\tLoss: 9.0860 Acc@1: 50.60%\n",
            "lr = 1e-05\n",
            "Best RMSE is of : 7.4850611598403365 for epoch : 33 ERROR TEST =  (7.4850611598403365, tensor(50.5968))\n",
            "| Epoch [ 34/ 50] Iter[  1/  6]\t\tLoss: 5.7613 Acc@1: 57.812%\n",
            "| Epoch [ 34/ 50] Iter[ 51/  6]\t\tLoss: 7.1144 Acc@1: 50.613%\n",
            "| Epoch [ 34/ 50] Iter[101/  6]\t\tLoss: 6.2365 Acc@1: 50.851%\n",
            "| Epoch [ 34/ 50] Iter[151/  6]\t\tLoss: 5.8446 Acc@1: 51.707%\n",
            "| Epoch [ 34/ 50] Iter[201/  6]\t\tLoss: 8.7668 Acc@1: 51.819%\n",
            "| Epoch [ 34/ 50] Iter[251/  6]\t\tLoss: 6.3446 Acc@1: 51.656%\n",
            "| Epoch [ 34/ 50] Iter[301/  6]\t\tLoss: 10.1514 Acc@1: 51.287%\n",
            "\n",
            "| Validation Epoch #34\t\t\tLoss: 9.3543 Acc@1: 50.41%\n",
            "lr = 1e-05\n",
            "| Epoch [ 35/ 50] Iter[  1/  6]\t\tLoss: 8.2295 Acc@1: 53.125%\n",
            "| Epoch [ 35/ 50] Iter[ 51/  6]\t\tLoss: 6.8693 Acc@1: 50.797%\n",
            "| Epoch [ 35/ 50] Iter[101/  6]\t\tLoss: 7.9617 Acc@1: 50.944%\n",
            "| Epoch [ 35/ 50] Iter[151/  6]\t\tLoss: 6.2335 Acc@1: 50.745%\n",
            "| Epoch [ 35/ 50] Iter[201/  6]\t\tLoss: 10.3977 Acc@1: 50.684%\n",
            "| Epoch [ 35/ 50] Iter[251/  6]\t\tLoss: 6.3894 Acc@1: 50.691%\n",
            "| Epoch [ 35/ 50] Iter[301/  6]\t\tLoss: 6.5958 Acc@1: 50.748%\n",
            "\n",
            "| Validation Epoch #35\t\t\tLoss: 7.7145 Acc@1: 49.52%\n",
            "lr = 1e-05\n",
            "| Epoch [ 36/ 50] Iter[  1/  6]\t\tLoss: 4.5127 Acc@1: 62.500%\n",
            "| Epoch [ 36/ 50] Iter[ 51/  6]\t\tLoss: 8.2278 Acc@1: 50.551%\n",
            "| Epoch [ 36/ 50] Iter[101/  6]\t\tLoss: 7.2953 Acc@1: 50.232%\n",
            "| Epoch [ 36/ 50] Iter[151/  6]\t\tLoss: 10.1327 Acc@1: 49.783%\n",
            "| Epoch [ 36/ 50] Iter[201/  6]\t\tLoss: 7.5950 Acc@1: 49.891%\n",
            "| Epoch [ 36/ 50] Iter[251/  6]\t\tLoss: 6.6235 Acc@1: 50.000%\n",
            "| Epoch [ 36/ 50] Iter[301/  6]\t\tLoss: 9.4361 Acc@1: 50.171%\n",
            "\n",
            "| Validation Epoch #36\t\t\tLoss: 4.5502 Acc@1: 49.10%\n",
            "lr = 1e-05\n",
            "| Epoch [ 37/ 50] Iter[  1/  6]\t\tLoss: 6.8301 Acc@1: 54.688%\n",
            "| Epoch [ 37/ 50] Iter[ 51/  6]\t\tLoss: 5.0386 Acc@1: 48.989%\n",
            "| Epoch [ 37/ 50] Iter[101/  6]\t\tLoss: 7.1927 Acc@1: 49.598%\n",
            "| Epoch [ 37/ 50] Iter[151/  6]\t\tLoss: 5.6598 Acc@1: 49.369%\n",
            "| Epoch [ 37/ 50] Iter[201/  6]\t\tLoss: 8.4356 Acc@1: 49.293%\n",
            "| Epoch [ 37/ 50] Iter[251/  6]\t\tLoss: 8.8916 Acc@1: 49.471%\n",
            "| Epoch [ 37/ 50] Iter[301/  6]\t\tLoss: 9.4840 Acc@1: 49.299%\n",
            "\n",
            "| Validation Epoch #37\t\t\tLoss: 4.3652 Acc@1: 48.53%\n",
            "lr = 1e-05\n",
            "| Epoch [ 38/ 50] Iter[  1/  6]\t\tLoss: 9.5578 Acc@1: 45.312%\n",
            "| Epoch [ 38/ 50] Iter[ 51/  6]\t\tLoss: 6.9782 Acc@1: 49.877%\n",
            "| Epoch [ 38/ 50] Iter[101/  6]\t\tLoss: 8.7010 Acc@1: 49.211%\n",
            "| Epoch [ 38/ 50] Iter[151/  6]\t\tLoss: 9.2504 Acc@1: 49.007%\n",
            "| Epoch [ 38/ 50] Iter[201/  6]\t\tLoss: 7.6735 Acc@1: 48.982%\n",
            "| Epoch [ 38/ 50] Iter[251/  6]\t\tLoss: 8.6453 Acc@1: 49.079%\n",
            "| Epoch [ 38/ 50] Iter[301/  6]\t\tLoss: 6.9818 Acc@1: 48.863%\n",
            "\n",
            "| Validation Epoch #38\t\t\tLoss: 11.4769 Acc@1: 48.11%\n",
            "lr = 1e-05\n",
            "| Epoch [ 39/ 50] Iter[  1/  6]\t\tLoss: 8.1959 Acc@1: 46.875%\n",
            "| Epoch [ 39/ 50] Iter[ 51/  6]\t\tLoss: 7.7440 Acc@1: 48.315%\n",
            "| Epoch [ 39/ 50] Iter[101/  6]\t\tLoss: 5.4813 Acc@1: 49.273%\n",
            "| Epoch [ 39/ 50] Iter[151/  6]\t\tLoss: 4.9312 Acc@1: 49.183%\n",
            "| Epoch [ 39/ 50] Iter[201/  6]\t\tLoss: 9.6311 Acc@1: 48.834%\n",
            "| Epoch [ 39/ 50] Iter[251/  6]\t\tLoss: 7.3761 Acc@1: 48.662%\n",
            "| Epoch [ 39/ 50] Iter[301/  6]\t\tLoss: 6.6650 Acc@1: 48.645%\n",
            "\n",
            "| Validation Epoch #39\t\t\tLoss: 8.6190 Acc@1: 47.87%\n",
            "lr = 1e-05\n",
            "| Epoch [ 40/ 50] Iter[  1/  6]\t\tLoss: 10.3794 Acc@1: 37.500%\n",
            "| Epoch [ 40/ 50] Iter[ 51/  6]\t\tLoss: 8.8010 Acc@1: 49.112%\n",
            "| Epoch [ 40/ 50] Iter[101/  6]\t\tLoss: 7.6390 Acc@1: 49.180%\n",
            "| Epoch [ 40/ 50] Iter[151/  6]\t\tLoss: 7.8264 Acc@1: 48.810%\n",
            "| Epoch [ 40/ 50] Iter[201/  6]\t\tLoss: 4.8530 Acc@1: 48.577%\n",
            "| Epoch [ 40/ 50] Iter[251/  6]\t\tLoss: 9.9906 Acc@1: 48.823%\n",
            "| Epoch [ 40/ 50] Iter[301/  6]\t\tLoss: 6.7711 Acc@1: 48.993%\n",
            "\n",
            "| Validation Epoch #40\t\t\tLoss: 8.7980 Acc@1: 48.15%\n",
            "lr = 1e-05\n",
            "| Epoch [ 41/ 50] Iter[  1/  6]\t\tLoss: 6.9944 Acc@1: 56.250%\n",
            "| Epoch [ 41/ 50] Iter[ 51/  6]\t\tLoss: 7.4084 Acc@1: 48.499%\n",
            "| Epoch [ 41/ 50] Iter[101/  6]\t\tLoss: 8.6176 Acc@1: 50.000%\n",
            "| Epoch [ 41/ 50] Iter[151/  6]\t\tLoss: 7.6066 Acc@1: 49.555%\n",
            "| Epoch [ 41/ 50] Iter[201/  6]\t\tLoss: 8.6835 Acc@1: 49.425%\n",
            "| Epoch [ 41/ 50] Iter[251/  6]\t\tLoss: 9.6562 Acc@1: 49.334%\n",
            "| Epoch [ 41/ 50] Iter[301/  6]\t\tLoss: 10.0174 Acc@1: 49.252%\n",
            "\n",
            "| Validation Epoch #41\t\t\tLoss: 7.1772 Acc@1: 48.72%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 42/ 50] Iter[  1/  6]\t\tLoss: 6.2284 Acc@1: 43.750%\n",
            "| Epoch [ 42/ 50] Iter[ 51/  6]\t\tLoss: 10.0066 Acc@1: 49.449%\n",
            "| Epoch [ 42/ 50] Iter[101/  6]\t\tLoss: 6.7883 Acc@1: 49.350%\n",
            "| Epoch [ 42/ 50] Iter[151/  6]\t\tLoss: 8.7554 Acc@1: 49.441%\n",
            "| Epoch [ 42/ 50] Iter[201/  6]\t\tLoss: 6.7798 Acc@1: 49.254%\n",
            "| Epoch [ 42/ 50] Iter[251/  6]\t\tLoss: 9.6399 Acc@1: 49.365%\n",
            "| Epoch [ 42/ 50] Iter[301/  6]\t\tLoss: 9.0070 Acc@1: 49.517%\n",
            "\n",
            "| Validation Epoch #42\t\t\tLoss: 6.6878 Acc@1: 48.66%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 43/ 50] Iter[  1/  6]\t\tLoss: 7.9760 Acc@1: 50.000%\n",
            "| Epoch [ 43/ 50] Iter[ 51/  6]\t\tLoss: 11.1829 Acc@1: 50.613%\n",
            "| Epoch [ 43/ 50] Iter[101/  6]\t\tLoss: 9.5286 Acc@1: 49.969%\n",
            "| Epoch [ 43/ 50] Iter[151/  6]\t\tLoss: 7.5628 Acc@1: 49.493%\n",
            "| Epoch [ 43/ 50] Iter[201/  6]\t\tLoss: 8.0469 Acc@1: 49.246%\n",
            "| Epoch [ 43/ 50] Iter[251/  6]\t\tLoss: 7.1019 Acc@1: 49.570%\n",
            "| Epoch [ 43/ 50] Iter[301/  6]\t\tLoss: 7.4291 Acc@1: 49.548%\n",
            "\n",
            "| Validation Epoch #43\t\t\tLoss: 4.9267 Acc@1: 48.73%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 44/ 50] Iter[  1/  6]\t\tLoss: 8.6885 Acc@1: 48.438%\n",
            "| Epoch [ 44/ 50] Iter[ 51/  6]\t\tLoss: 9.5192 Acc@1: 50.184%\n",
            "| Epoch [ 44/ 50] Iter[101/  6]\t\tLoss: 6.5379 Acc@1: 50.108%\n",
            "| Epoch [ 44/ 50] Iter[151/  6]\t\tLoss: 5.5941 Acc@1: 49.969%\n",
            "| Epoch [ 44/ 50] Iter[201/  6]\t\tLoss: 9.5515 Acc@1: 50.086%\n",
            "| Epoch [ 44/ 50] Iter[251/  6]\t\tLoss: 7.5957 Acc@1: 49.851%\n",
            "| Epoch [ 44/ 50] Iter[301/  6]\t\tLoss: 7.6549 Acc@1: 49.792%\n",
            "\n",
            "| Validation Epoch #44\t\t\tLoss: 10.8771 Acc@1: 49.04%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 45/ 50] Iter[  1/  6]\t\tLoss: 7.1142 Acc@1: 45.312%\n",
            "| Epoch [ 45/ 50] Iter[ 51/  6]\t\tLoss: 7.6672 Acc@1: 50.306%\n",
            "| Epoch [ 45/ 50] Iter[101/  6]\t\tLoss: 6.4149 Acc@1: 50.201%\n",
            "| Epoch [ 45/ 50] Iter[151/  6]\t\tLoss: 7.9189 Acc@1: 49.555%\n",
            "| Epoch [ 45/ 50] Iter[201/  6]\t\tLoss: 9.4168 Acc@1: 49.588%\n",
            "| Epoch [ 45/ 50] Iter[251/  6]\t\tLoss: 7.4422 Acc@1: 50.037%\n",
            "| Epoch [ 45/ 50] Iter[301/  6]\t\tLoss: 4.8428 Acc@1: 49.766%\n",
            "\n",
            "| Validation Epoch #45\t\t\tLoss: 6.4089 Acc@1: 49.21%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 46/ 50] Iter[  1/  6]\t\tLoss: 7.4349 Acc@1: 48.438%\n",
            "| Epoch [ 46/ 50] Iter[ 51/  6]\t\tLoss: 6.2071 Acc@1: 49.786%\n",
            "| Epoch [ 46/ 50] Iter[101/  6]\t\tLoss: 6.6811 Acc@1: 50.186%\n",
            "| Epoch [ 46/ 50] Iter[151/  6]\t\tLoss: 7.7921 Acc@1: 50.238%\n",
            "| Epoch [ 46/ 50] Iter[201/  6]\t\tLoss: 7.2614 Acc@1: 50.280%\n",
            "| Epoch [ 46/ 50] Iter[251/  6]\t\tLoss: 9.3403 Acc@1: 50.025%\n",
            "| Epoch [ 46/ 50] Iter[301/  6]\t\tLoss: 8.9472 Acc@1: 49.964%\n",
            "\n",
            "| Validation Epoch #46\t\t\tLoss: 7.2720 Acc@1: 49.36%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 47/ 50] Iter[  1/  6]\t\tLoss: 7.9402 Acc@1: 51.562%\n",
            "| Epoch [ 47/ 50] Iter[ 51/  6]\t\tLoss: 7.0935 Acc@1: 49.326%\n",
            "| Epoch [ 47/ 50] Iter[101/  6]\t\tLoss: 5.1525 Acc@1: 50.882%\n",
            "| Epoch [ 47/ 50] Iter[151/  6]\t\tLoss: 6.0227 Acc@1: 50.248%\n",
            "| Epoch [ 47/ 50] Iter[201/  6]\t\tLoss: 6.3878 Acc@1: 50.194%\n",
            "| Epoch [ 47/ 50] Iter[251/  6]\t\tLoss: 8.5330 Acc@1: 50.174%\n",
            "| Epoch [ 47/ 50] Iter[301/  6]\t\tLoss: 7.7457 Acc@1: 50.026%\n",
            "\n",
            "| Validation Epoch #47\t\t\tLoss: 8.6455 Acc@1: 49.55%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 48/ 50] Iter[  1/  6]\t\tLoss: 7.5488 Acc@1: 50.000%\n",
            "| Epoch [ 48/ 50] Iter[ 51/  6]\t\tLoss: 6.9242 Acc@1: 50.184%\n",
            "| Epoch [ 48/ 50] Iter[101/  6]\t\tLoss: 7.1750 Acc@1: 50.340%\n",
            "| Epoch [ 48/ 50] Iter[151/  6]\t\tLoss: 7.5704 Acc@1: 50.673%\n",
            "| Epoch [ 48/ 50] Iter[201/  6]\t\tLoss: 7.8497 Acc@1: 50.373%\n",
            "| Epoch [ 48/ 50] Iter[251/  6]\t\tLoss: 6.1569 Acc@1: 50.423%\n",
            "| Epoch [ 48/ 50] Iter[301/  6]\t\tLoss: 12.3312 Acc@1: 50.322%\n",
            "\n",
            "| Validation Epoch #48\t\t\tLoss: 5.7826 Acc@1: 49.58%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 49/ 50] Iter[  1/  6]\t\tLoss: 7.9144 Acc@1: 45.312%\n",
            "| Epoch [ 49/ 50] Iter[ 51/  6]\t\tLoss: 9.7002 Acc@1: 50.368%\n",
            "| Epoch [ 49/ 50] Iter[101/  6]\t\tLoss: 7.1536 Acc@1: 50.248%\n",
            "| Epoch [ 49/ 50] Iter[151/  6]\t\tLoss: 9.8683 Acc@1: 50.217%\n",
            "| Epoch [ 49/ 50] Iter[201/  6]\t\tLoss: 5.5255 Acc@1: 50.552%\n",
            "| Epoch [ 49/ 50] Iter[251/  6]\t\tLoss: 7.1163 Acc@1: 50.380%\n",
            "| Epoch [ 49/ 50] Iter[301/  6]\t\tLoss: 7.7200 Acc@1: 50.327%\n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 7.4291 Acc@1: 49.65%\n",
            "lr = 1.0000000000000002e-07\n",
            "Training Done!\n"
          ]
        }
      ],
      "source": [
        "print (\"Let us Train.\")\n",
        "EPOCHS = 50\n",
        "model = SentimentClassifier(768, NUM_CLASSES).to(device)\n",
        "model_test = SentimentClassifier(768, NUM_CLASSES).to(device)\n",
        "best_error = float('inf')\n",
        "LEARNING_RATE = 1e-3\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau,StepLR\n",
        "\n",
        "traindataset = EmbeddingDataset(train_embeddings, train_y)\n",
        "trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valdataset = EmbeddingDataset(val_embeddings, val_y)\n",
        "valloader = DataLoader(valdataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "#lr_scheduler =  StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "lr_scheduler = ReduceLROnPlateau(optimizer, 'min', patience=7)\n",
        "\n",
        "train_history = []\n",
        "val_history = []\n",
        "print('----------------------------------------------------------------------------------------------------')\n",
        "print('3/ training model 1')\n",
        "print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "iter =0\n",
        "for epoch in range(EPOCHS):\n",
        "    loss = train(model, trainloader, optimizer, epoch)\n",
        "    train_history.append(loss)\n",
        "    #lr_scheduler.step()\n",
        "    val_loss= test(model, valloader,epoch)\n",
        "    val_history.append(val_loss[0])\n",
        "    lr_scheduler.step(val_loss[0])\n",
        "    print('lr =',get_lr(optimizer))\n",
        "\n",
        "    if val_loss[0] <best_error:\n",
        "        best_error=val_loss[0]\n",
        "        print('Best RMSE is of : ' + str(best_error), 'for epoch :', epoch,'ERROR TEST = ',val_loss)\n",
        "        #model_test.parameters()=model.state_dict()\n",
        "        model_test.load_state_dict(model.state_dict(), strict=True)\n",
        "\n",
        "print (\"Training Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUgqW43GU6ne"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:28:24.157868Z",
          "iopub.status.busy": "2024-09-12T08:28:24.157398Z",
          "iopub.status.idle": "2024-09-12T08:28:24.285993Z",
          "shell.execute_reply": "2024-09-12T08:28:24.284901Z",
          "shell.execute_reply.started": "2024-09-12T08:28:24.157825Z"
        },
        "id": "s8_Iuj66dBip",
        "outputId": "c4b9ca89-fb80-4c58-de6a-fb78c24d52fe",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== \n",
            "Test set = \n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 6.5953 Acc@1: 49.66%\n",
            "==================== \n"
          ]
        }
      ],
      "source": [
        "testdataset = TextDataset(test_x,test_y, tokenizer, MAX_LENGTH)\n",
        "testloader = DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "bert = BertModel.from_pretrained(PRETRAINED_MODEL).to(device)\n",
        "# Extract embeddings\n",
        "\n",
        "test_embeddings = extract_embeddings(bert, testloader, device)\n",
        "test_embeddings =test_embeddings.cpu()\n",
        "print('==================== ')\n",
        "print('Test set = ')\n",
        "testdataset = EmbeddingDataset(test_embeddings, test_y)\n",
        "testdataset = DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loss,accu = test(model, testdataset,epoch)\n",
        "print('==================== ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkD2ubONd_R2"
      },
      "source": [
        "## Questions\n",
        "\n",
        "**q0/  please analyse the dataset with differents classical machine learning model**\n",
        "\n",
        "**q1/  please perform a classification with differents classical machine learning model and analyse the performences**\n",
        "\n",
        "**q2/  please perform a classification with a MLP?**\n",
        "\n",
        "**q3/  please analyse all the performences and explain which is the best**\n",
        "\n",
        "**q4/  please use an LLM compare your performences to a LLM**\n",
        "\n",
        "**q5/  please explain why I choose a BERT embedding instead of the raw text**\n",
        "\n",
        "**q6/  please read the BERT paper and explain the BERT architecture**\n",
        "\n",
        "**q7/  please finetue with LORA an LLM to classify the sentiment (optional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83a26eb8237c4670b59016ac2a41f3de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:  18%|#7        | 241M/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\elyes\\.cache\\huggingface\\hub\\models--bert-large-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20610, 1024])\n",
            "torch.Size([6870, 1024])\n",
            "Let us Train.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3/ training model 2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "| Epoch [  0/ 50] Iter[  1/  6]\t\tLoss: 1.0998 Acc@1: 29.688%\n",
            "| Epoch [  0/ 50] Iter[ 51/  6]\t\tLoss: 6.8486 Acc@1: 33.732%\n",
            "| Epoch [  0/ 50] Iter[101/  6]\t\tLoss: 17.3220 Acc@1: 35.566%\n",
            "| Epoch [  0/ 50] Iter[151/  6]\t\tLoss: 45.1580 Acc@1: 33.599%\n",
            "| Epoch [  0/ 50] Iter[201/  6]\t\tLoss: 34.1034 Acc@1: 33.341%\n",
            "| Epoch [  0/ 50] Iter[251/  6]\t\tLoss: 55.8790 Acc@1: 34.574%\n",
            "| Epoch [  0/ 50] Iter[301/  6]\t\tLoss: 86.1773 Acc@1: 34.240%\n",
            "\n",
            "| Validation Epoch #0\t\t\tLoss: 79.1753 Acc@1: 28.47%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 81.75154304504395 for epoch : 0 ERROR TEST =  (81.75154304504395, tensor(28.4716))\n",
            "| Epoch [  1/ 50] Iter[  1/  6]\t\tLoss: 75.9435 Acc@1: 34.375%\n",
            "| Epoch [  1/ 50] Iter[ 51/  6]\t\tLoss: 16.8787 Acc@1: 30.331%\n",
            "| Epoch [  1/ 50] Iter[101/  6]\t\tLoss: 58.7910 Acc@1: 32.457%\n",
            "| Epoch [  1/ 50] Iter[151/  6]\t\tLoss: 93.5261 Acc@1: 35.824%\n",
            "| Epoch [  1/ 50] Iter[201/  6]\t\tLoss: 105.0873 Acc@1: 35.557%\n",
            "| Epoch [  1/ 50] Iter[251/  6]\t\tLoss: 101.3136 Acc@1: 34.811%\n",
            "| Epoch [  1/ 50] Iter[301/  6]\t\tLoss: 114.9095 Acc@1: 35.392%\n",
            "\n",
            "| Validation Epoch #1\t\t\tLoss: 94.3340 Acc@1: 40.55%\n",
            "lr = 0.001\n",
            "| Epoch [  2/ 50] Iter[  1/  6]\t\tLoss: 87.0628 Acc@1: 57.812%\n",
            "| Epoch [  2/ 50] Iter[ 51/  6]\t\tLoss: 39.2936 Acc@1: 40.778%\n",
            "| Epoch [  2/ 50] Iter[101/  6]\t\tLoss: 48.5092 Acc@1: 37.469%\n",
            "| Epoch [  2/ 50] Iter[151/  6]\t\tLoss: 98.2564 Acc@1: 34.530%\n",
            "| Epoch [  2/ 50] Iter[201/  6]\t\tLoss: 91.7677 Acc@1: 34.103%\n",
            "| Epoch [  2/ 50] Iter[251/  6]\t\tLoss: 132.4433 Acc@1: 33.640%\n",
            "| Epoch [  2/ 50] Iter[301/  6]\t\tLoss: 116.6390 Acc@1: 33.347%\n",
            "\n",
            "| Validation Epoch #2\t\t\tLoss: 100.4681 Acc@1: 28.49%\n",
            "lr = 0.001\n",
            "| Epoch [  3/ 50] Iter[  1/  6]\t\tLoss: 120.4493 Acc@1: 20.312%\n",
            "| Epoch [  3/ 50] Iter[ 51/  6]\t\tLoss: 74.1000 Acc@1: 28.738%\n",
            "| Epoch [  3/ 50] Iter[101/  6]\t\tLoss: 66.5400 Acc@1: 31.173%\n",
            "| Epoch [  3/ 50] Iter[151/  6]\t\tLoss: 126.1859 Acc@1: 33.733%\n",
            "| Epoch [  3/ 50] Iter[201/  6]\t\tLoss: 149.3467 Acc@1: 35.627%\n",
            "| Epoch [  3/ 50] Iter[251/  6]\t\tLoss: 123.1353 Acc@1: 36.516%\n",
            "| Epoch [  3/ 50] Iter[301/  6]\t\tLoss: 98.8540 Acc@1: 36.493%\n",
            "\n",
            "| Validation Epoch #3\t\t\tLoss: 186.1256 Acc@1: 30.98%\n",
            "lr = 0.001\n",
            "| Epoch [  4/ 50] Iter[  1/  6]\t\tLoss: 204.2087 Acc@1: 21.875%\n",
            "| Epoch [  4/ 50] Iter[ 51/  6]\t\tLoss: 172.4125 Acc@1: 31.219%\n",
            "| Epoch [  4/ 50] Iter[101/  6]\t\tLoss: 155.9943 Acc@1: 31.265%\n",
            "| Epoch [  4/ 50] Iter[151/  6]\t\tLoss: 70.9888 Acc@1: 31.654%\n",
            "| Epoch [  4/ 50] Iter[201/  6]\t\tLoss: 72.5463 Acc@1: 33.877%\n",
            "| Epoch [  4/ 50] Iter[251/  6]\t\tLoss: 64.9509 Acc@1: 35.253%\n",
            "| Epoch [  4/ 50] Iter[301/  6]\t\tLoss: 118.8046 Acc@1: 35.024%\n",
            "\n",
            "| Validation Epoch #4\t\t\tLoss: 133.6089 Acc@1: 28.47%\n",
            "lr = 0.001\n",
            "| Epoch [  5/ 50] Iter[  1/  6]\t\tLoss: 197.1946 Acc@1: 25.000%\n",
            "| Epoch [  5/ 50] Iter[ 51/  6]\t\tLoss: 198.6495 Acc@1: 28.002%\n",
            "| Epoch [  5/ 50] Iter[101/  6]\t\tLoss: 180.1719 Acc@1: 28.434%\n",
            "| Epoch [  5/ 50] Iter[151/  6]\t\tLoss: 127.9561 Acc@1: 28.725%\n",
            "| Epoch [  5/ 50] Iter[201/  6]\t\tLoss: 143.9519 Acc@1: 31.864%\n",
            "| Epoch [  5/ 50] Iter[251/  6]\t\tLoss: 146.2914 Acc@1: 33.591%\n",
            "| Epoch [  5/ 50] Iter[301/  6]\t\tLoss: 150.2546 Acc@1: 34.583%\n",
            "\n",
            "| Validation Epoch #5\t\t\tLoss: 153.6601 Acc@1: 40.54%\n",
            "lr = 0.001\n",
            "| Epoch [  6/ 50] Iter[  1/  6]\t\tLoss: 137.6697 Acc@1: 35.938%\n",
            "| Epoch [  6/ 50] Iter[ 51/  6]\t\tLoss: 54.5738 Acc@1: 41.054%\n",
            "| Epoch [  6/ 50] Iter[101/  6]\t\tLoss: 112.6763 Acc@1: 37.794%\n",
            "| Epoch [  6/ 50] Iter[151/  6]\t\tLoss: 191.7001 Acc@1: 35.958%\n",
            "| Epoch [  6/ 50] Iter[201/  6]\t\tLoss: 202.4672 Acc@1: 35.331%\n",
            "| Epoch [  6/ 50] Iter[251/  6]\t\tLoss: 216.9773 Acc@1: 34.331%\n",
            "| Epoch [  6/ 50] Iter[301/  6]\t\tLoss: 135.1876 Acc@1: 33.638%\n",
            "\n",
            "| Validation Epoch #6\t\t\tLoss: 107.0858 Acc@1: 38.56%\n",
            "lr = 0.001\n",
            "| Epoch [  7/ 50] Iter[  1/  6]\t\tLoss: 71.7307 Acc@1: 46.875%\n",
            "| Epoch [  7/ 50] Iter[ 51/  6]\t\tLoss: 143.7708 Acc@1: 30.637%\n",
            "| Epoch [  7/ 50] Iter[101/  6]\t\tLoss: 163.3725 Acc@1: 29.301%\n",
            "| Epoch [  7/ 50] Iter[151/  6]\t\tLoss: 144.1298 Acc@1: 28.891%\n",
            "| Epoch [  7/ 50] Iter[201/  6]\t\tLoss: 86.7378 Acc@1: 29.493%\n",
            "| Epoch [  7/ 50] Iter[251/  6]\t\tLoss: 169.2105 Acc@1: 31.835%\n",
            "| Epoch [  7/ 50] Iter[301/  6]\t\tLoss: 215.7661 Acc@1: 33.145%\n",
            "\n",
            "| Validation Epoch #7\t\t\tLoss: 243.6966 Acc@1: 40.54%\n",
            "lr = 0.001\n",
            "| Epoch [  8/ 50] Iter[  1/  6]\t\tLoss: 214.5461 Acc@1: 43.750%\n",
            "| Epoch [  8/ 50] Iter[ 51/  6]\t\tLoss: 249.0677 Acc@1: 40.135%\n",
            "| Epoch [  8/ 50] Iter[101/  6]\t\tLoss: 234.4123 Acc@1: 40.656%\n",
            "| Epoch [  8/ 50] Iter[151/  6]\t\tLoss: 183.7753 Acc@1: 40.211%\n",
            "| Epoch [  8/ 50] Iter[201/  6]\t\tLoss: 147.6485 Acc@1: 40.291%\n",
            "| Epoch [  8/ 50] Iter[251/  6]\t\tLoss: 44.3067 Acc@1: 40.569%\n",
            "| Epoch [  8/ 50] Iter[301/  6]\t\tLoss: 81.6364 Acc@1: 39.400%\n",
            "\n",
            "| Validation Epoch #8\t\t\tLoss: 69.4852 Acc@1: 31.09%\n",
            "lr = 0.0001\n",
            "| Epoch [  9/ 50] Iter[  1/  6]\t\tLoss: 128.0646 Acc@1: 32.812%\n",
            "| Epoch [  9/ 50] Iter[ 51/  6]\t\tLoss: 159.6897 Acc@1: 31.648%\n",
            "| Epoch [  9/ 50] Iter[101/  6]\t\tLoss: 111.3701 Acc@1: 31.157%\n",
            "| Epoch [  9/ 50] Iter[151/  6]\t\tLoss: 95.1873 Acc@1: 31.219%\n",
            "| Epoch [  9/ 50] Iter[201/  6]\t\tLoss: 102.9241 Acc@1: 31.203%\n",
            "| Epoch [  9/ 50] Iter[251/  6]\t\tLoss: 105.3884 Acc@1: 31.412%\n",
            "| Epoch [  9/ 50] Iter[301/  6]\t\tLoss: 81.2434 Acc@1: 31.587%\n",
            "\n",
            "| Validation Epoch #9\t\t\tLoss: 87.6849 Acc@1: 32.18%\n",
            "lr = 0.0001\n",
            "| Epoch [ 10/ 50] Iter[  1/  6]\t\tLoss: 75.8309 Acc@1: 35.938%\n",
            "| Epoch [ 10/ 50] Iter[ 51/  6]\t\tLoss: 76.3985 Acc@1: 33.272%\n",
            "| Epoch [ 10/ 50] Iter[101/  6]\t\tLoss: 67.7804 Acc@1: 35.520%\n",
            "| Epoch [ 10/ 50] Iter[151/  6]\t\tLoss: 79.1890 Acc@1: 36.610%\n",
            "| Epoch [ 10/ 50] Iter[201/  6]\t\tLoss: 59.6448 Acc@1: 37.026%\n",
            "| Epoch [ 10/ 50] Iter[251/  6]\t\tLoss: 67.3940 Acc@1: 36.137%\n",
            "| Epoch [ 10/ 50] Iter[301/  6]\t\tLoss: 56.3245 Acc@1: 35.123%\n",
            "\n",
            "| Validation Epoch #10\t\t\tLoss: 60.9640 Acc@1: 29.21%\n",
            "lr = 0.0001\n",
            "Best RMSE is of : 73.69027406198008 for epoch : 10 ERROR TEST =  (73.69027406198008, tensor(29.2140))\n",
            "| Epoch [ 11/ 50] Iter[  1/  6]\t\tLoss: 66.2277 Acc@1: 34.375%\n",
            "| Epoch [ 11/ 50] Iter[ 51/  6]\t\tLoss: 76.0031 Acc@1: 28.585%\n",
            "| Epoch [ 11/ 50] Iter[101/  6]\t\tLoss: 87.9922 Acc@1: 27.800%\n",
            "| Epoch [ 11/ 50] Iter[151/  6]\t\tLoss: 63.3987 Acc@1: 27.939%\n",
            "| Epoch [ 11/ 50] Iter[201/  6]\t\tLoss: 56.1460 Acc@1: 28.226%\n",
            "| Epoch [ 11/ 50] Iter[251/  6]\t\tLoss: 50.9339 Acc@1: 28.449%\n",
            "| Epoch [ 11/ 50] Iter[301/  6]\t\tLoss: 46.6637 Acc@1: 28.618%\n",
            "\n",
            "| Validation Epoch #11\t\t\tLoss: 42.6719 Acc@1: 29.77%\n",
            "lr = 0.0001\n",
            "Best RMSE is of : 45.343296439559374 for epoch : 11 ERROR TEST =  (45.343296439559374, tensor(29.7671))\n",
            "| Epoch [ 12/ 50] Iter[  1/  6]\t\tLoss: 39.4087 Acc@1: 37.500%\n",
            "| Epoch [ 12/ 50] Iter[ 51/  6]\t\tLoss: 38.1865 Acc@1: 31.526%\n",
            "| Epoch [ 12/ 50] Iter[101/  6]\t\tLoss: 22.8313 Acc@1: 31.606%\n",
            "| Epoch [ 12/ 50] Iter[151/  6]\t\tLoss: 23.0562 Acc@1: 33.092%\n",
            "| Epoch [ 12/ 50] Iter[201/  6]\t\tLoss: 36.4182 Acc@1: 34.181%\n",
            "| Epoch [ 12/ 50] Iter[251/  6]\t\tLoss: 27.6931 Acc@1: 35.483%\n",
            "| Epoch [ 12/ 50] Iter[301/  6]\t\tLoss: 32.9685 Acc@1: 36.415%\n",
            "\n",
            "| Validation Epoch #12\t\t\tLoss: 29.1480 Acc@1: 42.11%\n",
            "lr = 0.0001\n",
            "Best RMSE is of : 30.415690669307 for epoch : 12 ERROR TEST =  (30.415690669307, tensor(42.1106))\n",
            "| Epoch [ 13/ 50] Iter[  1/  6]\t\tLoss: 30.5514 Acc@1: 39.062%\n",
            "| Epoch [ 13/ 50] Iter[ 51/  6]\t\tLoss: 36.3680 Acc@1: 40.778%\n",
            "| Epoch [ 13/ 50] Iter[101/  6]\t\tLoss: 45.8362 Acc@1: 41.259%\n",
            "| Epoch [ 13/ 50] Iter[151/  6]\t\tLoss: 38.1267 Acc@1: 41.132%\n",
            "| Epoch [ 13/ 50] Iter[201/  6]\t\tLoss: 46.3069 Acc@1: 41.480%\n",
            "| Epoch [ 13/ 50] Iter[251/  6]\t\tLoss: 46.1723 Acc@1: 41.391%\n",
            "| Epoch [ 13/ 50] Iter[301/  6]\t\tLoss: 55.7734 Acc@1: 41.144%\n",
            "\n",
            "| Validation Epoch #13\t\t\tLoss: 45.7370 Acc@1: 40.79%\n",
            "lr = 0.0001\n",
            "| Epoch [ 14/ 50] Iter[  1/  6]\t\tLoss: 46.1290 Acc@1: 46.875%\n",
            "| Epoch [ 14/ 50] Iter[ 51/  6]\t\tLoss: 52.9662 Acc@1: 41.513%\n",
            "| Epoch [ 14/ 50] Iter[101/  6]\t\tLoss: 43.4202 Acc@1: 41.027%\n",
            "| Epoch [ 14/ 50] Iter[151/  6]\t\tLoss: 58.6543 Acc@1: 40.894%\n",
            "| Epoch [ 14/ 50] Iter[201/  6]\t\tLoss: 53.6348 Acc@1: 40.835%\n",
            "| Epoch [ 14/ 50] Iter[251/  6]\t\tLoss: 53.1890 Acc@1: 40.961%\n",
            "| Epoch [ 14/ 50] Iter[301/  6]\t\tLoss: 53.4412 Acc@1: 41.336%\n",
            "\n",
            "| Validation Epoch #14\t\t\tLoss: 66.4519 Acc@1: 43.10%\n",
            "lr = 0.0001\n",
            "| Epoch [ 15/ 50] Iter[  1/  6]\t\tLoss: 63.3079 Acc@1: 39.062%\n",
            "| Epoch [ 15/ 50] Iter[ 51/  6]\t\tLoss: 67.0501 Acc@1: 44.638%\n",
            "| Epoch [ 15/ 50] Iter[101/  6]\t\tLoss: 53.8290 Acc@1: 43.750%\n",
            "| Epoch [ 15/ 50] Iter[151/  6]\t\tLoss: 58.9070 Acc@1: 43.502%\n",
            "| Epoch [ 15/ 50] Iter[201/  6]\t\tLoss: 49.3176 Acc@1: 43.478%\n",
            "| Epoch [ 15/ 50] Iter[251/  6]\t\tLoss: 45.7047 Acc@1: 43.482%\n",
            "| Epoch [ 15/ 50] Iter[301/  6]\t\tLoss: 46.5532 Acc@1: 43.278%\n",
            "\n",
            "| Validation Epoch #15\t\t\tLoss: 57.4368 Acc@1: 39.72%\n",
            "lr = 0.0001\n",
            "| Epoch [ 16/ 50] Iter[  1/  6]\t\tLoss: 49.3735 Acc@1: 43.750%\n",
            "| Epoch [ 16/ 50] Iter[ 51/  6]\t\tLoss: 46.4902 Acc@1: 41.023%\n",
            "| Epoch [ 16/ 50] Iter[101/  6]\t\tLoss: 57.0791 Acc@1: 39.604%\n",
            "| Epoch [ 16/ 50] Iter[151/  6]\t\tLoss: 68.4001 Acc@1: 38.411%\n",
            "| Epoch [ 16/ 50] Iter[201/  6]\t\tLoss: 65.0888 Acc@1: 37.982%\n",
            "| Epoch [ 16/ 50] Iter[251/  6]\t\tLoss: 59.8426 Acc@1: 37.270%\n",
            "| Epoch [ 16/ 50] Iter[301/  6]\t\tLoss: 55.7501 Acc@1: 36.882%\n",
            "\n",
            "| Validation Epoch #16\t\t\tLoss: 55.7970 Acc@1: 33.35%\n",
            "lr = 0.0001\n",
            "| Epoch [ 17/ 50] Iter[  1/  6]\t\tLoss: 67.7522 Acc@1: 31.250%\n",
            "| Epoch [ 17/ 50] Iter[ 51/  6]\t\tLoss: 66.1129 Acc@1: 33.578%\n",
            "| Epoch [ 17/ 50] Iter[101/  6]\t\tLoss: 56.5401 Acc@1: 33.369%\n",
            "| Epoch [ 17/ 50] Iter[151/  6]\t\tLoss: 62.5003 Acc@1: 33.733%\n",
            "| Epoch [ 17/ 50] Iter[201/  6]\t\tLoss: 65.1829 Acc@1: 33.644%\n",
            "| Epoch [ 17/ 50] Iter[251/  6]\t\tLoss: 58.8408 Acc@1: 33.809%\n",
            "| Epoch [ 17/ 50] Iter[301/  6]\t\tLoss: 37.6291 Acc@1: 34.048%\n",
            "\n",
            "| Validation Epoch #17\t\t\tLoss: 50.7142 Acc@1: 33.97%\n",
            "lr = 0.0001\n",
            "| Epoch [ 18/ 50] Iter[  1/  6]\t\tLoss: 40.1511 Acc@1: 40.625%\n",
            "| Epoch [ 18/ 50] Iter[ 51/  6]\t\tLoss: 33.4282 Acc@1: 35.539%\n",
            "| Epoch [ 18/ 50] Iter[101/  6]\t\tLoss: 34.9183 Acc@1: 35.938%\n",
            "| Epoch [ 18/ 50] Iter[151/  6]\t\tLoss: 28.2693 Acc@1: 36.817%\n",
            "| Epoch [ 18/ 50] Iter[201/  6]\t\tLoss: 28.0752 Acc@1: 36.964%\n",
            "| Epoch [ 18/ 50] Iter[251/  6]\t\tLoss: 20.0710 Acc@1: 37.749%\n",
            "| Epoch [ 18/ 50] Iter[301/  6]\t\tLoss: 19.8280 Acc@1: 38.549%\n",
            "\n",
            "| Validation Epoch #18\t\t\tLoss: 18.1113 Acc@1: 44.70%\n",
            "lr = 0.0001\n",
            "Best RMSE is of : 15.71196632915073 for epoch : 18 ERROR TEST =  (15.71196632915073, tensor(44.7016))\n",
            "| Epoch [ 19/ 50] Iter[  1/  6]\t\tLoss: 14.9717 Acc@1: 46.875%\n",
            "| Epoch [ 19/ 50] Iter[ 51/  6]\t\tLoss: 14.4818 Acc@1: 46.415%\n",
            "| Epoch [ 19/ 50] Iter[101/  6]\t\tLoss: 15.2313 Acc@1: 46.303%\n",
            "| Epoch [ 19/ 50] Iter[151/  6]\t\tLoss: 18.4286 Acc@1: 45.892%\n",
            "| Epoch [ 19/ 50] Iter[201/  6]\t\tLoss: 27.8622 Acc@1: 45.025%\n",
            "| Epoch [ 19/ 50] Iter[251/  6]\t\tLoss: 24.2808 Acc@1: 43.893%\n",
            "| Epoch [ 19/ 50] Iter[301/  6]\t\tLoss: 22.0097 Acc@1: 43.018%\n",
            "\n",
            "| Validation Epoch #19\t\t\tLoss: 30.6993 Acc@1: 35.75%\n",
            "lr = 0.0001\n",
            "| Epoch [ 20/ 50] Iter[  1/  6]\t\tLoss: 25.7506 Acc@1: 40.625%\n",
            "| Epoch [ 20/ 50] Iter[ 51/  6]\t\tLoss: 28.3267 Acc@1: 35.784%\n",
            "| Epoch [ 20/ 50] Iter[101/  6]\t\tLoss: 31.5016 Acc@1: 36.046%\n",
            "| Epoch [ 20/ 50] Iter[151/  6]\t\tLoss: 29.1345 Acc@1: 36.031%\n",
            "| Epoch [ 20/ 50] Iter[201/  6]\t\tLoss: 39.2421 Acc@1: 35.424%\n",
            "| Epoch [ 20/ 50] Iter[251/  6]\t\tLoss: 35.4096 Acc@1: 35.116%\n",
            "| Epoch [ 20/ 50] Iter[301/  6]\t\tLoss: 49.2545 Acc@1: 34.692%\n",
            "\n",
            "| Validation Epoch #20\t\t\tLoss: 46.8641 Acc@1: 32.66%\n",
            "lr = 0.0001\n",
            "| Epoch [ 21/ 50] Iter[  1/  6]\t\tLoss: 41.3263 Acc@1: 40.625%\n",
            "| Epoch [ 21/ 50] Iter[ 51/  6]\t\tLoss: 53.8344 Acc@1: 33.793%\n",
            "| Epoch [ 21/ 50] Iter[101/  6]\t\tLoss: 45.4825 Acc@1: 34.375%\n",
            "| Epoch [ 21/ 50] Iter[151/  6]\t\tLoss: 41.7942 Acc@1: 35.058%\n",
            "| Epoch [ 21/ 50] Iter[201/  6]\t\tLoss: 46.4946 Acc@1: 35.463%\n",
            "| Epoch [ 21/ 50] Iter[251/  6]\t\tLoss: 34.5940 Acc@1: 35.776%\n",
            "| Epoch [ 21/ 50] Iter[301/  6]\t\tLoss: 54.7506 Acc@1: 36.130%\n",
            "\n",
            "| Validation Epoch #21\t\t\tLoss: 50.4204 Acc@1: 39.29%\n",
            "lr = 0.0001\n",
            "| Epoch [ 22/ 50] Iter[  1/  6]\t\tLoss: 43.3068 Acc@1: 43.750%\n",
            "| Epoch [ 22/ 50] Iter[ 51/  6]\t\tLoss: 48.9915 Acc@1: 40.625%\n",
            "| Epoch [ 22/ 50] Iter[101/  6]\t\tLoss: 31.3896 Acc@1: 40.996%\n",
            "| Epoch [ 22/ 50] Iter[151/  6]\t\tLoss: 53.4321 Acc@1: 41.142%\n",
            "| Epoch [ 22/ 50] Iter[201/  6]\t\tLoss: 66.9724 Acc@1: 41.115%\n",
            "| Epoch [ 22/ 50] Iter[251/  6]\t\tLoss: 48.5781 Acc@1: 41.210%\n",
            "| Epoch [ 22/ 50] Iter[301/  6]\t\tLoss: 44.5067 Acc@1: 41.170%\n",
            "\n",
            "| Validation Epoch #22\t\t\tLoss: 15.7306 Acc@1: 41.35%\n",
            "lr = 0.0001\n",
            "| Epoch [ 23/ 50] Iter[  1/  6]\t\tLoss: 54.4903 Acc@1: 39.062%\n",
            "| Epoch [ 23/ 50] Iter[ 51/  6]\t\tLoss: 55.8524 Acc@1: 41.146%\n",
            "| Epoch [ 23/ 50] Iter[101/  6]\t\tLoss: 47.5967 Acc@1: 41.290%\n",
            "| Epoch [ 23/ 50] Iter[151/  6]\t\tLoss: 42.1169 Acc@1: 41.505%\n",
            "| Epoch [ 23/ 50] Iter[201/  6]\t\tLoss: 56.2161 Acc@1: 41.387%\n",
            "| Epoch [ 23/ 50] Iter[251/  6]\t\tLoss: 39.3696 Acc@1: 41.384%\n",
            "| Epoch [ 23/ 50] Iter[301/  6]\t\tLoss: 37.2908 Acc@1: 41.165%\n",
            "\n",
            "| Validation Epoch #23\t\t\tLoss: 46.2064 Acc@1: 38.01%\n",
            "lr = 0.0001\n",
            "| Epoch [ 24/ 50] Iter[  1/  6]\t\tLoss: 32.9450 Acc@1: 37.500%\n",
            "| Epoch [ 24/ 50] Iter[ 51/  6]\t\tLoss: 29.6691 Acc@1: 38.450%\n",
            "| Epoch [ 24/ 50] Iter[101/  6]\t\tLoss: 24.7012 Acc@1: 37.608%\n",
            "| Epoch [ 24/ 50] Iter[151/  6]\t\tLoss: 22.3888 Acc@1: 36.196%\n",
            "| Epoch [ 24/ 50] Iter[201/  6]\t\tLoss: 22.5111 Acc@1: 35.891%\n",
            "| Epoch [ 24/ 50] Iter[251/  6]\t\tLoss: 24.2017 Acc@1: 35.732%\n",
            "| Epoch [ 24/ 50] Iter[301/  6]\t\tLoss: 19.5999 Acc@1: 36.093%\n",
            "\n",
            "| Validation Epoch #24\t\t\tLoss: 17.7858 Acc@1: 38.76%\n",
            "lr = 0.0001\n",
            "| Epoch [ 25/ 50] Iter[  1/  6]\t\tLoss: 17.0708 Acc@1: 29.688%\n",
            "| Epoch [ 25/ 50] Iter[ 51/  6]\t\tLoss: 12.4128 Acc@1: 40.441%\n",
            "| Epoch [ 25/ 50] Iter[101/  6]\t\tLoss: 11.6628 Acc@1: 42.296%\n",
            "| Epoch [ 25/ 50] Iter[151/  6]\t\tLoss: 11.0865 Acc@1: 42.498%\n",
            "| Epoch [ 25/ 50] Iter[201/  6]\t\tLoss: 17.0072 Acc@1: 42.203%\n",
            "| Epoch [ 25/ 50] Iter[251/  6]\t\tLoss: 16.4986 Acc@1: 42.038%\n",
            "| Epoch [ 25/ 50] Iter[301/  6]\t\tLoss: 25.0149 Acc@1: 41.217%\n",
            "\n",
            "| Validation Epoch #25\t\t\tLoss: 18.5764 Acc@1: 34.61%\n",
            "lr = 0.0001\n",
            "| Epoch [ 26/ 50] Iter[  1/  6]\t\tLoss: 24.3700 Acc@1: 35.938%\n",
            "| Epoch [ 26/ 50] Iter[ 51/  6]\t\tLoss: 38.2273 Acc@1: 35.263%\n",
            "| Epoch [ 26/ 50] Iter[101/  6]\t\tLoss: 37.1150 Acc@1: 34.886%\n",
            "| Epoch [ 26/ 50] Iter[151/  6]\t\tLoss: 35.6223 Acc@1: 34.065%\n",
            "| Epoch [ 26/ 50] Iter[201/  6]\t\tLoss: 40.0364 Acc@1: 33.909%\n",
            "| Epoch [ 26/ 50] Iter[251/  6]\t\tLoss: 42.4312 Acc@1: 33.535%\n",
            "| Epoch [ 26/ 50] Iter[301/  6]\t\tLoss: 40.5387 Acc@1: 33.602%\n",
            "\n",
            "| Validation Epoch #26\t\t\tLoss: 33.3368 Acc@1: 33.55%\n",
            "lr = 1e-05\n",
            "| Epoch [ 27/ 50] Iter[  1/  6]\t\tLoss: 33.8883 Acc@1: 42.188%\n",
            "| Epoch [ 27/ 50] Iter[ 51/  6]\t\tLoss: 36.8227 Acc@1: 32.996%\n",
            "| Epoch [ 27/ 50] Iter[101/  6]\t\tLoss: 41.0603 Acc@1: 32.905%\n",
            "| Epoch [ 27/ 50] Iter[151/  6]\t\tLoss: 27.6911 Acc@1: 33.516%\n",
            "| Epoch [ 27/ 50] Iter[201/  6]\t\tLoss: 29.2184 Acc@1: 33.629%\n",
            "| Epoch [ 27/ 50] Iter[251/  6]\t\tLoss: 42.1792 Acc@1: 33.752%\n",
            "| Epoch [ 27/ 50] Iter[301/  6]\t\tLoss: 35.8991 Acc@1: 33.586%\n",
            "\n",
            "| Validation Epoch #27\t\t\tLoss: 31.1049 Acc@1: 33.78%\n",
            "lr = 1e-05\n",
            "| Epoch [ 28/ 50] Iter[  1/  6]\t\tLoss: 43.7672 Acc@1: 31.250%\n",
            "| Epoch [ 28/ 50] Iter[ 51/  6]\t\tLoss: 42.7548 Acc@1: 34.589%\n",
            "| Epoch [ 28/ 50] Iter[101/  6]\t\tLoss: 38.8377 Acc@1: 33.926%\n",
            "| Epoch [ 28/ 50] Iter[151/  6]\t\tLoss: 34.2988 Acc@1: 34.189%\n",
            "| Epoch [ 28/ 50] Iter[201/  6]\t\tLoss: 32.2892 Acc@1: 34.639%\n",
            "| Epoch [ 28/ 50] Iter[251/  6]\t\tLoss: 30.1512 Acc@1: 34.630%\n",
            "| Epoch [ 28/ 50] Iter[301/  6]\t\tLoss: 41.1325 Acc@1: 34.884%\n",
            "\n",
            "| Validation Epoch #28\t\t\tLoss: 29.7578 Acc@1: 34.86%\n",
            "lr = 1e-05\n",
            "| Epoch [ 29/ 50] Iter[  1/  6]\t\tLoss: 34.3389 Acc@1: 40.625%\n",
            "| Epoch [ 29/ 50] Iter[ 51/  6]\t\tLoss: 28.7267 Acc@1: 35.417%\n",
            "| Epoch [ 29/ 50] Iter[101/  6]\t\tLoss: 32.2725 Acc@1: 35.938%\n",
            "| Epoch [ 29/ 50] Iter[151/  6]\t\tLoss: 27.3139 Acc@1: 35.731%\n",
            "| Epoch [ 29/ 50] Iter[201/  6]\t\tLoss: 37.2024 Acc@1: 36.248%\n",
            "| Epoch [ 29/ 50] Iter[251/  6]\t\tLoss: 30.7185 Acc@1: 36.336%\n",
            "| Epoch [ 29/ 50] Iter[301/  6]\t\tLoss: 26.9668 Acc@1: 36.296%\n",
            "\n",
            "| Validation Epoch #29\t\t\tLoss: 35.0539 Acc@1: 36.84%\n",
            "lr = 1e-05\n",
            "| Epoch [ 30/ 50] Iter[  1/  6]\t\tLoss: 24.8944 Acc@1: 42.188%\n",
            "| Epoch [ 30/ 50] Iter[ 51/  6]\t\tLoss: 24.9093 Acc@1: 37.776%\n",
            "| Epoch [ 30/ 50] Iter[101/  6]\t\tLoss: 34.0780 Acc@1: 37.856%\n",
            "| Epoch [ 30/ 50] Iter[151/  6]\t\tLoss: 28.3174 Acc@1: 37.904%\n",
            "| Epoch [ 30/ 50] Iter[201/  6]\t\tLoss: 20.2447 Acc@1: 37.694%\n",
            "| Epoch [ 30/ 50] Iter[251/  6]\t\tLoss: 29.6715 Acc@1: 38.154%\n",
            "| Epoch [ 30/ 50] Iter[301/  6]\t\tLoss: 22.2747 Acc@1: 38.258%\n",
            "\n",
            "| Validation Epoch #30\t\t\tLoss: 19.4007 Acc@1: 39.13%\n",
            "lr = 1e-05\n",
            "| Epoch [ 31/ 50] Iter[  1/  6]\t\tLoss: 21.8192 Acc@1: 43.750%\n",
            "| Epoch [ 31/ 50] Iter[ 51/  6]\t\tLoss: 24.7878 Acc@1: 39.216%\n",
            "| Epoch [ 31/ 50] Iter[101/  6]\t\tLoss: 23.1016 Acc@1: 39.202%\n",
            "| Epoch [ 31/ 50] Iter[151/  6]\t\tLoss: 21.0387 Acc@1: 39.611%\n",
            "| Epoch [ 31/ 50] Iter[201/  6]\t\tLoss: 19.4020 Acc@1: 39.436%\n",
            "| Epoch [ 31/ 50] Iter[251/  6]\t\tLoss: 20.0356 Acc@1: 39.704%\n",
            "| Epoch [ 31/ 50] Iter[301/  6]\t\tLoss: 26.3365 Acc@1: 40.007%\n",
            "\n",
            "| Validation Epoch #31\t\t\tLoss: 12.3491 Acc@1: 41.14%\n",
            "lr = 1e-05\n",
            "| Epoch [ 32/ 50] Iter[  1/  6]\t\tLoss: 18.0244 Acc@1: 46.875%\n",
            "| Epoch [ 32/ 50] Iter[ 51/  6]\t\tLoss: 21.7958 Acc@1: 42.371%\n",
            "| Epoch [ 32/ 50] Iter[101/  6]\t\tLoss: 20.6604 Acc@1: 42.744%\n",
            "| Epoch [ 32/ 50] Iter[151/  6]\t\tLoss: 22.4851 Acc@1: 42.229%\n",
            "| Epoch [ 32/ 50] Iter[201/  6]\t\tLoss: 20.8964 Acc@1: 41.947%\n",
            "| Epoch [ 32/ 50] Iter[251/  6]\t\tLoss: 17.7823 Acc@1: 41.696%\n",
            "| Epoch [ 32/ 50] Iter[301/  6]\t\tLoss: 24.8370 Acc@1: 42.110%\n",
            "\n",
            "| Validation Epoch #32\t\t\tLoss: 22.0128 Acc@1: 42.84%\n",
            "lr = 1e-05\n",
            "| Epoch [ 33/ 50] Iter[  1/  6]\t\tLoss: 18.3618 Acc@1: 40.625%\n",
            "| Epoch [ 33/ 50] Iter[ 51/  6]\t\tLoss: 11.4115 Acc@1: 42.249%\n",
            "| Epoch [ 33/ 50] Iter[101/  6]\t\tLoss: 17.5023 Acc@1: 43.332%\n",
            "| Epoch [ 33/ 50] Iter[151/  6]\t\tLoss: 18.0710 Acc@1: 43.502%\n",
            "| Epoch [ 33/ 50] Iter[201/  6]\t\tLoss: 19.1915 Acc@1: 43.455%\n",
            "| Epoch [ 33/ 50] Iter[251/  6]\t\tLoss: 16.3360 Acc@1: 43.719%\n",
            "| Epoch [ 33/ 50] Iter[301/  6]\t\tLoss: 13.7438 Acc@1: 43.854%\n",
            "\n",
            "| Validation Epoch #33\t\t\tLoss: 18.7271 Acc@1: 44.69%\n",
            "lr = 1e-05\n",
            "| Epoch [ 34/ 50] Iter[  1/  6]\t\tLoss: 20.5033 Acc@1: 39.062%\n",
            "| Epoch [ 34/ 50] Iter[ 51/  6]\t\tLoss: 15.3666 Acc@1: 43.964%\n",
            "| Epoch [ 34/ 50] Iter[101/  6]\t\tLoss: 13.2903 Acc@1: 44.338%\n",
            "| Epoch [ 34/ 50] Iter[151/  6]\t\tLoss: 21.2208 Acc@1: 44.909%\n",
            "| Epoch [ 34/ 50] Iter[201/  6]\t\tLoss: 12.1718 Acc@1: 45.056%\n",
            "| Epoch [ 34/ 50] Iter[251/  6]\t\tLoss: 18.4547 Acc@1: 45.039%\n",
            "| Epoch [ 34/ 50] Iter[301/  6]\t\tLoss: 13.3301 Acc@1: 44.965%\n",
            "\n",
            "| Validation Epoch #34\t\t\tLoss: 9.7703 Acc@1: 45.71%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 35/ 50] Iter[  1/  6]\t\tLoss: 15.9371 Acc@1: 42.188%\n",
            "| Epoch [ 35/ 50] Iter[ 51/  6]\t\tLoss: 16.4485 Acc@1: 46.569%\n",
            "| Epoch [ 35/ 50] Iter[101/  6]\t\tLoss: 18.1095 Acc@1: 45.606%\n",
            "| Epoch [ 35/ 50] Iter[151/  6]\t\tLoss: 14.8502 Acc@1: 45.312%\n",
            "| Epoch [ 35/ 50] Iter[201/  6]\t\tLoss: 14.5652 Acc@1: 45.538%\n",
            "| Epoch [ 35/ 50] Iter[251/  6]\t\tLoss: 17.0927 Acc@1: 45.412%\n",
            "| Epoch [ 35/ 50] Iter[301/  6]\t\tLoss: 18.6800 Acc@1: 45.380%\n",
            "\n",
            "| Validation Epoch #35\t\t\tLoss: 13.0505 Acc@1: 45.71%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 36/ 50] Iter[  1/  6]\t\tLoss: 15.1305 Acc@1: 39.062%\n",
            "| Epoch [ 36/ 50] Iter[ 51/  6]\t\tLoss: 18.3808 Acc@1: 45.558%\n",
            "| Epoch [ 36/ 50] Iter[101/  6]\t\tLoss: 22.2336 Acc@1: 44.787%\n",
            "| Epoch [ 36/ 50] Iter[151/  6]\t\tLoss: 12.7377 Acc@1: 45.633%\n",
            "| Epoch [ 36/ 50] Iter[201/  6]\t\tLoss: 14.5762 Acc@1: 45.499%\n",
            "| Epoch [ 36/ 50] Iter[251/  6]\t\tLoss: 16.8119 Acc@1: 45.636%\n",
            "| Epoch [ 36/ 50] Iter[301/  6]\t\tLoss: 15.6983 Acc@1: 45.494%\n",
            "\n",
            "| Validation Epoch #36\t\t\tLoss: 16.6768 Acc@1: 45.63%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 37/ 50] Iter[  1/  6]\t\tLoss: 11.6404 Acc@1: 54.688%\n",
            "| Epoch [ 37/ 50] Iter[ 51/  6]\t\tLoss: 16.8901 Acc@1: 44.914%\n",
            "| Epoch [ 37/ 50] Iter[101/  6]\t\tLoss: 15.0662 Acc@1: 45.003%\n",
            "| Epoch [ 37/ 50] Iter[151/  6]\t\tLoss: 9.2920 Acc@1: 45.199%\n",
            "| Epoch [ 37/ 50] Iter[201/  6]\t\tLoss: 15.0876 Acc@1: 45.328%\n",
            "| Epoch [ 37/ 50] Iter[251/  6]\t\tLoss: 16.5175 Acc@1: 45.325%\n",
            "| Epoch [ 37/ 50] Iter[301/  6]\t\tLoss: 17.2540 Acc@1: 45.442%\n",
            "\n",
            "| Validation Epoch #37\t\t\tLoss: 19.6699 Acc@1: 45.59%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 38/ 50] Iter[  1/  6]\t\tLoss: 18.3208 Acc@1: 39.062%\n",
            "| Epoch [ 38/ 50] Iter[ 51/  6]\t\tLoss: 18.8738 Acc@1: 45.619%\n",
            "| Epoch [ 38/ 50] Iter[101/  6]\t\tLoss: 16.8535 Acc@1: 45.266%\n",
            "| Epoch [ 38/ 50] Iter[151/  6]\t\tLoss: 12.8287 Acc@1: 45.302%\n",
            "| Epoch [ 38/ 50] Iter[201/  6]\t\tLoss: 13.2901 Acc@1: 45.429%\n",
            "| Epoch [ 38/ 50] Iter[251/  6]\t\tLoss: 15.8415 Acc@1: 45.543%\n",
            "| Epoch [ 38/ 50] Iter[301/  6]\t\tLoss: 13.9175 Acc@1: 45.541%\n",
            "\n",
            "| Validation Epoch #38\t\t\tLoss: 16.8766 Acc@1: 45.66%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 39/ 50] Iter[  1/  6]\t\tLoss: 18.1185 Acc@1: 43.750%\n",
            "| Epoch [ 39/ 50] Iter[ 51/  6]\t\tLoss: 15.2251 Acc@1: 45.895%\n",
            "| Epoch [ 39/ 50] Iter[101/  6]\t\tLoss: 14.6693 Acc@1: 46.705%\n",
            "| Epoch [ 39/ 50] Iter[151/  6]\t\tLoss: 20.5216 Acc@1: 46.130%\n",
            "| Epoch [ 39/ 50] Iter[201/  6]\t\tLoss: 17.0410 Acc@1: 45.981%\n",
            "| Epoch [ 39/ 50] Iter[251/  6]\t\tLoss: 17.8526 Acc@1: 45.748%\n",
            "| Epoch [ 39/ 50] Iter[301/  6]\t\tLoss: 14.6293 Acc@1: 45.759%\n",
            "\n",
            "| Validation Epoch #39\t\t\tLoss: 18.3838 Acc@1: 45.69%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 40/ 50] Iter[  1/  6]\t\tLoss: 17.2018 Acc@1: 39.062%\n",
            "| Epoch [ 40/ 50] Iter[ 51/  6]\t\tLoss: 18.6134 Acc@1: 45.864%\n",
            "| Epoch [ 40/ 50] Iter[101/  6]\t\tLoss: 14.3054 Acc@1: 45.885%\n",
            "| Epoch [ 40/ 50] Iter[151/  6]\t\tLoss: 19.8259 Acc@1: 46.026%\n",
            "| Epoch [ 40/ 50] Iter[201/  6]\t\tLoss: 15.6272 Acc@1: 45.888%\n",
            "| Epoch [ 40/ 50] Iter[251/  6]\t\tLoss: 15.2454 Acc@1: 45.754%\n",
            "| Epoch [ 40/ 50] Iter[301/  6]\t\tLoss: 19.4803 Acc@1: 45.562%\n",
            "\n",
            "| Validation Epoch #40\t\t\tLoss: 28.9462 Acc@1: 45.74%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 41/ 50] Iter[  1/  6]\t\tLoss: 11.0800 Acc@1: 56.250%\n",
            "| Epoch [ 41/ 50] Iter[ 51/  6]\t\tLoss: 15.2050 Acc@1: 46.415%\n",
            "| Epoch [ 41/ 50] Iter[101/  6]\t\tLoss: 18.8351 Acc@1: 45.823%\n",
            "| Epoch [ 41/ 50] Iter[151/  6]\t\tLoss: 12.3562 Acc@1: 45.530%\n",
            "| Epoch [ 41/ 50] Iter[201/  6]\t\tLoss: 14.9907 Acc@1: 45.577%\n",
            "| Epoch [ 41/ 50] Iter[251/  6]\t\tLoss: 15.8499 Acc@1: 45.462%\n",
            "| Epoch [ 41/ 50] Iter[301/  6]\t\tLoss: 19.9989 Acc@1: 45.577%\n",
            "\n",
            "| Validation Epoch #41\t\t\tLoss: 8.8379 Acc@1: 45.74%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 42/ 50] Iter[  1/  6]\t\tLoss: 15.0168 Acc@1: 42.188%\n",
            "| Epoch [ 42/ 50] Iter[ 51/  6]\t\tLoss: 17.9128 Acc@1: 45.741%\n",
            "| Epoch [ 42/ 50] Iter[101/  6]\t\tLoss: 20.1955 Acc@1: 45.684%\n",
            "| Epoch [ 42/ 50] Iter[151/  6]\t\tLoss: 14.2027 Acc@1: 44.971%\n",
            "| Epoch [ 42/ 50] Iter[201/  6]\t\tLoss: 14.6810 Acc@1: 45.204%\n",
            "| Epoch [ 42/ 50] Iter[251/  6]\t\tLoss: 20.0092 Acc@1: 45.580%\n",
            "| Epoch [ 42/ 50] Iter[301/  6]\t\tLoss: 18.4062 Acc@1: 45.707%\n",
            "\n",
            "| Validation Epoch #42\t\t\tLoss: 20.7612 Acc@1: 45.90%\n",
            "lr = 1.0000000000000002e-07\n",
            "| Epoch [ 43/ 50] Iter[  1/  6]\t\tLoss: 15.6108 Acc@1: 48.438%\n",
            "| Epoch [ 43/ 50] Iter[ 51/  6]\t\tLoss: 15.4180 Acc@1: 46.446%\n",
            "| Epoch [ 43/ 50] Iter[101/  6]\t\tLoss: 14.1152 Acc@1: 46.364%\n",
            "| Epoch [ 43/ 50] Iter[151/  6]\t\tLoss: 13.5000 Acc@1: 46.161%\n",
            "| Epoch [ 43/ 50] Iter[201/  6]\t\tLoss: 16.4555 Acc@1: 45.833%\n",
            "| Epoch [ 43/ 50] Iter[251/  6]\t\tLoss: 16.1323 Acc@1: 45.655%\n",
            "| Epoch [ 43/ 50] Iter[301/  6]\t\tLoss: 14.3988 Acc@1: 45.712%\n",
            "\n",
            "| Validation Epoch #43\t\t\tLoss: 17.4396 Acc@1: 45.91%\n",
            "lr = 1.0000000000000002e-07\n",
            "| Epoch [ 44/ 50] Iter[  1/  6]\t\tLoss: 15.6060 Acc@1: 37.500%\n",
            "| Epoch [ 44/ 50] Iter[ 51/  6]\t\tLoss: 8.5370 Acc@1: 46.078%\n",
            "| Epoch [ 44/ 50] Iter[101/  6]\t\tLoss: 14.6072 Acc@1: 45.591%\n",
            "| Epoch [ 44/ 50] Iter[151/  6]\t\tLoss: 16.4035 Acc@1: 45.695%\n",
            "| Epoch [ 44/ 50] Iter[201/  6]\t\tLoss: 14.6674 Acc@1: 45.577%\n",
            "| Epoch [ 44/ 50] Iter[251/  6]\t\tLoss: 16.8322 Acc@1: 45.449%\n",
            "| Epoch [ 44/ 50] Iter[301/  6]\t\tLoss: 11.5830 Acc@1: 45.588%\n",
            "\n",
            "| Validation Epoch #44\t\t\tLoss: 10.8688 Acc@1: 45.94%\n",
            "lr = 1.0000000000000002e-07\n",
            "| Epoch [ 45/ 50] Iter[  1/  6]\t\tLoss: 16.1105 Acc@1: 37.500%\n",
            "| Epoch [ 45/ 50] Iter[ 51/  6]\t\tLoss: 14.6191 Acc@1: 44.363%\n",
            "| Epoch [ 45/ 50] Iter[101/  6]\t\tLoss: 15.3713 Acc@1: 45.761%\n",
            "| Epoch [ 45/ 50] Iter[151/  6]\t\tLoss: 11.8290 Acc@1: 45.644%\n",
            "| Epoch [ 45/ 50] Iter[201/  6]\t\tLoss: 15.4746 Acc@1: 45.973%\n",
            "| Epoch [ 45/ 50] Iter[251/  6]\t\tLoss: 9.0411 Acc@1: 45.941%\n",
            "| Epoch [ 45/ 50] Iter[301/  6]\t\tLoss: 10.3979 Acc@1: 45.629%\n",
            "\n",
            "| Validation Epoch #45\t\t\tLoss: 12.7373 Acc@1: 45.95%\n",
            "lr = 1.0000000000000002e-07\n",
            "| Epoch [ 46/ 50] Iter[  1/  6]\t\tLoss: 13.4597 Acc@1: 54.688%\n",
            "| Epoch [ 46/ 50] Iter[ 51/  6]\t\tLoss: 17.4580 Acc@1: 45.619%\n",
            "| Epoch [ 46/ 50] Iter[101/  6]\t\tLoss: 13.0727 Acc@1: 45.993%\n",
            "| Epoch [ 46/ 50] Iter[151/  6]\t\tLoss: 17.7926 Acc@1: 45.695%\n",
            "| Epoch [ 46/ 50] Iter[201/  6]\t\tLoss: 18.8942 Acc@1: 45.452%\n",
            "| Epoch [ 46/ 50] Iter[251/  6]\t\tLoss: 14.6253 Acc@1: 45.655%\n",
            "| Epoch [ 46/ 50] Iter[301/  6]\t\tLoss: 19.7419 Acc@1: 45.712%\n",
            "\n",
            "| Validation Epoch #46\t\t\tLoss: 17.7762 Acc@1: 45.98%\n",
            "lr = 1.0000000000000002e-07\n",
            "| Epoch [ 47/ 50] Iter[  1/  6]\t\tLoss: 14.9109 Acc@1: 40.625%\n",
            "| Epoch [ 47/ 50] Iter[ 51/  6]\t\tLoss: 16.0574 Acc@1: 45.772%\n",
            "| Epoch [ 47/ 50] Iter[101/  6]\t\tLoss: 11.0929 Acc@1: 45.575%\n",
            "| Epoch [ 47/ 50] Iter[151/  6]\t\tLoss: 15.2649 Acc@1: 45.799%\n",
            "| Epoch [ 47/ 50] Iter[201/  6]\t\tLoss: 12.2455 Acc@1: 45.476%\n",
            "| Epoch [ 47/ 50] Iter[251/  6]\t\tLoss: 12.2677 Acc@1: 45.630%\n",
            "| Epoch [ 47/ 50] Iter[301/  6]\t\tLoss: 16.0034 Acc@1: 45.567%\n",
            "\n",
            "| Validation Epoch #47\t\t\tLoss: 11.9211 Acc@1: 45.98%\n",
            "lr = 1.0000000000000002e-07\n",
            "Best RMSE is of : 15.708092168525413 for epoch : 47 ERROR TEST =  (15.708092168525413, tensor(45.9825))\n",
            "| Epoch [ 48/ 50] Iter[  1/  6]\t\tLoss: 12.4441 Acc@1: 53.125%\n",
            "| Epoch [ 48/ 50] Iter[ 51/  6]\t\tLoss: 15.8227 Acc@1: 45.159%\n",
            "| Epoch [ 48/ 50] Iter[101/  6]\t\tLoss: 15.8782 Acc@1: 45.591%\n",
            "| Epoch [ 48/ 50] Iter[151/  6]\t\tLoss: 12.7598 Acc@1: 45.882%\n",
            "| Epoch [ 48/ 50] Iter[201/  6]\t\tLoss: 10.5969 Acc@1: 45.864%\n",
            "| Epoch [ 48/ 50] Iter[251/  6]\t\tLoss: 10.2249 Acc@1: 45.935%\n",
            "| Epoch [ 48/ 50] Iter[301/  6]\t\tLoss: 12.6033 Acc@1: 45.790%\n",
            "\n",
            "| Validation Epoch #48\t\t\tLoss: 15.5218 Acc@1: 46.00%\n",
            "lr = 1.0000000000000002e-07\n",
            "| Epoch [ 49/ 50] Iter[  1/  6]\t\tLoss: 15.8976 Acc@1: 50.000%\n",
            "| Epoch [ 49/ 50] Iter[ 51/  6]\t\tLoss: 14.5700 Acc@1: 46.752%\n",
            "| Epoch [ 49/ 50] Iter[101/  6]\t\tLoss: 16.9401 Acc@1: 46.086%\n",
            "| Epoch [ 49/ 50] Iter[151/  6]\t\tLoss: 18.0238 Acc@1: 45.385%\n",
            "| Epoch [ 49/ 50] Iter[201/  6]\t\tLoss: 15.1676 Acc@1: 45.491%\n",
            "| Epoch [ 49/ 50] Iter[251/  6]\t\tLoss: 16.4981 Acc@1: 45.611%\n",
            "| Epoch [ 49/ 50] Iter[301/  6]\t\tLoss: 15.0821 Acc@1: 45.868%\n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 7.8728 Acc@1: 46.03%\n",
            "lr = 1.0000000000000002e-07\n",
            "Best RMSE is of : 15.647475220538952 for epoch : 49 ERROR TEST =  (15.647475220538952, tensor(46.0262))\n",
            "Training Done!\n",
            "==================== \n",
            "Test set = \n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 15.2746 Acc@1: 45.87%\n",
            "==================== \n"
          ]
        }
      ],
      "source": [
        "PRETRAINED_MODEL = \"bert-base-uncased\"\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "EPOCHS = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Custom Dataset\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
        "traindataset = TextDataset(train_x, train_y, tokenizer, MAX_LENGTH)\n",
        "trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "valdataset = TextDataset(val_x, val_y, tokenizer, MAX_LENGTH)\n",
        "valloader = DataLoader(valdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "bert = BertModel.from_pretrained(PRETRAINED_MODEL).to(device)\n",
        "# Extract embeddings\n",
        "train_embeddings = extract_embeddings(bert, trainloader, device)\n",
        "train_embeddings =train_embeddings.cpu()\n",
        "\n",
        "val_embeddings = extract_embeddings(bert, valloader, device)\n",
        "val_embeddings =val_embeddings.cpu()\n",
        "\n",
        "\n",
        "print(train_embeddings.size())\n",
        "print(val_embeddings.size())\n",
        "\n",
        "\n",
        "criterion= nn.CrossEntropyLoss()\n",
        "\n",
        "# Model Definition\n",
        "\n",
        "# training script\n",
        "\n",
        "# testing script\n",
        "\n",
        "print (\"Let us Train.\")\n",
        "EPOCHS = 50\n",
        "model = SentimentClassifier(1024, NUM_CLASSES).to(device)\n",
        "model_test = SentimentClassifier(1024, NUM_CLASSES).to(device)\n",
        "best_error = float('inf')\n",
        "LEARNING_RATE = 1e-3\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau,StepLR\n",
        "\n",
        "traindataset = EmbeddingDataset(train_embeddings, train_y)\n",
        "trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valdataset = EmbeddingDataset(val_embeddings, val_y)\n",
        "valloader = DataLoader(valdataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "#lr_scheduler =  StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "lr_scheduler = ReduceLROnPlateau(optimizer, 'min', patience=7)\n",
        "\n",
        "train_history = []\n",
        "val_history = []\n",
        "\n",
        "print('----------------------------------------------------------------------------------------------------')\n",
        "print('3/ training model 2')\n",
        "print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "iter =0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    loss = train(model, trainloader, optimizer, epoch)\n",
        "    train_history.append(loss)\n",
        "    #lr_scheduler.step()\n",
        "    val_loss= test(model, valloader,epoch)\n",
        "    val_history.append(val_loss[0])\n",
        "    lr_scheduler.step(val_loss[0])\n",
        "    print('lr =',get_lr(optimizer))\n",
        "\n",
        "    if val_loss[0] <best_error:\n",
        "        best_error=val_loss[0]\n",
        "        print('Best RMSE is of : ' + str(best_error), 'for epoch :', epoch,'ERROR TEST = ',val_loss)\n",
        "        #model_test.parameters()=model.state_dict()\n",
        "        model_test.load_state_dict(model.state_dict(), strict=True)\n",
        "\n",
        "print (\"Training Done!\")\n",
        "\n",
        "testdataset = TextDataset(test_x,test_y, tokenizer, MAX_LENGTH)\n",
        "testloader = DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "bert = BertModel.from_pretrained(PRETRAINED_MODEL).to(device)\n",
        "# Extract embeddings\n",
        "\n",
        "test_embeddings = extract_embeddings(bert, testloader, device)\n",
        "test_embeddings =test_embeddings.cpu()\n",
        "print('==================== ')\n",
        "print('Test set = ')\n",
        "testdataset = EmbeddingDataset(test_embeddings, test_y)\n",
        "testdataset = DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loss,accu = test(model, testdataset,epoch)\n",
        "\n",
        "print('==================== ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SentimentClassifier(\n",
            "  (fc): Linear(in_features=1024, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#printing the model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\elyes\\anaconda3\\lib\\site-packages (4.48.0)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Collecting peft\n",
            "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: datasets in c:\\users\\elyes\\anaconda3\\lib\\site-packages (3.2.0)\n",
            "Requirement already satisfied: torch in c:\\users\\elyes\\anaconda3\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: psutil in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from peft) (5.9.0)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from peft) (1.2.1)\n",
            "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: setuptools in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: colorama in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\elyes\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
            "Downloading huggingface_hub-0.28.0-py3-none-any.whl (464 kB)\n",
            "Installing collected packages: huggingface-hub, peft\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 0.24.6\n",
            "    Uninstalling huggingface_hub-0.24.6:\n",
            "      Successfully uninstalled huggingface_hub-0.24.6\n",
            "Successfully installed huggingface-hub-0.28.0 peft-0.14.0\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers peft datasets torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error importing huggingface_hub._snapshot_download: cannot import name 'GatedRepoError' from 'huggingface_hub.errors' (c:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\huggingface_hub\\errors.py)\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'GatedRepoError' from 'huggingface_hub.errors' (c:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\huggingface_hub\\errors.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_peft_model, LoraConfig, TaskType\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSequenceClassification, TrainingArguments, Trainer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1. LoRA Configuration\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\peft\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.14.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     AutoPeftModel,\n\u001b[0;32m     24\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[0;32m     25\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[0;32m     26\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[0;32m     27\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[0;32m     28\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[0;32m     29\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[0;32m     33\u001b[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     inject_adapter_in_model,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftMixedModel\n",
            "File \u001b[1;32mc:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\peft\\auto.py:31\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     AutoModel,\n\u001b[0;32m     23\u001b[0m     AutoModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     AutoTokenizer,\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     34\u001b[0m     PeftModel,\n\u001b[0;32m     35\u001b[0m     PeftModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     41\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\peft\\config.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hf_hub_download\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CONFIG_NAME, PeftType, TaskType\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# we expect at least these keys to be present in a PEFT adapter_config.json\u001b[39;00m\n\u001b[0;32m     28\u001b[0m MIN_EXPECTED_CONFIG_KEYS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeft_type\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
            "File \u001b[1;32mc:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\peft\\utils\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# module, but to preserve other warnings. So, don't check this module at all\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# from .config import PeftConfig, PeftType, PromptLearningConfig, TaskType\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_cache_to_layer_device_map\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloftq_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m replace_lora_weights_loftq\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftType, TaskType\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mother\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING,\n\u001b[0;32m     26\u001b[0m     TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     cast_mixed_precision_params,\n\u001b[0;32m     55\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\peft\\utils\\loftq_utils.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Optional, Union\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m snapshot_download\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HFValidationError, LocalEntryNotFoundError\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msafetensors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SafetensorError, safe_open\n",
            "File \u001b[1;32mc:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\huggingface_hub\\__init__.py:520\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     54\u001b[0m _SUBMOD_ATTRS \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_scheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommitScheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m     ],\n\u001b[0;32m    497\u001b[0m }\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# WARNING: __all__ is generated automatically, Any manual edit will be lost when re-generating this file !\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m# To update the static imports, please run the following command and commit the changes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# make style\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# ```\u001b[39;00m\n\u001b[0;32m    510\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsyncInferenceClient\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudioClassificationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudioClassificationOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudioClassificationOutputTransform\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudioClassificationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudioToAudioInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAudioToAudioOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutomaticSpeechRecognitionEarlyStoppingEnum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutomaticSpeechRecognitionGenerationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutomaticSpeechRecognitionInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutomaticSpeechRecognitionOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutomaticSpeechRecognitionOutputChunk\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutomaticSpeechRecognitionParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCONFIG_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCacheNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCachedFileInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCachedRepoInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCachedRevisionInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCardData\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputFunctionDefinition\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputFunctionName\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputGrammarType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputGrammarTypeType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputMessageChunk\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputMessageChunkType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputStreamOptions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputTool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputToolChoiceClass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputToolChoiceEnum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionInputURL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionOutputComplete\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionOutputFunctionDefinition\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionOutputLogprob\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionOutputLogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionOutputMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionOutputToolCall\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionOutputTopLogprob\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionOutputUsage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionStreamOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionStreamOutputChoice\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionStreamOutputDelta\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionStreamOutputDeltaToolCall\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionStreamOutputFunction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionStreamOutputLogprob\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionStreamOutputLogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionStreamOutputTopLogprob\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionStreamOutputUsage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollectionItem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommitInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommitOperation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommitOperationAdd\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommitOperationCopy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommitOperationDelete\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommitScheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorruptedCacheException\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDDUFEntry\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetCard\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetCardData\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeleteCacheStrategy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDepthEstimationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDepthEstimationOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscussion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscussionComment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscussionCommit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscussionEvent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscussionStatusChange\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscussionTitleChange\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscussionWithDetails\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocumentQuestionAnsweringInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocumentQuestionAnsweringInputData\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocumentQuestionAnsweringOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocumentQuestionAnsweringParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvalResult\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLAX_WEIGHTS_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatureExtractionInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatureExtractionInputTruncationDirection\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFillMaskInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFillMaskOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFillMaskParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGitCommitInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGitRefInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGitRefs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHFCacheInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHFSummaryWriter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHUGGINGFACE_CO_URL_HOME\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHUGGINGFACE_CO_URL_TEMPLATE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHfApi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHfFileMetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHfFileSystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHfFileSystemFile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHfFileSystemResolvedPath\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHfFileSystemStreamFile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHfFolder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageClassificationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageClassificationOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageClassificationOutputTransform\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageClassificationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageSegmentationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageSegmentationOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageSegmentationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageSegmentationSubtask\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageToImageInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageToImageOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageToImageParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageToImageTargetSize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageToTextEarlyStoppingEnum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageToTextGenerationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageToTextInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageToTextOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageToTextParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceApi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceClient\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceEndpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceEndpointError\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceEndpointStatus\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceEndpointTimeoutError\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceEndpointType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceTimeoutError\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKerasModelHubMixin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelCard\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelCardData\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelHubMixin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjectDetectionBoundingBox\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjectDetectionInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjectDetectionOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjectDetectionParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTORCH_WEIGHTS_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPadding\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorchModelHubMixin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestionAnsweringInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestionAnsweringInputData\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestionAnsweringOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestionAnsweringParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREPO_TYPE_DATASET\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREPO_TYPE_MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREPO_TYPE_SPACE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoCard\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoUrl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepository\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentenceSimilarityInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentenceSimilarityInputData\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpaceCard\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpaceCardData\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpaceHardware\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpaceInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpaceRuntime\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpaceStage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpaceStorage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpaceVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStateDictSplit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarizationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarizationOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarizationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarizationTruncationStrategy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    671\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF2_WEIGHTS_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF_WEIGHTS_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTableQuestionAnsweringInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTableQuestionAnsweringInputData\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTableQuestionAnsweringOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTableQuestionAnsweringParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText2TextGenerationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText2TextGenerationOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText2TextGenerationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText2TextGenerationTruncationStrategy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextClassificationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextClassificationOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextClassificationOutputTransform\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextClassificationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationInputGenerateParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationInputGrammarType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationOutputBestOfSequence\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationOutputDetails\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationOutputFinishReason\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationOutputPrefillToken\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationOutputToken\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationStreamOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationStreamOutputStreamDetails\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextGenerationStreamOutputToken\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToAudioEarlyStoppingEnum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToAudioGenerationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToAudioInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToAudioOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToAudioParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToImageInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToImageOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToImageParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToImageTargetSize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToSpeechEarlyStoppingEnum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToSpeechGenerationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToSpeechInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToSpeechOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToSpeechParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToVideoInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToVideoOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextToVideoParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenClassificationAggregationStrategy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenClassificationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenClassificationOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenClassificationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslationOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslationTruncationStrategy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTypeEnum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    724\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUserLikes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideoClassificationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideoClassificationOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideoClassificationOutputTransform\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideoClassificationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    729\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualQuestionAnsweringInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualQuestionAnsweringInputData\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualQuestionAnsweringOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualQuestionAnsweringParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhookInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhookPayload\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhookPayloadComment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhookPayloadDiscussion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhookPayloadDiscussionChanges\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhookPayloadEvent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhookPayloadMovedTo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhookPayloadRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhookPayloadUrl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhookPayloadWebhook\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhookWatchedItem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebhooksServer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeroShotClassificationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeroShotClassificationOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeroShotClassificationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeroShotImageClassificationInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeroShotImageClassificationOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeroShotImageClassificationParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeroShotObjectDetectionBoundingBox\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeroShotObjectDetectionInput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeroShotObjectDetectionOutputElement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZeroShotObjectDetectionParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_CACHED_NO_EXIST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_save_pretrained_fastai\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept_access_request\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_collection_item\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_space_secret\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_space_variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth_check\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth_list\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth_switch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcached_assets_path\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancel_access_request\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchange_discussion_status\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_discussion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigure_http_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_branch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_collection\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_commit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_discussion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_inference_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_pull_request\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_repo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_tag\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_webhook\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_info\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_branch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_collection\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_collection_item\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_file\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_folder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_inference_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_repo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_space_secret\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_space_storage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_space_variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_tag\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelete_webhook\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_webhook\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdump_environment_info\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduplicate_space\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medit_discussion_comment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_webhook\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport_entries_as_dduf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport_folder_as_dduf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_exists\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_pretrained_fastai\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_pretrained_keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_collection\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_dataset_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_discussion_details\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_full_repo_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_hf_file_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_inference_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_model_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_paths_info\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_repo_discussions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_safetensors_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_session\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_space_runtime\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_space_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_tf_storage_size\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_token\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    816\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_token_permission\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_torch_storage_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_torch_storage_size\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_user_overview\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_webhook\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrant_access\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_hub_download\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_hub_url\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterpreter_login\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_accepted_access_requests\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_collections\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_inference_endpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_liked_repos\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_models\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_organization_members\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_papers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_pending_access_requests\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_rejected_access_requests\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_repo_commits\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_repo_files\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_repo_likers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_repo_refs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_repo_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_spaces\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_user_followers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_user_following\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_webhooks\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_state_dict_from_file\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_torch_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogging\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    848\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerge_pull_request\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_eval_result\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_load\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_save\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_update\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_info\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmove_repo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebook_login\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaper_info\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparse_safetensors_file_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpause_inference_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpause_space\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreupload_lfs_files\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpush_to_hub_fastai\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpush_to_hub_keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_dduf_file\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreject_access_request\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrename_discussion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_exists\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_info\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_type_and_id_from_hf_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_space_hardware\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_space_storage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestart_space\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume_inference_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision_exists\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_as_future\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_pretrained_keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_torch_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_torch_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_to_zero_inference_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscan_cache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_space_sleep_time\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnapshot_download\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspace_info\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_state_dict_into_shards_factory\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_tf_state_dict_into_shards\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_torch_state_dict_into_shards\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuper_squash_history\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtry_to_load_from_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlike\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_collection_item\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_collection_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_inference_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_repo_settings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_repo_visibility\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_webhook\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupload_file\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupload_folder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupload_large_folder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwebhook_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhoami\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    901\u001b[0m ]\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_attach\u001b[39m(package_name, submodules\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, submod_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Attach lazily loaded submodules, functions, or other attributes.\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \n\u001b[0;32m    907\u001b[0m \u001b[38;5;124;03m    Typically, modules import submodules and attributes as follows:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    942\u001b[0m \n\u001b[0;32m    943\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\elyes\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
            "File \u001b[1;32mc:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\huggingface_hub\\_snapshot_download.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GatedRepoError, LocalEntryNotFoundError, RepositoryNotFoundError, RevisionNotFoundError\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_download\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m REGEX_COMMIT_HASH, hf_hub_download, repo_folder_name\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhf_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetInfo, HfApi, ModelInfo, SpaceInfo\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'GatedRepoError' from 'huggingface_hub.errors' (c:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\huggingface_hub\\errors.py)"
          ]
        }
      ],
      "source": [
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# 1. LoRA Configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,  # rank of update matrices\n",
        "    lora_alpha=32,  # scaling factor\n",
        "    target_modules=[\"query\", \"value\"],  # layers to apply LoRA\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_CLS\n",
        ")\n",
        "\n",
        "# 2. Load base model\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=NUM_CLASSES\n",
        ")\n",
        "\n",
        "# 3. Create LoRA model\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "print(f\"Trainable parameters: {lora_model.print_trainable_parameters()}\")\n",
        "\n",
        "# 4. Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./lora_sentiment_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# 5. Format dataset\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# 6. Prepare datasets\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "train_dataset = SentimentDataset(train_x, train_y, tokenizer)\n",
        "val_dataset = SentimentDataset(val_x, val_y, tokenizer)\n",
        "\n",
        "# 7. Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "# 8. Train\n",
        "trainer.train()\n",
        "\n",
        "# 9. Save model\n",
        "lora_model.save_pretrained(\"./lora_sentiment_model_final\")\n",
        "\n",
        "# 10. Inference\n",
        "def predict(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = lora_model(**inputs)\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of KNN model is : 0.46066779852857953\n"
          ]
        }
      ],
      "source": [
        "## KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Elbow method to find the best K\n",
        "k_range = range(1, 10)\n",
        "scores = []\n",
        "for k in k_range:\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn_model.fit(train_embeddings, train_y)\n",
        "    knn_predictions = knn_model.predict(val_embeddings)\n",
        "    scores.append(accuracy_score(val_y, knn_predictions))\n",
        "plt.plot(k_range, scores)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Accuracy Scores for Values of K of K-Nearest-Neighbors')\n",
        "plt.show()\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(train_embeddings, train_y)\n",
        "yhat = knn_model.predict(test_embeddings)\n",
        "print('Accuracy of KNN model is :',accuracy_score(test_y, yhat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUIRWJllOee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (newton-cg) Accuracy: 0.64\n",
            "Logistic Regression (lbfgs) Accuracy: 0.64\n",
            "Logistic Regression (sag) Accuracy: 0.64\n"
          ]
        }
      ],
      "source": [
        "## QUESTION 0 and 1 :\n",
        "import sklearn\n",
        "## LOGISTIC REGRESSION\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "for solver in ['newton-cg', 'lbfgs', 'sag', 'saga']:\n",
        "    logistic_model = LogisticRegression(max_iter=1000, solver=solver,C=10, random_state=42)\n",
        "    logistic_model.fit(train_embeddings, train_y)\n",
        "    logistic_predictions = logistic_model.predict(val_embeddings)\n",
        "    logistic_accuracy = accuracy_score(val_y, logistic_predictions)\n",
        "    print(f'Logistic Regression ({solver}) Accuracy: {logistic_accuracy:.2f}')\n",
        "    yhat = logistic_model.predict(test_embeddings)\n",
        "    acc = accuracy_score(test_y, yhat)\n",
        "    print(f'Logistic Regression ({solver}) Accuracy: {acc:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Validation Accuracy: 0.42\n",
            "Decision Tree Test Accuracy: 0.42\n"
          ]
        }
      ],
      "source": [
        "## DECISION TREE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree_model.fit(train_embeddings, train_y)\n",
        "decision_tree_predictions = decision_tree_model.predict(val_embeddings)\n",
        "decision_tree_accuracy = accuracy_score(val_y, decision_tree_predictions)\n",
        "print(f'Decision Tree Validation Accuracy: {decision_tree_accuracy:.2f}')\n",
        "yhat = decision_tree_model.predict(test_embeddings)\n",
        "acc = accuracy_score(test_y, yhat)\n",
        "print(f'Decision Tree Test Accuracy: {acc:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Validation Accuracy: 0.54\n",
            "Random Forest Test Accuracy: 0.55\n"
          ]
        }
      ],
      "source": [
        "## RANDOM FOREST\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest_model = RandomForestClassifier(random_state=42, n_estimators=100,)\n",
        "random_forest_model.fit(train_embeddings, train_y)\n",
        "random_forest_predictions = random_forest_model.predict(val_embeddings)\n",
        "random_forest_accuracy = accuracy_score(val_y, random_forest_predictions)\n",
        "print(f'Random Forest Validation Accuracy: {random_forest_accuracy:.2f}')\n",
        "yhat = random_forest_model.predict(test_embeddings)\n",
        "acc = accuracy_score(test_y, yhat)\n",
        "print(f'Random Forest Test Accuracy: {acc:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM (linear, C=0.1) Validation Accuracy: 0.63\n",
            "SVM (linear, C=0.1) Test Accuracy: 0.64\n",
            "SVM (linear, C=1) Validation Accuracy: 0.65\n",
            "SVM (linear, C=1) Test Accuracy: 0.65\n"
          ]
        }
      ],
      "source": [
        "## SVM with parameters and hyperparameters\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
        "    for C in [0.1, 1, 10]:\n",
        "        svm_model = SVC(kernel=kernel, C=C, random_state=42)\n",
        "        svm_model.fit(train_embeddings, train_y)\n",
        "        svm_predictions = svm_model.predict(val_embeddings)\n",
        "        svm_accuracy = accuracy_score(val_y, svm_predictions)\n",
        "        print(f'SVM ({kernel}, C={C}) Validation Accuracy: {svm_accuracy:.2f}')\n",
        "        yhat = svm_model.predict(test_embeddings)\n",
        "        acc = accuracy_score(test_y, yhat)\n",
        "        print(f'SVM ({kernel}, C={C}) Test Accuracy: {acc:.2f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Validation Accuracy: 0.4473\n",
            "Epoch 2/10, Validation Accuracy: 0.3728\n",
            "Epoch 3/10, Validation Accuracy: 0.4437\n",
            "Epoch 4/10, Validation Accuracy: 0.5361\n",
            "Epoch 5/10, Validation Accuracy: 0.5876\n",
            "Epoch 6/10, Validation Accuracy: 0.4028\n",
            "Epoch 7/10, Validation Accuracy: 0.5907\n",
            "Epoch 8/10, Validation Accuracy: 0.6044\n",
            "Epoch 9/10, Validation Accuracy: 0.5951\n",
            "Epoch 10/10, Validation Accuracy: 0.4611\n",
            "Test Accuracy: 0.4595\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.15      0.25      1001\n",
            "           1       0.54      0.32      0.40      1430\n",
            "           2       0.41      0.93      0.57      1103\n",
            "\n",
            "    accuracy                           0.46      3534\n",
            "   macro avg       0.58      0.46      0.40      3534\n",
            "weighted avg       0.57      0.46      0.41      3534\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Assuming you have these already:\n",
        "# train_embeddings  (Tensor)\n",
        "# train_y          (List or numpy array)\n",
        "# val_embeddings    (Tensor)\n",
        "# val_y            (List or numpy array)\n",
        "# test_embeddings   (Tensor)\n",
        "# test_y           (List or numpy array)\n",
        "# NUM_CLASSES      (int, the number of sentiment classes)\n",
        "# device           (torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# 1. Create TensorDatasets and DataLoaders\n",
        "train_dataset = TensorDataset(train_embeddings, torch.tensor(train_y, dtype=torch.long))\n",
        "val_dataset = TensorDataset(val_embeddings, torch.tensor(val_y, dtype=torch.long))\n",
        "test_dataset = TensorDataset(test_embeddings, torch.tensor(test_y, dtype=torch.long))\n",
        "\n",
        "BATCH_SIZE = 128  # Adjust as needed\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "# 2. Define the MLP Model\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "input_size = train_embeddings.shape[1]\n",
        "hidden_size = 512  # Experiment with this value\n",
        "mlp_model = MLPClassifier(input_size, hidden_size, NUM_CLASSES).to(device)\n",
        "\n",
        "\n",
        "# 3. Training Loop\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=1e-3)  # Adjust learning rate\n",
        "\n",
        "EPOCHS = 10  # Adjust as needed\n",
        "for epoch in range(EPOCHS):\n",
        "    for batch in train_loader:\n",
        "        embeddings, labels = batch\n",
        "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = mlp_model(embeddings)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        val_predictions = []\n",
        "        for batch in val_loader:\n",
        "            embeddings, labels = batch\n",
        "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
        "            outputs = mlp_model(embeddings)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_predictions.extend(predicted.cpu().numpy())\n",
        "        val_accuracy = accuracy_score(val_y, val_predictions)\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# 4. Evaluation on Test Set\n",
        "with torch.no_grad():\n",
        "    test_predictions = []\n",
        "    for batch in test_loader:\n",
        "        embeddings, labels = batch\n",
        "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
        "        outputs = mlp_model(embeddings)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_predictions.extend(predicted.cpu().numpy())\n",
        "    test_accuracy = accuracy_score(test_y, test_predictions)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "    print(classification_report(test_y, test_predictions)) # Detailed report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2611f4f3e6424b98aa7ce264f8bca853",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\elyes\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\elyes\\.cache\\huggingface\\hub\\models--facebook--bart-large-mnli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2583d03ef3914b0986ba1bdd9af8b027",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6862db7ed65f44e8a6fe0abeac71d6d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e387d6af84ca474faaeb61a103f9e07b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8d673cd8d054021951212d808494bed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4123c9962244f69bb938ee298133270",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'test_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m candidate_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m  \u001b[38;5;66;03m# Start with a smaller batch size; adjust as needed based on GPU memory\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     14\u001b[0m llm_predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m n_samples\n\u001b[0;32m     15\u001b[0m original_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "\u001b[1;31mNameError\u001b[0m: name 'test_df' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
        "\n",
        "candidate_labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "batch_size = 8  # Start with a smaller batch size; adjust as needed based on GPU memory\n",
        "\n",
        "n_samples = len(test_df['sentiment'])\n",
        "llm_predictions = [None] * n_samples\n",
        "original_labels = list(test_df['sentiment'])\n",
        "\n",
        "for i in tqdm(range(0, n_samples, batch_size)):\n",
        "    batch = test_df['processed_text'][i:i + batch_size].tolist()\n",
        "    valid_batch = [str(text).strip() for text in batch if str(text).strip()]\n",
        "\n",
        "    if valid_batch:\n",
        "        try:\n",
        "            results = classifier(valid_batch, candidate_labels)\n",
        "            for j, result in enumerate(results):\n",
        "                llm_predictions[i + j] = result['labels'][0]\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {i}: {e}\")\n",
        "            for j in range(len(batch)):\n",
        "                llm_predictions[i + j] = \"neutral\"  # Or another default value\n",
        "    else:\n",
        "        for j in range(len(batch)):\n",
        "            llm_predictions[i + j] = \"neutral\"\n",
        "\n",
        "# Filter None values\n",
        "valid_indices = [i for i, pred in enumerate(llm_predictions) if pred is not None]\n",
        "filtered_predictions = [llm_predictions[i] for i in valid_indices]\n",
        "filtered_labels = [original_labels[i] for i in valid_indices]\n",
        "\n",
        "# Evaluate\n",
        "print(classification_report(filtered_labels, filtered_predictions))\n",
        "print(\"Accuracy:\", accuracy_score(filtered_labels, filtered_predictions))\n",
        "\n",
        "# Convert to numerical labels (if needed)\n",
        "sentiment_mapping = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
        "numerical_predictions = [sentiment_mapping.get(pred, -1) for pred in filtered_predictions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example\n",
        "del results\n",
        "del valid_batch\n",
        "torch.cuda.empty_cache()  # This is important!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 989445,
          "sourceId": 1808590,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30761,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
