{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malek9876/LLM-Based-Text-Classification/blob/main/Sentiment_Analysis_Using_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMQV0xV5GUQX",
        "outputId": "808358cf-d3fa-4d51-a1b6-1c70457d0df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (24.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: kagglehub in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.6)\n",
            "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (23.2)\n",
            "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (2024.8.30)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.1)\n",
            "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.48.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
            "Requirement already satisfied: seaborn in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "%pip install --upgrade pip\n",
        "%pip install kagglehub\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download('abhi8923shriv/sentiment-analysis-dataset')\n",
        "\n",
        "# Install the required libraries\n",
        "%pip install pandas numpy nltk scikit-learn transformers matplotlib seaborn\n",
        "#%pip uninstall torch torchvision torchaudio -y\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WspHhyP757H4"
      },
      "source": [
        "# Sentiment Analysis on Kaggle sentiment analysis dataset\n",
        "sentiment analysis tasks on kaggle sentiment analysis dataset using simple machine learning model: Naive bayes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgtBS7we9zxF"
      },
      "source": [
        "## Including needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:36.548968Z",
          "iopub.status.busy": "2024-09-12T08:22:36.548571Z",
          "iopub.status.idle": "2024-09-12T08:22:39.953833Z",
          "shell.execute_reply": "2024-09-12T08:22:39.952412Z",
          "shell.execute_reply.started": "2024-09-12T08:22:36.548927Z"
        },
        "id": "V56eXYTz3Wi6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# --------------- MAIN LIBRARIES ------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# --------------- HELPING LIBRARIES ----------------\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ------------- Pytorch Librairies ---------------\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX8kWFB-_ou8"
      },
      "source": [
        "## Uploading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:39.957158Z",
          "iopub.status.busy": "2024-09-12T08:22:39.956494Z",
          "iopub.status.idle": "2024-09-12T08:22:39.976107Z",
          "shell.execute_reply": "2024-09-12T08:22:39.974235Z",
          "shell.execute_reply.started": "2024-09-12T08:22:39.957103Z"
        },
        "id": "K9dAjDTZBSKW",
        "outputId": "2a1964af-5ae9-4781-a91d-ffb39be37cb8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "train_dataset = path+'/train.csv'\n",
        "test_dataset = path+'/test.csv'\n",
        "\n",
        "# Check if the path exists\n",
        "print (os.path.exists(train_dataset))\n",
        "print (os.path.exists(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:39.978592Z",
          "iopub.status.busy": "2024-09-12T08:22:39.978053Z",
          "iopub.status.idle": "2024-09-12T08:22:40.231514Z",
          "shell.execute_reply": "2024-09-12T08:22:40.230228Z",
          "shell.execute_reply.started": "2024-09-12T08:22:39.978535Z"
        },
        "id": "hW9BRdvvB5-i",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "train_df = pd.read_csv(train_dataset, encoding='ISO-8859-1')\n",
        "test_df = pd.read_csv(test_dataset, encoding='ISO-8859-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.236134Z",
          "iopub.status.busy": "2024-09-12T08:22:40.234876Z",
          "iopub.status.idle": "2024-09-12T08:22:40.279444Z",
          "shell.execute_reply": "2024-09-12T08:22:40.278232Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.236076Z"
        },
        "id": "Cv2hsR9aDAkQ",
        "outputId": "d2e36aeb-3af6-413d-91a4-0e2c161d341c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment Time of Tweet Age of User  \\\n",
              "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
              "1                             Sooo SAD  negative          noon       21-30   \n",
              "2                          bullying me  negative         night       31-45   \n",
              "3                       leave me alone  negative       morning       46-60   \n",
              "4                        Sons of ****,  negative          noon       60-70   \n",
              "\n",
              "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
              "0  Afghanistan          38928346         652860.0               60  \n",
              "1      Albania           2877797          27400.0              105  \n",
              "2      Algeria          43851044        2381740.0               18  \n",
              "3      Andorra             77265            470.0              164  \n",
              "4       Angola          32866272        1246700.0               26  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLHgZmS_KaeW"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.282164Z",
          "iopub.status.busy": "2024-09-12T08:22:40.281383Z",
          "iopub.status.idle": "2024-09-12T08:22:40.337247Z",
          "shell.execute_reply": "2024-09-12T08:22:40.335825Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.282119Z"
        },
        "id": "lQTMOPxnWhs7",
        "outputId": "5595146d-2358-4289-f2bc-c087a7e39b76",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27481 entries, 0 to 27480\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            27481 non-null  object \n",
            " 1   text              27480 non-null  object \n",
            " 2   selected_text     27480 non-null  object \n",
            " 3   sentiment         27481 non-null  object \n",
            " 4   Time of Tweet     27481 non-null  object \n",
            " 5   Age of User       27481 non-null  object \n",
            " 6   Country           27481 non-null  object \n",
            " 7   Population -2020  27481 non-null  int64  \n",
            " 8   Land Area (Km²)   27481 non-null  float64\n",
            " 9   Density (P/Km²)   27481 non-null  int64  \n",
            "dtypes: float64(1), int64(2), object(7)\n",
            "memory usage: 2.1+ MB\n"
          ]
        }
      ],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.340796Z",
          "iopub.status.busy": "2024-09-12T08:22:40.340393Z",
          "iopub.status.idle": "2024-09-12T08:22:40.358799Z",
          "shell.execute_reply": "2024-09-12T08:22:40.357343Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.340755Z"
        },
        "id": "GmpjaoKBWluP",
        "outputId": "2143527c-74cd-4a50-f732-82d04cd4fdb2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4815 entries, 0 to 4814\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            3534 non-null   object \n",
            " 1   text              3534 non-null   object \n",
            " 2   sentiment         3534 non-null   object \n",
            " 3   Time of Tweet     3534 non-null   object \n",
            " 4   Age of User       3534 non-null   object \n",
            " 5   Country           3534 non-null   object \n",
            " 6   Population -2020  3534 non-null   float64\n",
            " 7   Land Area (Km²)   3534 non-null   float64\n",
            " 8   Density (P/Km²)   3534 non-null   float64\n",
            "dtypes: float64(3), object(6)\n",
            "memory usage: 338.7+ KB\n"
          ]
        }
      ],
      "source": [
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U95kjy7kKgIC"
      },
      "source": [
        "#### Handling null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.360843Z",
          "iopub.status.busy": "2024-09-12T08:22:40.360383Z",
          "iopub.status.idle": "2024-09-12T08:22:40.402343Z",
          "shell.execute_reply": "2024-09-12T08:22:40.401081Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.36079Z"
        },
        "id": "RaWIiyJWKeUd",
        "outputId": "6c61868f-1cf3-4f01-b690-d9f168cb98cc",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                1\n",
              "selected_text       1\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.404817Z",
          "iopub.status.busy": "2024-09-12T08:22:40.404388Z",
          "iopub.status.idle": "2024-09-12T08:22:40.465463Z",
          "shell.execute_reply": "2024-09-12T08:22:40.463998Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.404776Z"
        },
        "id": "_5ZDZQ73Kydz",
        "outputId": "a31675d6-563d-4ac8-be41-3b6fd77cfa95",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                0\n",
              "selected_text       0\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = train_df.dropna()\n",
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.467344Z",
          "iopub.status.busy": "2024-09-12T08:22:40.466939Z",
          "iopub.status.idle": "2024-09-12T08:22:40.481329Z",
          "shell.execute_reply": "2024-09-12T08:22:40.479919Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.4673Z"
        },
        "id": "x5nimN6_WGRR",
        "outputId": "3eee7f0a-83e3-492f-bcf0-f3edd602ab4c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              1281\n",
              "text                1281\n",
              "sentiment           1281\n",
              "Time of Tweet       1281\n",
              "Age of User         1281\n",
              "Country             1281\n",
              "Population -2020    1281\n",
              "Land Area (Km²)     1281\n",
              "Density (P/Km²)     1281\n",
              "dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.487599Z",
          "iopub.status.busy": "2024-09-12T08:22:40.486547Z",
          "iopub.status.idle": "2024-09-12T08:22:40.507416Z",
          "shell.execute_reply": "2024-09-12T08:22:40.506177Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.487539Z"
        },
        "id": "A3hqNN4GWP9J",
        "outputId": "d37c315f-eccb-42f3-9563-941610c401d5",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                0\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOgrqQewLCdw"
      },
      "source": [
        "#### Removing stopwords & lowercase all text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.509448Z",
          "iopub.status.busy": "2024-09-12T08:22:40.508972Z",
          "iopub.status.idle": "2024-09-12T08:22:40.598748Z",
          "shell.execute_reply": "2024-09-12T08:22:40.597069Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.509394Z"
        },
        "id": "Qpsxd4BWNHJO",
        "outputId": "f1abd31d-5bd5-4b9f-de18-4cb44ce81a10",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.601099Z",
          "iopub.status.busy": "2024-09-12T08:22:40.600609Z",
          "iopub.status.idle": "2024-09-12T08:22:40.609951Z",
          "shell.execute_reply": "2024-09-12T08:22:40.608024Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.601044Z"
        },
        "id": "GyCFZy2FOZ0u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Text preprocessing function that removes stopwords and convert text to lowercase\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.611901Z",
          "iopub.status.busy": "2024-09-12T08:22:40.611511Z",
          "iopub.status.idle": "2024-09-12T08:22:45.335514Z",
          "shell.execute_reply": "2024-09-12T08:22:45.334329Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.611861Z"
        },
        "id": "6Rd5y7pkOyXz",
        "outputId": "e9b5306f-5c8d-46c9-fa42-c4856f39cf98",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60</td>\n",
              "      <td>i`d responded, going</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105</td>\n",
              "      <td>sooo sad miss san diego!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18</td>\n",
              "      <td>boss bullying me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164</td>\n",
              "      <td>interview! leave alone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26</td>\n",
              "      <td>sons ****, couldn`t put releases already bought</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment Time of Tweet Age of User  \\\n",
              "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
              "1                             Sooo SAD  negative          noon       21-30   \n",
              "2                          bullying me  negative         night       31-45   \n",
              "3                       leave me alone  negative       morning       46-60   \n",
              "4                        Sons of ****,  negative          noon       60-70   \n",
              "\n",
              "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \\\n",
              "0  Afghanistan          38928346         652860.0               60   \n",
              "1      Albania           2877797          27400.0              105   \n",
              "2      Algeria          43851044        2381740.0               18   \n",
              "3      Andorra             77265            470.0              164   \n",
              "4       Angola          32866272        1246700.0               26   \n",
              "\n",
              "                                    processed_text  \n",
              "0                             i`d responded, going  \n",
              "1                       sooo sad miss san diego!!!  \n",
              "2                              boss bullying me...  \n",
              "3                           interview! leave alone  \n",
              "4  sons ****, couldn`t put releases already bought  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply preprocessing on train dataset\n",
        "train_df['processed_text'] = train_df['text'].apply(preprocess_text)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:45.337762Z",
          "iopub.status.busy": "2024-09-12T08:22:45.337232Z",
          "iopub.status.idle": "2024-09-12T08:22:45.959644Z",
          "shell.execute_reply": "2024-09-12T08:22:45.958512Z",
          "shell.execute_reply.started": "2024-09-12T08:22:45.337709Z"
        },
        "id": "2Vpcp2FVXXVQ",
        "outputId": "c6770cf5-f897-410a-b6ae-7df5bd9181a2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f87dea47db</td>\n",
              "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346.0</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>last session day http://twitpic.com/67ezh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96d74cb729</td>\n",
              "      <td>Shanghai is also really exciting (precisely -...</td>\n",
              "      <td>positive</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797.0</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>shanghai also really exciting (precisely -- sk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eee518ae67</td>\n",
              "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044.0</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>recession hit veronique branquinho, quit compa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01082688c6</td>\n",
              "      <td>happy bday!</td>\n",
              "      <td>positive</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265.0</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>happy bday!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33987a8ee5</td>\n",
              "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
              "      <td>positive</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272.0</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>http://twitpic.com/4w75p - like it!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text sentiment  \\\n",
              "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
              "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
              "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
              "3  01082688c6                                        happy bday!  positive   \n",
              "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
              "\n",
              "  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n",
              "0       morning        0-20  Afghanistan        38928346.0         652860.0   \n",
              "1          noon       21-30      Albania         2877797.0          27400.0   \n",
              "2         night       31-45      Algeria        43851044.0        2381740.0   \n",
              "3       morning       46-60      Andorra           77265.0            470.0   \n",
              "4          noon       60-70       Angola        32866272.0        1246700.0   \n",
              "\n",
              "   Density (P/Km²)                                     processed_text  \n",
              "0             60.0          last session day http://twitpic.com/67ezh  \n",
              "1            105.0  shanghai also really exciting (precisely -- sk...  \n",
              "2             18.0  recession hit veronique branquinho, quit compa...  \n",
              "3            164.0                                        happy bday!  \n",
              "4             26.0               http://twitpic.com/4w75p - like it!!  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply preprocessing on test dataset\n",
        "test_df['processed_text'] = test_df['text'].apply(preprocess_text)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9FZF-S6RwT0"
      },
      "source": [
        "## Check Imbalancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:27:19.351826Z",
          "iopub.status.busy": "2024-09-12T08:27:19.351335Z",
          "iopub.status.idle": "2024-09-12T08:27:19.610508Z",
          "shell.execute_reply": "2024-09-12T08:27:19.609354Z",
          "shell.execute_reply.started": "2024-09-12T08:27:19.351775Z"
        },
        "id": "uRP-7dXHUcgb",
        "outputId": "c55e8422-deb7-49b4-b029-1d1d3a550c50",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Distribution of sentiment labels\n",
        "sns.countplot(x='sentiment', data=train_df)\n",
        "plt.title(\"Distribution of Sentiment Labels\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ppFEsZZXIW75"
      },
      "outputs": [],
      "source": [
        "# 1. Transform sentiment into 3 classes\n",
        "# Example mapping: positive -> 2, neutral -> 1, negative -> 0\n",
        "sentiment_mapping = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
        "train_df[\"sentiment_class\"] = train_df[\"sentiment\"].map(sentiment_mapping)\n",
        "test_df[\"sentiment_class\"] = test_df[\"sentiment\"].map(sentiment_mapping)\n",
        "\n",
        "# 2. Extract all the values from the 'processed_text' column into a list\n",
        "trainval_x = train_df[\"processed_text\"].tolist()\n",
        "trainval_y = train_df[\"sentiment_class\"].tolist()\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(trainval_x, trainval_y, test_size=0.25, random_state=42)\n",
        "\n",
        "test_x = test_df[\"processed_text\"].tolist()\n",
        "test_y = test_df[\"sentiment_class\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGje1w01rjlw",
        "outputId": "862fa31c-ba1a-4f4d-ce50-676b87f2b2a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27480 6870 3534\n"
          ]
        }
      ],
      "source": [
        "print(len(trainval_x),len(val_x),len(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "meidY0NVsChh"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "PRETRAINED_MODEL = \"bert-base-uncased\"\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "EPOCHS = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Custom Dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of sentiment labels (e.g., 0, 1).\n",
        "            tokenizer (transformers.BertTokenizer): Tokenizer for BERT.\n",
        "            max_length (int): Maximum length for tokenized sequences.\n",
        "        \"\"\"\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and encode the text\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Extract embeddings for all data\n",
        "def extract_embeddings(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Extracts embeddings for all data using a pre-trained BERT model.\n",
        "\n",
        "    Args:\n",
        "        model (transformers.BertModel): Pre-trained BERT model.\n",
        "        dataloader (DataLoader): DataLoader for the dataset.\n",
        "        device (torch.device): Device to run the model on (CPU or GPU).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A matrix of size (number_of_samples, embedding_size).\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    embeddings = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            # Forward pass through BERT\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            pooled_output = outputs.pooler_output  # CLS token representation\n",
        "\n",
        "            # Append embeddings to the list\n",
        "            embeddings.append(pooled_output.cpu())\n",
        "\n",
        "    # Combine all embeddings into a single matrix\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "# Initialize tokenizer, dataset, and dataloader\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
        "traindataset = TextDataset(train_x, train_y, tokenizer, MAX_LENGTH)\n",
        "trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "valdataset = TextDataset(val_x, val_y, tokenizer, MAX_LENGTH)\n",
        "valloader = DataLoader(valdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "bert = BertModel.from_pretrained(PRETRAINED_MODEL).to(device)\n",
        "# Extract embeddings\n",
        "train_embeddings = extract_embeddings(bert, trainloader, device)\n",
        "train_embeddings =train_embeddings.cpu()\n",
        "\n",
        "val_embeddings = extract_embeddings(bert, valloader, device)\n",
        "val_embeddings =val_embeddings.cpu()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWzk4bUcvX03",
        "outputId": "a905e572-cd4f-4db6-9117-16f9e062d890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20610, 768])\n",
            "torch.Size([6870, 768])\n"
          ]
        }
      ],
      "source": [
        "print(train_embeddings.size())\n",
        "print(val_embeddings.size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lHR_N9OiwgYL"
      },
      "outputs": [],
      "source": [
        "criterion= nn.CrossEntropyLoss()\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "# Custom Dataset\n",
        "class EmbeddingDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of sentiment labels (e.g., 0, 1).\n",
        "            tokenizer (transformers.BertTokenizer): Tokenizer for BERT.\n",
        "            max_length (int): Maximum length for tokenized sequences.\n",
        "        \"\"\"\n",
        "        self.embeddings = embeddings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and encode the text\n",
        "        embeddings = self.embeddings[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": embeddings.squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Model Definition\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "\n",
        "        # Fully connected layer for classification\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "\n",
        "        # Pass through the fully connected layer\n",
        "        logits = self.fc(input_ids)\n",
        "        return logits\n",
        "\n",
        "# training script\n",
        "\n",
        "def train( model, train_loader, optimizer, epoch,log_interval=50):\n",
        "    model.train()\n",
        "    loss_cpu=0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, target = data['input_ids'],data['label']\n",
        "        inputs, target = inputs.cuda(), target.cuda()\n",
        "        inputs =inputs.detach()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        loss_cpu+= loss.item()\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
        "                %(epoch, EPOCHS, batch_idx+1,\n",
        "                    (len(train_loader)//BATCH_SIZE)+1, loss.item(), 100.*correct/total))\n",
        "            #n_iter=epoch * len(train_loader) + batch_idx\n",
        "\n",
        "    return loss_cpu/len(train_loader)\n",
        "\n",
        "# testing script\n",
        "def test( model, test_loader,epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss_MSE =0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(test_loader, 0):\n",
        "            inputs, target = data['input_ids'],data['label']\n",
        "            inputs, target = inputs.cuda(), target.cuda()\n",
        "            outputs  = model(inputs)\n",
        "            loss = criterion(outputs,target)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target.data).cpu().sum()\n",
        "            test_loss_MSE+= loss.item()\n",
        "\n",
        "    test_loss_MSE = test_loss_MSE/ len(test_loader)\n",
        "    print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), 100.*correct/total))\n",
        "    return test_loss_MSE, 100.*correct/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0X6VeclzYro",
        "outputId": "1d64bacd-dc0d-42b0-a915-387380137513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let us Train.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3/ training model 1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "| Epoch [  0/ 50] Iter[  1/  6]\t\tLoss: 1.1370 Acc@1: 37.500%\n",
            "| Epoch [  0/ 50] Iter[ 51/  6]\t\tLoss: 7.4475 Acc@1: 35.999%\n",
            "| Epoch [  0/ 50] Iter[101/  6]\t\tLoss: 9.1122 Acc@1: 32.782%\n",
            "| Epoch [  0/ 50] Iter[151/  6]\t\tLoss: 19.6443 Acc@1: 35.555%\n",
            "| Epoch [  0/ 50] Iter[201/  6]\t\tLoss: 12.6108 Acc@1: 35.922%\n",
            "| Epoch [  0/ 50] Iter[251/  6]\t\tLoss: 38.0411 Acc@1: 34.605%\n",
            "| Epoch [  0/ 50] Iter[301/  6]\t\tLoss: 21.8274 Acc@1: 33.576%\n",
            "\n",
            "| Validation Epoch #0\t\t\tLoss: 24.7069 Acc@1: 31.00%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 26.349986252961337 for epoch : 0 ERROR TEST =  (26.349986252961337, tensor(31.0044))\n",
            "| Epoch [  1/ 50] Iter[  1/  6]\t\tLoss: 23.2040 Acc@1: 40.625%\n",
            "| Epoch [  1/ 50] Iter[ 51/  6]\t\tLoss: 25.1680 Acc@1: 35.784%\n",
            "| Epoch [  1/ 50] Iter[101/  6]\t\tLoss: 51.9732 Acc@1: 38.134%\n",
            "| Epoch [  1/ 50] Iter[151/  6]\t\tLoss: 37.8096 Acc@1: 38.493%\n",
            "| Epoch [  1/ 50] Iter[201/  6]\t\tLoss: 5.3740 Acc@1: 39.094%\n",
            "| Epoch [  1/ 50] Iter[251/  6]\t\tLoss: 25.3333 Acc@1: 37.799%\n",
            "| Epoch [  1/ 50] Iter[301/  6]\t\tLoss: 56.8423 Acc@1: 36.156%\n",
            "\n",
            "| Validation Epoch #1\t\t\tLoss: 48.6278 Acc@1: 29.51%\n",
            "lr = 0.001\n",
            "| Epoch [  2/ 50] Iter[  1/  6]\t\tLoss: 57.3892 Acc@1: 32.812%\n",
            "| Epoch [  2/ 50] Iter[ 51/  6]\t\tLoss: 65.0482 Acc@1: 32.874%\n",
            "| Epoch [  2/ 50] Iter[101/  6]\t\tLoss: 56.9338 Acc@1: 32.426%\n",
            "| Epoch [  2/ 50] Iter[151/  6]\t\tLoss: 40.9158 Acc@1: 32.212%\n",
            "| Epoch [  2/ 50] Iter[201/  6]\t\tLoss: 17.5234 Acc@1: 31.934%\n",
            "| Epoch [  2/ 50] Iter[251/  6]\t\tLoss: 53.1524 Acc@1: 33.560%\n",
            "| Epoch [  2/ 50] Iter[301/  6]\t\tLoss: 56.9803 Acc@1: 34.775%\n",
            "\n",
            "| Validation Epoch #2\t\t\tLoss: 79.3204 Acc@1: 40.51%\n",
            "lr = 0.001\n",
            "| Epoch [  3/ 50] Iter[  1/  6]\t\tLoss: 61.7134 Acc@1: 50.000%\n",
            "| Epoch [  3/ 50] Iter[ 51/  6]\t\tLoss: 44.4119 Acc@1: 40.441%\n",
            "| Epoch [  3/ 50] Iter[101/  6]\t\tLoss: 41.4722 Acc@1: 40.625%\n",
            "| Epoch [  3/ 50] Iter[151/  6]\t\tLoss: 48.5640 Acc@1: 39.497%\n",
            "| Epoch [  3/ 50] Iter[201/  6]\t\tLoss: 58.3397 Acc@1: 37.764%\n",
            "| Epoch [  3/ 50] Iter[251/  6]\t\tLoss: 35.9549 Acc@1: 36.616%\n",
            "| Epoch [  3/ 50] Iter[301/  6]\t\tLoss: 55.1020 Acc@1: 35.777%\n",
            "\n",
            "| Validation Epoch #3\t\t\tLoss: 69.6225 Acc@1: 28.53%\n",
            "lr = 0.001\n",
            "| Epoch [  4/ 50] Iter[  1/  6]\t\tLoss: 83.3398 Acc@1: 23.438%\n",
            "| Epoch [  4/ 50] Iter[ 51/  6]\t\tLoss: 78.8794 Acc@1: 27.267%\n",
            "| Epoch [  4/ 50] Iter[101/  6]\t\tLoss: 55.4800 Acc@1: 27.893%\n",
            "| Epoch [  4/ 50] Iter[151/  6]\t\tLoss: 16.8408 Acc@1: 28.756%\n",
            "| Epoch [  4/ 50] Iter[201/  6]\t\tLoss: 32.8693 Acc@1: 31.973%\n",
            "| Epoch [  4/ 50] Iter[251/  6]\t\tLoss: 51.4663 Acc@1: 33.479%\n",
            "| Epoch [  4/ 50] Iter[301/  6]\t\tLoss: 50.6968 Acc@1: 34.884%\n",
            "\n",
            "| Validation Epoch #4\t\t\tLoss: 74.8054 Acc@1: 40.29%\n",
            "lr = 0.001\n",
            "| Epoch [  5/ 50] Iter[  1/  6]\t\tLoss: 53.3478 Acc@1: 34.375%\n",
            "| Epoch [  5/ 50] Iter[ 51/  6]\t\tLoss: 102.1762 Acc@1: 34.436%\n",
            "| Epoch [  5/ 50] Iter[101/  6]\t\tLoss: 73.6081 Acc@1: 33.803%\n",
            "| Epoch [  5/ 50] Iter[151/  6]\t\tLoss: 74.3085 Acc@1: 34.354%\n",
            "| Epoch [  5/ 50] Iter[201/  6]\t\tLoss: 67.2001 Acc@1: 36.614%\n",
            "| Epoch [  5/ 50] Iter[251/  6]\t\tLoss: 81.0220 Acc@1: 37.419%\n",
            "| Epoch [  5/ 50] Iter[301/  6]\t\tLoss: 77.1919 Acc@1: 37.967%\n",
            "\n",
            "| Validation Epoch #5\t\t\tLoss: 73.9513 Acc@1: 40.64%\n",
            "lr = 0.001\n",
            "| Epoch [  6/ 50] Iter[  1/  6]\t\tLoss: 69.3270 Acc@1: 43.750%\n",
            "| Epoch [  6/ 50] Iter[ 51/  6]\t\tLoss: 38.7179 Acc@1: 40.564%\n",
            "| Epoch [  6/ 50] Iter[101/  6]\t\tLoss: 21.6515 Acc@1: 41.863%\n",
            "| Epoch [  6/ 50] Iter[151/  6]\t\tLoss: 25.1120 Acc@1: 40.087%\n",
            "| Epoch [  6/ 50] Iter[201/  6]\t\tLoss: 48.8656 Acc@1: 39.272%\n",
            "| Epoch [  6/ 50] Iter[251/  6]\t\tLoss: 77.6791 Acc@1: 37.239%\n",
            "| Epoch [  6/ 50] Iter[301/  6]\t\tLoss: 97.6149 Acc@1: 35.782%\n",
            "\n",
            "| Validation Epoch #6\t\t\tLoss: 91.5556 Acc@1: 28.70%\n",
            "lr = 0.001\n",
            "| Epoch [  7/ 50] Iter[  1/  6]\t\tLoss: 86.1332 Acc@1: 23.438%\n",
            "| Epoch [  7/ 50] Iter[ 51/  6]\t\tLoss: 76.6364 Acc@1: 29.442%\n",
            "| Epoch [  7/ 50] Iter[101/  6]\t\tLoss: 70.7007 Acc@1: 32.905%\n",
            "| Epoch [  7/ 50] Iter[151/  6]\t\tLoss: 70.8245 Acc@1: 32.461%\n",
            "| Epoch [  7/ 50] Iter[201/  6]\t\tLoss: 67.1101 Acc@1: 32.649%\n",
            "| Epoch [  7/ 50] Iter[251/  6]\t\tLoss: 41.7203 Acc@1: 32.202%\n",
            "| Epoch [  7/ 50] Iter[301/  6]\t\tLoss: 24.8707 Acc@1: 33.378%\n",
            "\n",
            "| Validation Epoch #7\t\t\tLoss: 37.0036 Acc@1: 40.83%\n",
            "lr = 0.001\n",
            "| Epoch [  8/ 50] Iter[  1/  6]\t\tLoss: 32.8548 Acc@1: 43.750%\n",
            "| Epoch [  8/ 50] Iter[ 51/  6]\t\tLoss: 59.2561 Acc@1: 40.594%\n",
            "| Epoch [  8/ 50] Iter[101/  6]\t\tLoss: 78.9872 Acc@1: 40.486%\n",
            "| Epoch [  8/ 50] Iter[151/  6]\t\tLoss: 78.1672 Acc@1: 40.232%\n",
            "| Epoch [  8/ 50] Iter[201/  6]\t\tLoss: 69.2685 Acc@1: 40.376%\n",
            "| Epoch [  8/ 50] Iter[251/  6]\t\tLoss: 53.3657 Acc@1: 40.532%\n",
            "| Epoch [  8/ 50] Iter[301/  6]\t\tLoss: 74.6014 Acc@1: 40.111%\n",
            "\n",
            "| Validation Epoch #8\t\t\tLoss: 78.5381 Acc@1: 28.68%\n",
            "lr = 0.0001\n",
            "| Epoch [  9/ 50] Iter[  1/  6]\t\tLoss: 74.4995 Acc@1: 28.125%\n",
            "| Epoch [  9/ 50] Iter[ 51/  6]\t\tLoss: 86.4476 Acc@1: 29.320%\n",
            "| Epoch [  9/ 50] Iter[101/  6]\t\tLoss: 74.4385 Acc@1: 28.373%\n",
            "| Epoch [  9/ 50] Iter[151/  6]\t\tLoss: 54.8436 Acc@1: 28.208%\n",
            "| Epoch [  9/ 50] Iter[201/  6]\t\tLoss: 70.4358 Acc@1: 28.646%\n",
            "| Epoch [  9/ 50] Iter[251/  6]\t\tLoss: 71.0316 Acc@1: 28.629%\n",
            "| Epoch [  9/ 50] Iter[301/  6]\t\tLoss: 59.8407 Acc@1: 28.654%\n",
            "\n",
            "| Validation Epoch #9\t\t\tLoss: 80.1336 Acc@1: 30.19%\n",
            "lr = 0.0001\n",
            "| Epoch [ 10/ 50] Iter[  1/  6]\t\tLoss: 49.9129 Acc@1: 34.375%\n",
            "| Epoch [ 10/ 50] Iter[ 51/  6]\t\tLoss: 36.0475 Acc@1: 32.322%\n",
            "| Epoch [ 10/ 50] Iter[101/  6]\t\tLoss: 45.0506 Acc@1: 32.642%\n",
            "| Epoch [ 10/ 50] Iter[151/  6]\t\tLoss: 39.6310 Acc@1: 33.506%\n",
            "| Epoch [ 10/ 50] Iter[201/  6]\t\tLoss: 24.7816 Acc@1: 34.942%\n",
            "| Epoch [ 10/ 50] Iter[251/  6]\t\tLoss: 22.9741 Acc@1: 36.336%\n",
            "| Epoch [ 10/ 50] Iter[301/  6]\t\tLoss: 33.1547 Acc@1: 37.443%\n",
            "\n",
            "| Validation Epoch #10\t\t\tLoss: 31.6978 Acc@1: 41.89%\n",
            "lr = 0.0001\n",
            "| Epoch [ 11/ 50] Iter[  1/  6]\t\tLoss: 41.1056 Acc@1: 39.062%\n",
            "| Epoch [ 11/ 50] Iter[ 51/  6]\t\tLoss: 25.8359 Acc@1: 40.686%\n",
            "| Epoch [ 11/ 50] Iter[101/  6]\t\tLoss: 35.3175 Acc@1: 41.306%\n",
            "| Epoch [ 11/ 50] Iter[151/  6]\t\tLoss: 41.0260 Acc@1: 41.515%\n",
            "| Epoch [ 11/ 50] Iter[201/  6]\t\tLoss: 35.2616 Acc@1: 41.877%\n",
            "| Epoch [ 11/ 50] Iter[251/  6]\t\tLoss: 32.3021 Acc@1: 41.509%\n",
            "| Epoch [ 11/ 50] Iter[301/  6]\t\tLoss: 40.7862 Acc@1: 41.274%\n",
            "\n",
            "| Validation Epoch #11\t\t\tLoss: 27.7564 Acc@1: 40.77%\n",
            "lr = 0.0001\n",
            "| Epoch [ 12/ 50] Iter[  1/  6]\t\tLoss: 29.3674 Acc@1: 43.750%\n",
            "| Epoch [ 12/ 50] Iter[ 51/  6]\t\tLoss: 31.5573 Acc@1: 40.809%\n",
            "| Epoch [ 12/ 50] Iter[101/  6]\t\tLoss: 26.3276 Acc@1: 41.290%\n",
            "| Epoch [ 12/ 50] Iter[151/  6]\t\tLoss: 21.2370 Acc@1: 41.236%\n",
            "| Epoch [ 12/ 50] Iter[201/  6]\t\tLoss: 19.6893 Acc@1: 41.340%\n",
            "| Epoch [ 12/ 50] Iter[251/  6]\t\tLoss: 14.6188 Acc@1: 41.708%\n",
            "| Epoch [ 12/ 50] Iter[301/  6]\t\tLoss: 15.8336 Acc@1: 42.063%\n",
            "\n",
            "| Validation Epoch #12\t\t\tLoss: 12.8475 Acc@1: 45.69%\n",
            "lr = 0.0001\n",
            "Best RMSE is of : 12.74111525217692 for epoch : 12 ERROR TEST =  (12.74111525217692, tensor(45.6914))\n",
            "| Epoch [ 13/ 50] Iter[  1/  6]\t\tLoss: 10.8551 Acc@1: 48.438%\n",
            "| Epoch [ 13/ 50] Iter[ 51/  6]\t\tLoss: 9.4930 Acc@1: 45.067%\n",
            "| Epoch [ 13/ 50] Iter[101/  6]\t\tLoss: 10.8181 Acc@1: 47.200%\n",
            "| Epoch [ 13/ 50] Iter[151/  6]\t\tLoss: 10.6743 Acc@1: 47.765%\n",
            "| Epoch [ 13/ 50] Iter[201/  6]\t\tLoss: 10.0744 Acc@1: 47.722%\n",
            "| Epoch [ 13/ 50] Iter[251/  6]\t\tLoss: 7.2249 Acc@1: 47.989%\n",
            "| Epoch [ 13/ 50] Iter[301/  6]\t\tLoss: 12.5550 Acc@1: 47.711%\n",
            "\n",
            "| Validation Epoch #13\t\t\tLoss: 14.4059 Acc@1: 44.09%\n",
            "lr = 0.0001\n",
            "| Epoch [ 14/ 50] Iter[  1/  6]\t\tLoss: 15.5085 Acc@1: 42.188%\n",
            "| Epoch [ 14/ 50] Iter[ 51/  6]\t\tLoss: 11.9751 Acc@1: 45.650%\n",
            "| Epoch [ 14/ 50] Iter[101/  6]\t\tLoss: 14.1556 Acc@1: 44.585%\n",
            "| Epoch [ 14/ 50] Iter[151/  6]\t\tLoss: 17.0634 Acc@1: 42.943%\n",
            "| Epoch [ 14/ 50] Iter[201/  6]\t\tLoss: 17.5658 Acc@1: 41.620%\n",
            "| Epoch [ 14/ 50] Iter[251/  6]\t\tLoss: 27.3634 Acc@1: 40.781%\n",
            "| Epoch [ 14/ 50] Iter[301/  6]\t\tLoss: 19.4863 Acc@1: 40.205%\n",
            "\n",
            "| Validation Epoch #14\t\t\tLoss: 18.4600 Acc@1: 36.00%\n",
            "lr = 0.0001\n",
            "| Epoch [ 15/ 50] Iter[  1/  6]\t\tLoss: 29.0915 Acc@1: 34.375%\n",
            "| Epoch [ 15/ 50] Iter[ 51/  6]\t\tLoss: 26.5187 Acc@1: 35.478%\n",
            "| Epoch [ 15/ 50] Iter[101/  6]\t\tLoss: 29.3953 Acc@1: 35.458%\n",
            "| Epoch [ 15/ 50] Iter[151/  6]\t\tLoss: 25.9299 Acc@1: 35.534%\n",
            "| Epoch [ 15/ 50] Iter[201/  6]\t\tLoss: 26.6376 Acc@1: 35.658%\n",
            "| Epoch [ 15/ 50] Iter[251/  6]\t\tLoss: 34.1163 Acc@1: 35.583%\n",
            "| Epoch [ 15/ 50] Iter[301/  6]\t\tLoss: 38.7339 Acc@1: 35.543%\n",
            "\n",
            "| Validation Epoch #15\t\t\tLoss: 40.7279 Acc@1: 34.29%\n",
            "lr = 0.0001\n",
            "| Epoch [ 16/ 50] Iter[  1/  6]\t\tLoss: 37.7376 Acc@1: 21.875%\n",
            "| Epoch [ 16/ 50] Iter[ 51/  6]\t\tLoss: 30.4217 Acc@1: 34.804%\n",
            "| Epoch [ 16/ 50] Iter[101/  6]\t\tLoss: 33.5594 Acc@1: 34.174%\n",
            "| Epoch [ 16/ 50] Iter[151/  6]\t\tLoss: 28.9055 Acc@1: 34.530%\n",
            "| Epoch [ 16/ 50] Iter[201/  6]\t\tLoss: 24.8825 Acc@1: 34.468%\n",
            "| Epoch [ 16/ 50] Iter[251/  6]\t\tLoss: 33.1749 Acc@1: 34.680%\n",
            "| Epoch [ 16/ 50] Iter[301/  6]\t\tLoss: 27.5523 Acc@1: 34.614%\n",
            "\n",
            "| Validation Epoch #16\t\t\tLoss: 26.8015 Acc@1: 35.18%\n",
            "lr = 0.0001\n",
            "| Epoch [ 17/ 50] Iter[  1/  6]\t\tLoss: 25.7665 Acc@1: 37.500%\n",
            "| Epoch [ 17/ 50] Iter[ 51/  6]\t\tLoss: 24.2029 Acc@1: 35.447%\n",
            "| Epoch [ 17/ 50] Iter[101/  6]\t\tLoss: 21.4726 Acc@1: 36.556%\n",
            "| Epoch [ 17/ 50] Iter[151/  6]\t\tLoss: 18.1473 Acc@1: 37.159%\n",
            "| Epoch [ 17/ 50] Iter[201/  6]\t\tLoss: 24.0282 Acc@1: 37.593%\n",
            "| Epoch [ 17/ 50] Iter[251/  6]\t\tLoss: 19.1832 Acc@1: 38.203%\n",
            "| Epoch [ 17/ 50] Iter[301/  6]\t\tLoss: 22.3624 Acc@1: 38.834%\n",
            "\n",
            "| Validation Epoch #17\t\t\tLoss: 20.6079 Acc@1: 42.79%\n",
            "lr = 0.0001\n",
            "| Epoch [ 18/ 50] Iter[  1/  6]\t\tLoss: 14.9353 Acc@1: 42.188%\n",
            "| Epoch [ 18/ 50] Iter[ 51/  6]\t\tLoss: 15.1515 Acc@1: 42.953%\n",
            "| Epoch [ 18/ 50] Iter[101/  6]\t\tLoss: 14.1623 Acc@1: 43.209%\n",
            "| Epoch [ 18/ 50] Iter[151/  6]\t\tLoss: 14.4410 Acc@1: 42.653%\n",
            "| Epoch [ 18/ 50] Iter[201/  6]\t\tLoss: 12.2915 Acc@1: 42.988%\n",
            "| Epoch [ 18/ 50] Iter[251/  6]\t\tLoss: 13.4826 Acc@1: 42.704%\n",
            "| Epoch [ 18/ 50] Iter[301/  6]\t\tLoss: 12.8114 Acc@1: 42.219%\n",
            "\n",
            "| Validation Epoch #18\t\t\tLoss: 12.9629 Acc@1: 40.36%\n",
            "lr = 0.0001\n",
            "| Epoch [ 19/ 50] Iter[  1/  6]\t\tLoss: 10.3973 Acc@1: 42.188%\n",
            "| Epoch [ 19/ 50] Iter[ 51/  6]\t\tLoss: 10.7186 Acc@1: 40.717%\n",
            "| Epoch [ 19/ 50] Iter[101/  6]\t\tLoss: 11.7517 Acc@1: 40.254%\n",
            "| Epoch [ 19/ 50] Iter[151/  6]\t\tLoss: 10.6267 Acc@1: 40.780%\n",
            "| Epoch [ 19/ 50] Iter[201/  6]\t\tLoss: 10.7078 Acc@1: 41.332%\n",
            "| Epoch [ 19/ 50] Iter[251/  6]\t\tLoss: 12.5989 Acc@1: 41.565%\n",
            "| Epoch [ 19/ 50] Iter[301/  6]\t\tLoss: 10.2156 Acc@1: 41.871%\n",
            "\n",
            "| Validation Epoch #19\t\t\tLoss: 14.7637 Acc@1: 43.89%\n",
            "lr = 0.0001\n",
            "Best RMSE is of : 12.50420571256567 for epoch : 19 ERROR TEST =  (12.50420571256567, tensor(43.8865))\n",
            "| Epoch [ 20/ 50] Iter[  1/  6]\t\tLoss: 14.5516 Acc@1: 34.375%\n",
            "| Epoch [ 20/ 50] Iter[ 51/  6]\t\tLoss: 12.4639 Acc@1: 44.700%\n",
            "| Epoch [ 20/ 50] Iter[101/  6]\t\tLoss: 14.8344 Acc@1: 44.369%\n",
            "| Epoch [ 20/ 50] Iter[151/  6]\t\tLoss: 14.2252 Acc@1: 44.795%\n",
            "| Epoch [ 20/ 50] Iter[201/  6]\t\tLoss: 20.7989 Acc@1: 44.294%\n",
            "| Epoch [ 20/ 50] Iter[251/  6]\t\tLoss: 22.3946 Acc@1: 44.080%\n",
            "| Epoch [ 20/ 50] Iter[301/  6]\t\tLoss: 22.9466 Acc@1: 43.755%\n",
            "\n",
            "| Validation Epoch #20\t\t\tLoss: 22.5726 Acc@1: 41.86%\n",
            "lr = 0.0001\n",
            "| Epoch [ 21/ 50] Iter[  1/  6]\t\tLoss: 25.3903 Acc@1: 35.938%\n",
            "| Epoch [ 21/ 50] Iter[ 51/  6]\t\tLoss: 19.3465 Acc@1: 41.789%\n",
            "| Epoch [ 21/ 50] Iter[101/  6]\t\tLoss: 23.0432 Acc@1: 41.925%\n",
            "| Epoch [ 21/ 50] Iter[151/  6]\t\tLoss: 24.8154 Acc@1: 41.794%\n",
            "| Epoch [ 21/ 50] Iter[201/  6]\t\tLoss: 30.3617 Acc@1: 41.496%\n",
            "| Epoch [ 21/ 50] Iter[251/  6]\t\tLoss: 28.1286 Acc@1: 41.590%\n",
            "| Epoch [ 21/ 50] Iter[301/  6]\t\tLoss: 27.5420 Acc@1: 41.373%\n",
            "\n",
            "| Validation Epoch #21\t\t\tLoss: 38.5328 Acc@1: 40.93%\n",
            "lr = 0.0001\n",
            "| Epoch [ 22/ 50] Iter[  1/  6]\t\tLoss: 28.4633 Acc@1: 35.938%\n",
            "| Epoch [ 22/ 50] Iter[ 51/  6]\t\tLoss: 27.6261 Acc@1: 41.176%\n",
            "| Epoch [ 22/ 50] Iter[101/  6]\t\tLoss: 30.9621 Acc@1: 40.625%\n",
            "| Epoch [ 22/ 50] Iter[151/  6]\t\tLoss: 28.8827 Acc@1: 40.811%\n",
            "| Epoch [ 22/ 50] Iter[201/  6]\t\tLoss: 26.3001 Acc@1: 41.208%\n",
            "| Epoch [ 22/ 50] Iter[251/  6]\t\tLoss: 29.4320 Acc@1: 41.160%\n",
            "| Epoch [ 22/ 50] Iter[301/  6]\t\tLoss: 14.8705 Acc@1: 41.388%\n",
            "\n",
            "| Validation Epoch #22\t\t\tLoss: 23.7775 Acc@1: 42.30%\n",
            "lr = 0.0001\n",
            "| Epoch [ 23/ 50] Iter[  1/  6]\t\tLoss: 26.8756 Acc@1: 35.938%\n",
            "| Epoch [ 23/ 50] Iter[ 51/  6]\t\tLoss: 23.9422 Acc@1: 42.555%\n",
            "| Epoch [ 23/ 50] Iter[101/  6]\t\tLoss: 22.1645 Acc@1: 43.007%\n",
            "| Epoch [ 23/ 50] Iter[151/  6]\t\tLoss: 19.5219 Acc@1: 43.543%\n",
            "| Epoch [ 23/ 50] Iter[201/  6]\t\tLoss: 20.3952 Acc@1: 43.369%\n",
            "| Epoch [ 23/ 50] Iter[251/  6]\t\tLoss: 16.3814 Acc@1: 43.177%\n",
            "| Epoch [ 23/ 50] Iter[301/  6]\t\tLoss: 12.9600 Acc@1: 42.842%\n",
            "\n",
            "| Validation Epoch #23\t\t\tLoss: 13.3290 Acc@1: 40.42%\n",
            "lr = 0.0001\n",
            "| Epoch [ 24/ 50] Iter[  1/  6]\t\tLoss: 14.3272 Acc@1: 48.438%\n",
            "| Epoch [ 24/ 50] Iter[ 51/  6]\t\tLoss: 15.8790 Acc@1: 39.491%\n",
            "| Epoch [ 24/ 50] Iter[101/  6]\t\tLoss: 20.3801 Acc@1: 39.155%\n",
            "| Epoch [ 24/ 50] Iter[151/  6]\t\tLoss: 21.5802 Acc@1: 38.069%\n",
            "| Epoch [ 24/ 50] Iter[201/  6]\t\tLoss: 16.4561 Acc@1: 37.687%\n",
            "| Epoch [ 24/ 50] Iter[251/  6]\t\tLoss: 15.0132 Acc@1: 37.176%\n",
            "| Epoch [ 24/ 50] Iter[301/  6]\t\tLoss: 16.5432 Acc@1: 36.784%\n",
            "\n",
            "| Validation Epoch #24\t\t\tLoss: 20.7977 Acc@1: 36.59%\n",
            "lr = 0.0001\n",
            "| Epoch [ 25/ 50] Iter[  1/  6]\t\tLoss: 14.0347 Acc@1: 43.750%\n",
            "| Epoch [ 25/ 50] Iter[ 51/  6]\t\tLoss: 14.5549 Acc@1: 36.642%\n",
            "| Epoch [ 25/ 50] Iter[101/  6]\t\tLoss: 13.6353 Acc@1: 37.995%\n",
            "| Epoch [ 25/ 50] Iter[151/  6]\t\tLoss: 8.8776 Acc@1: 38.918%\n",
            "| Epoch [ 25/ 50] Iter[201/  6]\t\tLoss: 7.7432 Acc@1: 40.151%\n",
            "| Epoch [ 25/ 50] Iter[251/  6]\t\tLoss: 7.2680 Acc@1: 41.615%\n",
            "| Epoch [ 25/ 50] Iter[301/  6]\t\tLoss: 7.7742 Acc@1: 43.013%\n",
            "\n",
            "| Validation Epoch #25\t\t\tLoss: 6.6979 Acc@1: 49.27%\n",
            "lr = 0.0001\n",
            "Best RMSE is of : 7.979623551721926 for epoch : 25 ERROR TEST =  (7.979623551721926, tensor(49.2722))\n",
            "| Epoch [ 26/ 50] Iter[  1/  6]\t\tLoss: 8.2955 Acc@1: 56.250%\n",
            "| Epoch [ 26/ 50] Iter[ 51/  6]\t\tLoss: 8.3124 Acc@1: 50.184%\n",
            "| Epoch [ 26/ 50] Iter[101/  6]\t\tLoss: 9.6182 Acc@1: 49.551%\n",
            "| Epoch [ 26/ 50] Iter[151/  6]\t\tLoss: 12.4249 Acc@1: 48.820%\n",
            "| Epoch [ 26/ 50] Iter[201/  6]\t\tLoss: 13.2872 Acc@1: 47.683%\n",
            "| Epoch [ 26/ 50] Iter[251/  6]\t\tLoss: 13.5285 Acc@1: 46.663%\n",
            "| Epoch [ 26/ 50] Iter[301/  6]\t\tLoss: 13.0469 Acc@1: 45.676%\n",
            "\n",
            "| Validation Epoch #26\t\t\tLoss: 16.1639 Acc@1: 39.01%\n",
            "lr = 0.0001\n",
            "| Epoch [ 27/ 50] Iter[  1/  6]\t\tLoss: 18.1357 Acc@1: 32.812%\n",
            "| Epoch [ 27/ 50] Iter[ 51/  6]\t\tLoss: 17.3392 Acc@1: 37.806%\n",
            "| Epoch [ 27/ 50] Iter[101/  6]\t\tLoss: 17.4756 Acc@1: 38.598%\n",
            "| Epoch [ 27/ 50] Iter[151/  6]\t\tLoss: 17.8859 Acc@1: 38.524%\n",
            "| Epoch [ 27/ 50] Iter[201/  6]\t\tLoss: 19.1695 Acc@1: 37.990%\n",
            "| Epoch [ 27/ 50] Iter[251/  6]\t\tLoss: 23.1174 Acc@1: 37.842%\n",
            "| Epoch [ 27/ 50] Iter[301/  6]\t\tLoss: 17.1810 Acc@1: 37.843%\n",
            "\n",
            "| Validation Epoch #27\t\t\tLoss: 17.5227 Acc@1: 37.57%\n",
            "lr = 0.0001\n",
            "| Epoch [ 28/ 50] Iter[  1/  6]\t\tLoss: 20.9263 Acc@1: 37.500%\n",
            "| Epoch [ 28/ 50] Iter[ 51/  6]\t\tLoss: 18.3148 Acc@1: 38.113%\n",
            "| Epoch [ 28/ 50] Iter[101/  6]\t\tLoss: 21.2936 Acc@1: 38.382%\n",
            "| Epoch [ 28/ 50] Iter[151/  6]\t\tLoss: 13.6884 Acc@1: 38.897%\n",
            "| Epoch [ 28/ 50] Iter[201/  6]\t\tLoss: 16.4545 Acc@1: 39.506%\n",
            "| Epoch [ 28/ 50] Iter[251/  6]\t\tLoss: 21.5603 Acc@1: 40.015%\n",
            "| Epoch [ 28/ 50] Iter[301/  6]\t\tLoss: 11.8870 Acc@1: 40.599%\n",
            "\n",
            "| Validation Epoch #28\t\t\tLoss: 11.9212 Acc@1: 43.78%\n",
            "lr = 0.0001\n",
            "| Epoch [ 29/ 50] Iter[  1/  6]\t\tLoss: 19.8999 Acc@1: 42.188%\n",
            "| Epoch [ 29/ 50] Iter[ 51/  6]\t\tLoss: 12.6743 Acc@1: 44.087%\n",
            "| Epoch [ 29/ 50] Iter[101/  6]\t\tLoss: 14.3050 Acc@1: 44.926%\n",
            "| Epoch [ 29/ 50] Iter[151/  6]\t\tLoss: 18.9399 Acc@1: 45.747%\n",
            "| Epoch [ 29/ 50] Iter[201/  6]\t\tLoss: 13.1242 Acc@1: 46.082%\n",
            "| Epoch [ 29/ 50] Iter[251/  6]\t\tLoss: 16.3317 Acc@1: 46.022%\n",
            "| Epoch [ 29/ 50] Iter[301/  6]\t\tLoss: 10.1322 Acc@1: 46.086%\n",
            "\n",
            "| Validation Epoch #29\t\t\tLoss: 10.5551 Acc@1: 46.93%\n",
            "lr = 0.0001\n",
            "| Epoch [ 30/ 50] Iter[  1/  6]\t\tLoss: 14.6345 Acc@1: 53.125%\n",
            "| Epoch [ 30/ 50] Iter[ 51/  6]\t\tLoss: 15.3400 Acc@1: 46.262%\n",
            "| Epoch [ 30/ 50] Iter[101/  6]\t\tLoss: 15.2320 Acc@1: 46.225%\n",
            "| Epoch [ 30/ 50] Iter[151/  6]\t\tLoss: 16.6752 Acc@1: 46.120%\n",
            "| Epoch [ 30/ 50] Iter[201/  6]\t\tLoss: 17.9775 Acc@1: 45.670%\n",
            "| Epoch [ 30/ 50] Iter[251/  6]\t\tLoss: 15.9764 Acc@1: 45.456%\n",
            "| Epoch [ 30/ 50] Iter[301/  6]\t\tLoss: 15.7117 Acc@1: 45.546%\n",
            "\n",
            "| Validation Epoch #30\t\t\tLoss: 10.5693 Acc@1: 45.84%\n",
            "lr = 0.0001\n",
            "| Epoch [ 31/ 50] Iter[  1/  6]\t\tLoss: 13.3119 Acc@1: 40.625%\n",
            "| Epoch [ 31/ 50] Iter[ 51/  6]\t\tLoss: 12.3190 Acc@1: 44.761%\n",
            "| Epoch [ 31/ 50] Iter[101/  6]\t\tLoss: 9.6679 Acc@1: 45.096%\n",
            "| Epoch [ 31/ 50] Iter[151/  6]\t\tLoss: 11.3552 Acc@1: 46.202%\n",
            "| Epoch [ 31/ 50] Iter[201/  6]\t\tLoss: 10.0640 Acc@1: 46.766%\n",
            "| Epoch [ 31/ 50] Iter[251/  6]\t\tLoss: 6.8670 Acc@1: 47.647%\n",
            "| Epoch [ 31/ 50] Iter[301/  6]\t\tLoss: 10.1131 Acc@1: 47.643%\n",
            "\n",
            "| Validation Epoch #31\t\t\tLoss: 8.4944 Acc@1: 45.15%\n",
            "lr = 0.0001\n",
            "| Epoch [ 32/ 50] Iter[  1/  6]\t\tLoss: 8.7475 Acc@1: 37.500%\n",
            "| Epoch [ 32/ 50] Iter[ 51/  6]\t\tLoss: 8.8215 Acc@1: 44.363%\n",
            "| Epoch [ 32/ 50] Iter[101/  6]\t\tLoss: 11.9130 Acc@1: 42.203%\n",
            "| Epoch [ 32/ 50] Iter[151/  6]\t\tLoss: 12.2524 Acc@1: 40.780%\n",
            "| Epoch [ 32/ 50] Iter[201/  6]\t\tLoss: 14.7488 Acc@1: 39.490%\n",
            "| Epoch [ 32/ 50] Iter[251/  6]\t\tLoss: 17.4478 Acc@1: 38.247%\n",
            "| Epoch [ 32/ 50] Iter[301/  6]\t\tLoss: 17.1863 Acc@1: 37.412%\n",
            "\n",
            "| Validation Epoch #32\t\t\tLoss: 25.1009 Acc@1: 32.82%\n",
            "lr = 0.0001\n",
            "| Epoch [ 33/ 50] Iter[  1/  6]\t\tLoss: 19.9874 Acc@1: 34.375%\n",
            "| Epoch [ 33/ 50] Iter[ 51/  6]\t\tLoss: 20.6149 Acc@1: 31.710%\n",
            "| Epoch [ 33/ 50] Iter[101/  6]\t\tLoss: 19.4073 Acc@1: 31.745%\n",
            "| Epoch [ 33/ 50] Iter[151/  6]\t\tLoss: 17.5252 Acc@1: 31.995%\n",
            "| Epoch [ 33/ 50] Iter[201/  6]\t\tLoss: 12.0762 Acc@1: 32.338%\n",
            "| Epoch [ 33/ 50] Iter[251/  6]\t\tLoss: 20.3230 Acc@1: 32.520%\n",
            "| Epoch [ 33/ 50] Iter[301/  6]\t\tLoss: 14.4400 Acc@1: 33.207%\n",
            "\n",
            "| Validation Epoch #33\t\t\tLoss: 15.3131 Acc@1: 36.30%\n",
            "lr = 1e-05\n",
            "| Epoch [ 34/ 50] Iter[  1/  6]\t\tLoss: 10.8240 Acc@1: 45.312%\n",
            "| Epoch [ 34/ 50] Iter[ 51/  6]\t\tLoss: 11.5423 Acc@1: 38.542%\n",
            "| Epoch [ 34/ 50] Iter[101/  6]\t\tLoss: 15.4692 Acc@1: 38.041%\n",
            "| Epoch [ 34/ 50] Iter[151/  6]\t\tLoss: 12.2490 Acc@1: 37.810%\n",
            "| Epoch [ 34/ 50] Iter[201/  6]\t\tLoss: 13.3454 Acc@1: 37.702%\n",
            "| Epoch [ 34/ 50] Iter[251/  6]\t\tLoss: 13.4983 Acc@1: 37.705%\n",
            "| Epoch [ 34/ 50] Iter[301/  6]\t\tLoss: 11.0996 Acc@1: 37.645%\n",
            "\n",
            "| Validation Epoch #34\t\t\tLoss: 11.4007 Acc@1: 38.01%\n",
            "lr = 1e-05\n",
            "| Epoch [ 35/ 50] Iter[  1/  6]\t\tLoss: 13.9260 Acc@1: 34.375%\n",
            "| Epoch [ 35/ 50] Iter[ 51/  6]\t\tLoss: 12.2443 Acc@1: 38.787%\n",
            "| Epoch [ 35/ 50] Iter[101/  6]\t\tLoss: 8.4886 Acc@1: 39.279%\n",
            "| Epoch [ 35/ 50] Iter[151/  6]\t\tLoss: 10.5474 Acc@1: 39.735%\n",
            "| Epoch [ 35/ 50] Iter[201/  6]\t\tLoss: 11.9211 Acc@1: 39.964%\n",
            "| Epoch [ 35/ 50] Iter[251/  6]\t\tLoss: 8.8323 Acc@1: 40.090%\n",
            "| Epoch [ 35/ 50] Iter[301/  6]\t\tLoss: 10.0012 Acc@1: 40.054%\n",
            "\n",
            "| Validation Epoch #35\t\t\tLoss: 12.9782 Acc@1: 40.76%\n",
            "lr = 1e-05\n",
            "| Epoch [ 36/ 50] Iter[  1/  6]\t\tLoss: 14.3277 Acc@1: 28.125%\n",
            "| Epoch [ 36/ 50] Iter[ 51/  6]\t\tLoss: 10.7693 Acc@1: 40.349%\n",
            "| Epoch [ 36/ 50] Iter[101/  6]\t\tLoss: 9.2656 Acc@1: 41.491%\n",
            "| Epoch [ 36/ 50] Iter[151/  6]\t\tLoss: 9.2456 Acc@1: 41.691%\n",
            "| Epoch [ 36/ 50] Iter[201/  6]\t\tLoss: 5.9400 Acc@1: 42.118%\n",
            "| Epoch [ 36/ 50] Iter[251/  6]\t\tLoss: 9.2798 Acc@1: 42.493%\n",
            "| Epoch [ 36/ 50] Iter[301/  6]\t\tLoss: 7.7249 Acc@1: 42.977%\n",
            "\n",
            "| Validation Epoch #36\t\t\tLoss: 14.5481 Acc@1: 43.55%\n",
            "lr = 1e-05\n",
            "| Epoch [ 37/ 50] Iter[  1/  6]\t\tLoss: 9.8353 Acc@1: 39.062%\n",
            "| Epoch [ 37/ 50] Iter[ 51/  6]\t\tLoss: 8.8590 Acc@1: 44.516%\n",
            "| Epoch [ 37/ 50] Iter[101/  6]\t\tLoss: 8.0731 Acc@1: 44.910%\n",
            "| Epoch [ 37/ 50] Iter[151/  6]\t\tLoss: 8.2389 Acc@1: 45.043%\n",
            "| Epoch [ 37/ 50] Iter[201/  6]\t\tLoss: 8.1388 Acc@1: 45.328%\n",
            "| Epoch [ 37/ 50] Iter[251/  6]\t\tLoss: 6.0250 Acc@1: 45.692%\n",
            "| Epoch [ 37/ 50] Iter[301/  6]\t\tLoss: 7.3195 Acc@1: 46.096%\n",
            "\n",
            "| Validation Epoch #37\t\t\tLoss: 15.1394 Acc@1: 46.84%\n",
            "lr = 1e-05\n",
            "Best RMSE is of : 7.587376704922429 for epoch : 37 ERROR TEST =  (7.587376704922429, tensor(46.8413))\n",
            "| Epoch [ 38/ 50] Iter[  1/  6]\t\tLoss: 6.5208 Acc@1: 43.750%\n",
            "| Epoch [ 38/ 50] Iter[ 51/  6]\t\tLoss: 7.5622 Acc@1: 48.407%\n",
            "| Epoch [ 38/ 50] Iter[101/  6]\t\tLoss: 6.7436 Acc@1: 47.772%\n",
            "| Epoch [ 38/ 50] Iter[151/  6]\t\tLoss: 8.0427 Acc@1: 48.127%\n",
            "| Epoch [ 38/ 50] Iter[201/  6]\t\tLoss: 7.8987 Acc@1: 48.663%\n",
            "| Epoch [ 38/ 50] Iter[251/  6]\t\tLoss: 6.5406 Acc@1: 48.805%\n",
            "| Epoch [ 38/ 50] Iter[301/  6]\t\tLoss: 5.8510 Acc@1: 48.697%\n",
            "\n",
            "| Validation Epoch #38\t\t\tLoss: 6.3627 Acc@1: 48.92%\n",
            "lr = 1e-05\n",
            "Best RMSE is of : 6.652570697996351 for epoch : 38 ERROR TEST =  (6.652570697996351, tensor(48.9229))\n",
            "| Epoch [ 39/ 50] Iter[  1/  6]\t\tLoss: 6.8124 Acc@1: 45.312%\n",
            "| Epoch [ 39/ 50] Iter[ 51/  6]\t\tLoss: 7.1280 Acc@1: 50.521%\n",
            "| Epoch [ 39/ 50] Iter[101/  6]\t\tLoss: 5.2371 Acc@1: 50.232%\n",
            "| Epoch [ 39/ 50] Iter[151/  6]\t\tLoss: 6.8070 Acc@1: 50.300%\n",
            "| Epoch [ 39/ 50] Iter[201/  6]\t\tLoss: 5.0699 Acc@1: 50.233%\n",
            "| Epoch [ 39/ 50] Iter[251/  6]\t\tLoss: 5.0103 Acc@1: 50.579%\n",
            "| Epoch [ 39/ 50] Iter[301/  6]\t\tLoss: 4.8312 Acc@1: 50.587%\n",
            "\n",
            "| Validation Epoch #39\t\t\tLoss: 2.7991 Acc@1: 50.66%\n",
            "lr = 1e-05\n",
            "Best RMSE is of : 6.173605066758615 for epoch : 39 ERROR TEST =  (6.173605066758615, tensor(50.6550))\n",
            "| Epoch [ 40/ 50] Iter[  1/  6]\t\tLoss: 7.4897 Acc@1: 53.125%\n",
            "| Epoch [ 40/ 50] Iter[ 51/  6]\t\tLoss: 5.4742 Acc@1: 51.287%\n",
            "| Epoch [ 40/ 50] Iter[101/  6]\t\tLoss: 6.6266 Acc@1: 51.315%\n",
            "| Epoch [ 40/ 50] Iter[151/  6]\t\tLoss: 7.0544 Acc@1: 51.024%\n",
            "| Epoch [ 40/ 50] Iter[201/  6]\t\tLoss: 6.4671 Acc@1: 51.252%\n",
            "| Epoch [ 40/ 50] Iter[251/  6]\t\tLoss: 7.2555 Acc@1: 51.438%\n",
            "| Epoch [ 40/ 50] Iter[301/  6]\t\tLoss: 7.8918 Acc@1: 51.656%\n",
            "\n",
            "| Validation Epoch #40\t\t\tLoss: 3.8747 Acc@1: 51.73%\n",
            "lr = 1e-05\n",
            "Best RMSE is of : 6.056519905726115 for epoch : 40 ERROR TEST =  (6.056519905726115, tensor(51.7322))\n",
            "| Epoch [ 41/ 50] Iter[  1/  6]\t\tLoss: 4.9958 Acc@1: 54.688%\n",
            "| Epoch [ 41/ 50] Iter[ 51/  6]\t\tLoss: 7.0397 Acc@1: 51.593%\n",
            "| Epoch [ 41/ 50] Iter[101/  6]\t\tLoss: 6.6223 Acc@1: 52.645%\n",
            "| Epoch [ 41/ 50] Iter[151/  6]\t\tLoss: 6.0674 Acc@1: 52.877%\n",
            "| Epoch [ 41/ 50] Iter[201/  6]\t\tLoss: 4.3835 Acc@1: 52.760%\n",
            "| Epoch [ 41/ 50] Iter[251/  6]\t\tLoss: 6.6474 Acc@1: 52.596%\n",
            "| Epoch [ 41/ 50] Iter[301/  6]\t\tLoss: 5.3097 Acc@1: 52.621%\n",
            "\n",
            "| Validation Epoch #41\t\t\tLoss: 3.5731 Acc@1: 52.36%\n",
            "lr = 1e-05\n",
            "| Epoch [ 42/ 50] Iter[  1/  6]\t\tLoss: 7.7959 Acc@1: 46.875%\n",
            "| Epoch [ 42/ 50] Iter[ 51/  6]\t\tLoss: 7.4503 Acc@1: 53.431%\n",
            "| Epoch [ 42/ 50] Iter[101/  6]\t\tLoss: 6.0512 Acc@1: 52.986%\n",
            "| Epoch [ 42/ 50] Iter[151/  6]\t\tLoss: 7.1916 Acc@1: 52.597%\n",
            "| Epoch [ 42/ 50] Iter[201/  6]\t\tLoss: 8.9624 Acc@1: 52.783%\n",
            "| Epoch [ 42/ 50] Iter[251/  6]\t\tLoss: 5.9077 Acc@1: 52.677%\n",
            "| Epoch [ 42/ 50] Iter[301/  6]\t\tLoss: 5.8623 Acc@1: 52.461%\n",
            "\n",
            "| Validation Epoch #42\t\t\tLoss: 3.8029 Acc@1: 51.34%\n",
            "lr = 1e-05\n",
            "| Epoch [ 43/ 50] Iter[  1/  6]\t\tLoss: 6.8302 Acc@1: 45.312%\n",
            "| Epoch [ 43/ 50] Iter[ 51/  6]\t\tLoss: 5.5838 Acc@1: 53.339%\n",
            "| Epoch [ 43/ 50] Iter[101/  6]\t\tLoss: 6.2379 Acc@1: 52.475%\n",
            "| Epoch [ 43/ 50] Iter[151/  6]\t\tLoss: 8.1762 Acc@1: 52.059%\n",
            "| Epoch [ 43/ 50] Iter[201/  6]\t\tLoss: 7.9506 Acc@1: 51.998%\n",
            "| Epoch [ 43/ 50] Iter[251/  6]\t\tLoss: 8.0596 Acc@1: 51.830%\n",
            "| Epoch [ 43/ 50] Iter[301/  6]\t\tLoss: 6.7683 Acc@1: 51.749%\n",
            "\n",
            "| Validation Epoch #43\t\t\tLoss: 7.2312 Acc@1: 50.90%\n",
            "lr = 1e-05\n",
            "| Epoch [ 44/ 50] Iter[  1/  6]\t\tLoss: 7.8438 Acc@1: 40.625%\n",
            "| Epoch [ 44/ 50] Iter[ 51/  6]\t\tLoss: 9.0528 Acc@1: 50.735%\n",
            "| Epoch [ 44/ 50] Iter[101/  6]\t\tLoss: 5.8565 Acc@1: 51.315%\n",
            "| Epoch [ 44/ 50] Iter[151/  6]\t\tLoss: 8.5547 Acc@1: 51.459%\n",
            "| Epoch [ 44/ 50] Iter[201/  6]\t\tLoss: 6.3009 Acc@1: 51.360%\n",
            "| Epoch [ 44/ 50] Iter[251/  6]\t\tLoss: 5.7559 Acc@1: 51.214%\n",
            "| Epoch [ 44/ 50] Iter[301/  6]\t\tLoss: 7.4461 Acc@1: 51.168%\n",
            "\n",
            "| Validation Epoch #44\t\t\tLoss: 8.0969 Acc@1: 49.99%\n",
            "lr = 1e-05\n",
            "| Epoch [ 45/ 50] Iter[  1/  6]\t\tLoss: 4.0475 Acc@1: 64.062%\n",
            "| Epoch [ 45/ 50] Iter[ 51/  6]\t\tLoss: 8.5470 Acc@1: 49.877%\n",
            "| Epoch [ 45/ 50] Iter[101/  6]\t\tLoss: 7.7887 Acc@1: 50.480%\n",
            "| Epoch [ 45/ 50] Iter[151/  6]\t\tLoss: 7.0663 Acc@1: 50.921%\n",
            "| Epoch [ 45/ 50] Iter[201/  6]\t\tLoss: 8.7697 Acc@1: 50.622%\n",
            "| Epoch [ 45/ 50] Iter[251/  6]\t\tLoss: 9.9495 Acc@1: 50.523%\n",
            "| Epoch [ 45/ 50] Iter[301/  6]\t\tLoss: 8.1558 Acc@1: 50.317%\n",
            "\n",
            "| Validation Epoch #45\t\t\tLoss: 13.2629 Acc@1: 49.36%\n",
            "lr = 1e-05\n",
            "| Epoch [ 46/ 50] Iter[  1/  6]\t\tLoss: 6.6733 Acc@1: 50.000%\n",
            "| Epoch [ 46/ 50] Iter[ 51/  6]\t\tLoss: 7.7408 Acc@1: 51.103%\n",
            "| Epoch [ 46/ 50] Iter[101/  6]\t\tLoss: 9.6602 Acc@1: 50.681%\n",
            "| Epoch [ 46/ 50] Iter[151/  6]\t\tLoss: 6.3335 Acc@1: 50.393%\n",
            "| Epoch [ 46/ 50] Iter[201/  6]\t\tLoss: 8.4875 Acc@1: 50.381%\n",
            "| Epoch [ 46/ 50] Iter[251/  6]\t\tLoss: 8.4679 Acc@1: 50.168%\n",
            "| Epoch [ 46/ 50] Iter[301/  6]\t\tLoss: 7.0863 Acc@1: 49.875%\n",
            "\n",
            "| Validation Epoch #46\t\t\tLoss: 5.8305 Acc@1: 49.00%\n",
            "lr = 1e-05\n",
            "| Epoch [ 47/ 50] Iter[  1/  6]\t\tLoss: 10.0189 Acc@1: 37.500%\n",
            "| Epoch [ 47/ 50] Iter[ 51/  6]\t\tLoss: 5.0691 Acc@1: 48.713%\n",
            "| Epoch [ 47/ 50] Iter[101/  6]\t\tLoss: 8.8976 Acc@1: 49.489%\n",
            "| Epoch [ 47/ 50] Iter[151/  6]\t\tLoss: 10.0780 Acc@1: 49.089%\n",
            "| Epoch [ 47/ 50] Iter[201/  6]\t\tLoss: 9.5765 Acc@1: 49.285%\n",
            "| Epoch [ 47/ 50] Iter[251/  6]\t\tLoss: 8.6593 Acc@1: 49.253%\n",
            "| Epoch [ 47/ 50] Iter[301/  6]\t\tLoss: 9.1222 Acc@1: 49.320%\n",
            "\n",
            "| Validation Epoch #47\t\t\tLoss: 8.6258 Acc@1: 48.72%\n",
            "lr = 1e-05\n",
            "| Epoch [ 48/ 50] Iter[  1/  6]\t\tLoss: 9.6712 Acc@1: 50.000%\n",
            "| Epoch [ 48/ 50] Iter[ 51/  6]\t\tLoss: 10.1419 Acc@1: 49.081%\n",
            "| Epoch [ 48/ 50] Iter[101/  6]\t\tLoss: 10.4589 Acc@1: 49.165%\n",
            "| Epoch [ 48/ 50] Iter[151/  6]\t\tLoss: 5.3587 Acc@1: 49.100%\n",
            "| Epoch [ 48/ 50] Iter[201/  6]\t\tLoss: 9.1230 Acc@1: 49.557%\n",
            "| Epoch [ 48/ 50] Iter[251/  6]\t\tLoss: 9.0000 Acc@1: 49.521%\n",
            "| Epoch [ 48/ 50] Iter[301/  6]\t\tLoss: 8.5061 Acc@1: 49.284%\n",
            "\n",
            "| Validation Epoch #48\t\t\tLoss: 9.9892 Acc@1: 48.60%\n",
            "lr = 1.0000000000000002e-06\n",
            "| Epoch [ 49/ 50] Iter[  1/  6]\t\tLoss: 9.1590 Acc@1: 48.438%\n",
            "| Epoch [ 49/ 50] Iter[ 51/  6]\t\tLoss: 8.8905 Acc@1: 48.376%\n",
            "| Epoch [ 49/ 50] Iter[101/  6]\t\tLoss: 7.8864 Acc@1: 49.056%\n",
            "| Epoch [ 49/ 50] Iter[151/  6]\t\tLoss: 11.2856 Acc@1: 49.079%\n",
            "| Epoch [ 49/ 50] Iter[201/  6]\t\tLoss: 7.8554 Acc@1: 48.857%\n",
            "| Epoch [ 49/ 50] Iter[251/  6]\t\tLoss: 8.3134 Acc@1: 48.855%\n",
            "| Epoch [ 49/ 50] Iter[301/  6]\t\tLoss: 9.8446 Acc@1: 48.910%\n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 8.3608 Acc@1: 48.60%\n",
            "lr = 1.0000000000000002e-06\n",
            "Training Done!\n"
          ]
        }
      ],
      "source": [
        "print (\"Let us Train.\")\n",
        "EPOCHS = 50\n",
        "model = SentimentClassifier(768, NUM_CLASSES).to(device)\n",
        "model_test = SentimentClassifier(768, NUM_CLASSES).to(device)\n",
        "best_error = float('inf')\n",
        "LEARNING_RATE = 1e-3\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau,StepLR\n",
        "\n",
        "traindataset = EmbeddingDataset(train_embeddings, train_y)\n",
        "trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valdataset = EmbeddingDataset(val_embeddings, val_y)\n",
        "valloader = DataLoader(valdataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "#lr_scheduler =  StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "lr_scheduler = ReduceLROnPlateau(optimizer, 'min', patience=7)\n",
        "\n",
        "train_history = []\n",
        "val_history = []\n",
        "print('----------------------------------------------------------------------------------------------------')\n",
        "print('3/ training model 1')\n",
        "print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "iter =0\n",
        "for epoch in range(EPOCHS):\n",
        "    loss = train(model, trainloader, optimizer, epoch)\n",
        "    train_history.append(loss)\n",
        "    #lr_scheduler.step()\n",
        "    val_loss= test(model, valloader,epoch)\n",
        "    val_history.append(val_loss[0])\n",
        "    lr_scheduler.step(val_loss[0])\n",
        "    print('lr =',get_lr(optimizer))\n",
        "\n",
        "    if val_loss[0] <best_error:\n",
        "        best_error=val_loss[0]\n",
        "        print('Best RMSE is of : ' + str(best_error), 'for epoch :', epoch,'ERROR TEST = ',val_loss)\n",
        "        #model_test.parameters()=model.state_dict()\n",
        "        model_test.load_state_dict(model.state_dict(), strict=True)\n",
        "\n",
        "print (\"Training Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUgqW43GU6ne"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:28:24.157868Z",
          "iopub.status.busy": "2024-09-12T08:28:24.157398Z",
          "iopub.status.idle": "2024-09-12T08:28:24.285993Z",
          "shell.execute_reply": "2024-09-12T08:28:24.284901Z",
          "shell.execute_reply.started": "2024-09-12T08:28:24.157825Z"
        },
        "id": "s8_Iuj66dBip",
        "outputId": "c4b9ca89-fb80-4c58-de6a-fb78c24d52fe",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== \n",
            "Test set = \n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 4.7535 Acc@1: 49.35%\n",
            "==================== \n"
          ]
        }
      ],
      "source": [
        "testdataset = TextDataset(test_x,test_y, tokenizer, MAX_LENGTH)\n",
        "testloader = DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "bert = BertModel.from_pretrained(PRETRAINED_MODEL).to(device)\n",
        "# Extract embeddings\n",
        "\n",
        "test_embeddings = extract_embeddings(bert, testloader, device)\n",
        "test_embeddings =test_embeddings.cpu()\n",
        "print('==================== ')\n",
        "print('Test set = ')\n",
        "testdataset = EmbeddingDataset(test_embeddings, test_y)\n",
        "testdataset = DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loss,accu = test(model, testdataset,epoch)\n",
        "print('==================== ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkD2ubONd_R2"
      },
      "source": [
        "## Questions\n",
        "\n",
        "**q0/  please analyse the dataset with differents classical machine learning model**\n",
        "\n",
        "**q1/  please perform a classification with differents classical machine learning model and analyse the performences**\n",
        "\n",
        "**q2/  please perform a classification with a MLP?**\n",
        "\n",
        "**q3/  please analyse all the performences and explain which is the best**\n",
        "\n",
        "**q4/  please use an LLM compare your performences to a LLM**\n",
        "\n",
        "**q5/  please explain why I choose a BERT embedding instead of the raw text**\n",
        "\n",
        "**q6/  please read the BERT paper and explain the BERT architecture**\n",
        "\n",
        "**q7/  please finetue with LORA an LLM to classify the sentiment (optional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUIRWJllOee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (newton-cg) Accuracy: 0.64\n",
            "Logistic Regression (lbfgs) Accuracy: 0.64\n"
          ]
        }
      ],
      "source": [
        "## QUESTION 0 and 1 :\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "for solver in ['newton-cg', 'lbfgs', 'sag', 'saga']:\n",
        "    logistic_model = LogisticRegression(max_iter=10000, solver=solver,C=10, random_state=42)\n",
        "    logistic_model.fit(train_embeddings, train_y)\n",
        "    logistic_predictions = logistic_model.predict(val_embeddings)\n",
        "    logistic_accuracy = accuracy_score(val_y, logistic_predictions)\n",
        "    print(f'Logistic Regression ({solver}) Accuracy: {logistic_accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 989445,
          "sourceId": 1808590,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30761,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
